Start logging at 2025-02-25 20:02:09
File /home/tuandang/workspace/datasets/tum/extract/rgbd_dataset_freiburg1_desk/depth.txt containts 595 images
File /home/tuandang/workspace/datasets/tum/extract/rgbd_dataset_freiburg1_desk/rgb.txt containts 613 images
Cache at /home/tuandang/workspace/datasets/tum/extract/rgbd_dataset_freiburg1_desk/cached was built previously! Just use it!
FrameId=0:  cached_time=3.4 ms
  TumDataset->next_frame: Original=307200 -downsample-> 27794, --cropped--> 27793
  Sampling->dist_sampling: pc=torch.Size([27793, 6]) -> sampled_points=torch.Size([138965, 6]) time= 1.75 ms
  LatentFeature->update: samples=138965, new_points=3549 (closreSur>VoxDwn>Radius>Distance), all_points=3549
  TrainingPool->update: Nvs=138965 ->  close_surface_sample_idx=83410, all_points=138965, increasement: 0
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([83410])
  TrainingPool->train: break at iter=103, cur_mean_loss=0.800865, mean_loss=0.800954, diff=-0.000089, thres=0.000100
FrameId=1:  cached_time=2.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 28448, --cropped--> 28447
  Registration->register: reg_points=torch.Size([1006, 6]), translation=tensor([0., 0., 0.], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([28447, 6]) -> sampled_points=torch.Size([142235, 6]) time= 0.92 ms
  LatentFeature->update: samples=142235, new_points=3469 (closreSur>VoxDwn>Radius>Distance), all_points=7018
  TrainingPool->update: Nvs=142235 ->  close_surface_sample_idx=84561, all_points=281200, increasement: 138965
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([84561])
  TrainingPool->train: break at iter=62, cur_mean_loss=0.796045, mean_loss=0.796099, diff=-0.000054, thres=0.000100
FrameId=2:  cached_time=3.3 ms
  TumDataset->next_frame: Original=307200 -downsample-> 29146, --cropped--> 29145
  Registration->register: reg_points=torch.Size([1008, 6]), translation=tensor([ 0.0134, -0.0075,  0.0052], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([29145, 6]) -> sampled_points=torch.Size([145725, 6]) time= 0.86 ms
  LatentFeature->update: samples=145725, new_points=3595 (closreSur>VoxDwn>Radius>Distance), all_points=10613
  TrainingPool->update: Nvs=145725 ->  close_surface_sample_idx=86463, all_points=426925, increasement: 281200
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([86463])
  TrainingPool->train: break at iter=64, cur_mean_loss=0.791689, mean_loss=0.791783, diff=-0.000093, thres=0.000100
FrameId=3:  cached_time=2.2 ms
  TumDataset->next_frame: Original=307200 -downsample-> 29965, --cropped--> 29964
  Registration->register: reg_points=torch.Size([1062, 6]), translation=tensor([ 0.0205, -0.0052,  0.0110], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([29964, 6]) -> sampled_points=torch.Size([149820, 6]) time= 0.91 ms
  LatentFeature->update: samples=149820, new_points=3608 (closreSur>VoxDwn>Radius>Distance), all_points=14221
  TrainingPool->update: Nvs=149820 ->  close_surface_sample_idx=89253, all_points=576745, increasement: 426925
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([89253])
  TrainingPool->train: break at iter=57, cur_mean_loss=0.792505, mean_loss=0.792548, diff=-0.000043, thres=0.000100
FrameId=4:  cached_time=2.3 ms
  TumDataset->next_frame: Original=307200 -downsample-> 30727, --cropped--> 30726
  Registration->register: reg_points=torch.Size([1101, 6]), translation=tensor([ 0.0318, -0.0089,  0.0229], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([30726, 6]) -> sampled_points=torch.Size([153630, 6]) time= 0.83 ms
  LatentFeature->update: samples=153630, new_points=3793 (closreSur>VoxDwn>Radius>Distance), all_points=18014
  TrainingPool->update: Nvs=153630 ->  close_surface_sample_idx=91562, all_points=730375, increasement: 576745
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([91562])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.791082, mean_loss=0.791058, diff=0.000023, thres=0.000100
FrameId=5:  cached_time=2.2 ms
  TumDataset->next_frame: Original=307200 -downsample-> 31547, --cropped--> 31546
  Registration->register: reg_points=torch.Size([1125, 6]), translation=tensor([ 0.0284, -0.0126,  0.0407], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([31546, 6]) -> sampled_points=torch.Size([157730, 6]) time= 0.90 ms
  LatentFeature->update: samples=157730, new_points=3869 (closreSur>VoxDwn>Radius>Distance), all_points=21883
  TrainingPool->update: Nvs=157730 ->  close_surface_sample_idx=93609, all_points=888105, increasement: 730375
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([93609])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.790500, mean_loss=0.790486, diff=0.000014, thres=0.000100
FrameId=6:  cached_time=2.3 ms
  TumDataset->next_frame: Original=307200 -downsample-> 32620, --cropped--> 32619
  Registration->register: reg_points=torch.Size([1225, 6]), translation=tensor([ 0.0283, -0.0118,  0.0535], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([32619, 6]) -> sampled_points=torch.Size([163095, 6]) time= 0.92 ms
  LatentFeature->update: samples=163095, new_points=4119 (closreSur>VoxDwn>Radius>Distance), all_points=26002
  TrainingPool->update: Nvs=163095 ->  close_surface_sample_idx=96964, all_points=1051200, increasement: 888105
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([96964])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.789581, mean_loss=0.789647, diff=-0.000066, thres=0.000100
FrameId=7:  cached_time=2.4 ms
  TumDataset->next_frame: Original=307200 -downsample-> 34024, --cropped--> 34023
  Registration->register: reg_points=torch.Size([1265, 6]), translation=tensor([ 0.0284, -0.0149,  0.0646], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([34023, 6]) -> sampled_points=torch.Size([170115, 6]) time= 0.96 ms
  LatentFeature->update: samples=170115, new_points=4300 (closreSur>VoxDwn>Radius>Distance), all_points=30302
  TrainingPool->update: Nvs=170115 ->  close_surface_sample_idx=101322, all_points=1221315, increasement: 1051200
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([101322])
  TrainingPool->train: break at iter=55, cur_mean_loss=0.789669, mean_loss=0.789722, diff=-0.000052, thres=0.000100
FrameId=8:  cached_time=2.4 ms
  TumDataset->next_frame: Original=307200 -downsample-> 35260, --cropped--> 35259
  Registration->register: reg_points=torch.Size([1297, 6]), translation=tensor([ 0.0311, -0.0196,  0.0797], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([35259, 6]) -> sampled_points=torch.Size([176295, 6]) time= 0.80 ms
  LatentFeature->update: samples=176295, new_points=4445 (closreSur>VoxDwn>Radius>Distance), all_points=34747
  TrainingPool->update: Nvs=176295 ->  close_surface_sample_idx=104916, all_points=1397610, increasement: 1221315
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([104916])
  TrainingPool->train: break at iter=57, cur_mean_loss=0.787530, mean_loss=0.787471, diff=0.000059, thres=0.000100
FrameId=9:  cached_time=2.5 ms
  TumDataset->next_frame: Original=307200 -downsample-> 36115, --cropped--> 36114
  Registration->register: reg_points=torch.Size([1341, 6]), translation=tensor([ 0.0235, -0.0210,  0.0954], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([36114, 6]) -> sampled_points=torch.Size([180570, 6]) time= 0.81 ms
  LatentFeature->update: samples=180570, new_points=4586 (closreSur>VoxDwn>Radius>Distance), all_points=39333
  TrainingPool->update: Nvs=180570 ->  close_surface_sample_idx=107740, all_points=1578180, increasement: 1397610
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([107740])
  TrainingPool->train: break at iter=58, cur_mean_loss=0.785815, mean_loss=0.785824, diff=-0.000009, thres=0.000100
FrameId=10:  cached_time=2.5 ms
  TumDataset->next_frame: Original=307200 -downsample-> 37502, --cropped--> 37501
  Registration->register: reg_points=torch.Size([1417, 6]), translation=tensor([ 0.0153, -0.0246,  0.1103], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([37501, 6]) -> sampled_points=torch.Size([187505, 6]) time= 0.96 ms
  LatentFeature->update: samples=187505, new_points=4811 (closreSur>VoxDwn>Radius>Distance), all_points=44144
  TrainingPool->update: Nvs=187505 ->  close_surface_sample_idx=111605, all_points=1765685, increasement: 1578180
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([111605])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.787546, mean_loss=0.787520, diff=0.000026, thres=0.000100
FrameId=11:  cached_time=2.5 ms
  TumDataset->next_frame: Original=307200 -downsample-> 38453, --cropped--> 38452
  Registration->register: reg_points=torch.Size([1440, 6]), translation=tensor([ 0.0159, -0.0338,  0.1210], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([38452, 6]) -> sampled_points=torch.Size([192260, 6]) time= 0.97 ms
  LatentFeature->update: samples=192260, new_points=4931 (closreSur>VoxDwn>Radius>Distance), all_points=49075
  TrainingPool->update: Nvs=192260 ->  close_surface_sample_idx=114590, all_points=1957945, increasement: 1765685
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([114590])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.786370, mean_loss=0.786395, diff=-0.000025, thres=0.000100
FrameId=12:  cached_time=2.4 ms
  TumDataset->next_frame: Original=307200 -downsample-> 38982, --cropped--> 38981
  Registration->register: reg_points=torch.Size([1477, 6]), translation=tensor([ 0.0031, -0.0401,  0.1375], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([38981, 6]) -> sampled_points=torch.Size([194905, 6]) time= 1.03 ms
  LatentFeature->update: samples=194905, new_points=5060 (closreSur>VoxDwn>Radius>Distance), all_points=54135
  TrainingPool->update: Nvs=194905 ->  close_surface_sample_idx=116285, all_points=2152850, increasement: 1957945
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([116285])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.787244, mean_loss=0.787232, diff=0.000012, thres=0.000100
FrameId=13:  cached_time=2.5 ms
  TumDataset->next_frame: Original=307200 -downsample-> 40286, --cropped--> 40285
  Registration->register: reg_points=torch.Size([1548, 6]), translation=tensor([-0.0128, -0.0438,  0.1529], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([40285, 6]) -> sampled_points=torch.Size([201425, 6]) time= 0.94 ms
  LatentFeature->update: samples=201425, new_points=5248 (closreSur>VoxDwn>Radius>Distance), all_points=59383
  TrainingPool->update: Nvs=201425 ->  close_surface_sample_idx=119771, all_points=2354275, increasement: 2152850
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([119771])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.786648, mean_loss=0.786630, diff=0.000018, thres=0.000100
FrameId=14:  cached_time=2.3 ms
  TumDataset->next_frame: Original=307200 -downsample-> 40150, --cropped--> 40149
  Registration->register: reg_points=torch.Size([1560, 6]), translation=tensor([-0.0265, -0.0574,  0.1659], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([40149, 6]) -> sampled_points=torch.Size([200745, 6]) time= 0.91 ms
  LatentFeature->update: samples=200745, new_points=5282 (closreSur>VoxDwn>Radius>Distance), all_points=64665
  TrainingPool->update: Nvs=200745 ->  close_surface_sample_idx=119311, all_points=2555020, increasement: 2354275
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([119311])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.785934, mean_loss=0.785986, diff=-0.000052, thres=0.000100
FrameId=15:  cached_time=2.2 ms
  TumDataset->next_frame: Original=307200 -downsample-> 39658, --cropped--> 39657
  Registration->register: reg_points=torch.Size([1519, 6]), translation=tensor([-0.0402, -0.0700,  0.1747], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([39657, 6]) -> sampled_points=torch.Size([198285, 6]) time= 0.95 ms
  LatentFeature->update: samples=198285, new_points=5270 (closreSur>VoxDwn>Radius>Distance), all_points=69935
  TrainingPool->update: Nvs=198285 ->  close_surface_sample_idx=118026, all_points=2753305, increasement: 2555020
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([118026])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.785496, mean_loss=0.785417, diff=0.000078, thres=0.000100
FrameId=16:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 39129, --cropped--> 39128
  Registration->register: reg_points=torch.Size([1532, 6]), translation=tensor([-0.0555, -0.0734,  0.1829], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([39128, 6]) -> sampled_points=torch.Size([195640, 6]) time= 0.96 ms
  LatentFeature->update: samples=195640, new_points=5117 (closreSur>VoxDwn>Radius>Distance), all_points=75052
  TrainingPool->update: Nvs=195640 ->  close_surface_sample_idx=115443, all_points=2948945, increasement: 2753305
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([115443])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.783623, mean_loss=0.783651, diff=-0.000028, thres=0.000100
FrameId=17:  cached_time=2.2 ms
  TumDataset->next_frame: Original=307200 -downsample-> 38576, --cropped--> 38575
  Registration->register: reg_points=torch.Size([1534, 6]), translation=tensor([-0.0766, -0.0842,  0.1894], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([38575, 6]) -> sampled_points=torch.Size([192875, 6]) time= 0.99 ms
  LatentFeature->update: samples=192875, new_points=5240 (closreSur>VoxDwn>Radius>Distance), all_points=80292
  TrainingPool->update: Nvs=192875 ->  close_surface_sample_idx=115008, all_points=3141820, increasement: 2948945
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([115008])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.784210, mean_loss=0.784219, diff=-0.000010, thres=0.000100
FrameId=18:  cached_time=2.0 ms
  TumDataset->next_frame: Original=307200 -downsample-> 38629, --cropped--> 38628
  Registration->register: reg_points=torch.Size([1582, 6]), translation=tensor([-0.0947, -0.0901,  0.1969], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([38628, 6]) -> sampled_points=torch.Size([193140, 6]) time= 0.95 ms
  LatentFeature->update: samples=193140, new_points=5364 (closreSur>VoxDwn>Radius>Distance), all_points=85656
  TrainingPool->update: Nvs=193140 ->  close_surface_sample_idx=114638, all_points=3334960, increasement: 3141820
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([114638])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.784366, mean_loss=0.784413, diff=-0.000046, thres=0.000100
FrameId=19:  cached_time=2.3 ms
  TumDataset->next_frame: Original=307200 -downsample-> 37397, --cropped--> 37396
  Registration->register: reg_points=torch.Size([1552, 6]), translation=tensor([-0.1011, -0.1035,  0.2064], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([37396, 6]) -> sampled_points=torch.Size([186980, 6]) time= 0.93 ms
  LatentFeature->update: samples=186980, new_points=5280 (closreSur>VoxDwn>Radius>Distance), all_points=90936
  TrainingPool->update: Nvs=186980 ->  close_surface_sample_idx=111147, all_points=3521940, increasement: 3334960
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([111147])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.783970, mean_loss=0.783969, diff=0.000001, thres=0.000100
FrameId=20:  cached_time=2.2 ms
  TumDataset->next_frame: Original=307200 -downsample-> 36723, --cropped--> 36722
  Registration->register: reg_points=torch.Size([1561, 6]), translation=tensor([-0.1211, -0.1027,  0.2080], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([36722, 6]) -> sampled_points=torch.Size([183610, 6]) time= 0.99 ms
  LatentFeature->update: samples=183610, new_points=5286 (closreSur>VoxDwn>Radius>Distance), all_points=96222
  TrainingPool->update: Nvs=183610 ->  close_surface_sample_idx=109525, all_points=3705550, increasement: 3521940
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([109525])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.782896, mean_loss=0.782809, diff=0.000087, thres=0.000100
FrameId=21:  cached_time=2.0 ms
  TumDataset->next_frame: Original=307200 -downsample-> 35974, --cropped--> 35973
  Registration->register: reg_points=torch.Size([1574, 6]), translation=tensor([-0.1211, -0.0984,  0.2062], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([35973, 6]) -> sampled_points=torch.Size([179865, 6]) time= 0.90 ms
  LatentFeature->update: samples=179865, new_points=5274 (closreSur>VoxDwn>Radius>Distance), all_points=101496
  TrainingPool->update: Nvs=179865 ->  close_surface_sample_idx=107302, all_points=3885415, increasement: 3705550
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([107302])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.783657, mean_loss=0.783686, diff=-0.000029, thres=0.000100
FrameId=22:  cached_time=2.3 ms
  TumDataset->next_frame: Original=307200 -downsample-> 34958, --cropped--> 34957
  Registration->register: reg_points=torch.Size([1516, 6]), translation=tensor([-0.1431, -0.1135,  0.2193], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([34957, 6]) -> sampled_points=torch.Size([174785, 6]) time= 0.99 ms
  LatentFeature->update: samples=174785, new_points=5200 (closreSur>VoxDwn>Radius>Distance), all_points=106696
  TrainingPool->update: Nvs=174785 ->  close_surface_sample_idx=104227, all_points=4060200, increasement: 3885415
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([104227])
  TrainingPool->train: break at iter=58, cur_mean_loss=0.783332, mean_loss=0.783373, diff=-0.000041, thres=0.000100
FrameId=23:  cached_time=2.2 ms
  TumDataset->next_frame: Original=307200 -downsample-> 34087, --cropped--> 34086
  Registration->register: reg_points=torch.Size([1498, 6]), translation=tensor([-0.1531, -0.1089,  0.2158], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([34086, 6]) -> sampled_points=torch.Size([170430, 6]) time= 0.92 ms
  LatentFeature->update: samples=170430, new_points=5151 (closreSur>VoxDwn>Radius>Distance), all_points=111847
  TrainingPool->update: Nvs=170430 ->  close_surface_sample_idx=101680, all_points=4230630, increasement: 4060200
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([101680])
  TrainingPool->train: break at iter=56, cur_mean_loss=0.782551, mean_loss=0.782522, diff=0.000029, thres=0.000100
FrameId=24:  cached_time=2.2 ms
  TumDataset->next_frame: Original=307200 -downsample-> 33739, --cropped--> 33738
  Registration->register: reg_points=torch.Size([1488, 6]), translation=tensor([-0.1644, -0.1038,  0.2171], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([33738, 6]) -> sampled_points=torch.Size([168690, 6]) time= 0.79 ms
  LatentFeature->update: samples=168690, new_points=5086 (closreSur>VoxDwn>Radius>Distance), all_points=116933
  TrainingPool->update: Nvs=168690 ->  close_surface_sample_idx=100580, all_points=4399320, increasement: 4230630
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([100580])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.783131, mean_loss=0.783202, diff=-0.000070, thres=0.000100
FrameId=25:  cached_time=2.3 ms
  TumDataset->next_frame: Original=307200 -downsample-> 32777, --cropped--> 32776
  Registration->register: reg_points=torch.Size([1464, 6]), translation=tensor([-0.2131, -0.1238,  0.2382], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([32776, 6]) -> sampled_points=torch.Size([163880, 6]) time= 0.90 ms
  LatentFeature->update: samples=163880, new_points=5028 (closreSur>VoxDwn>Radius>Distance), all_points=121961
  TrainingPool->update: Nvs=163880 ->  close_surface_sample_idx=98046, all_points=4563200, increasement: 4399320
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([98046])
  TrainingPool->train: break at iter=57, cur_mean_loss=0.780174, mean_loss=0.780186, diff=-0.000013, thres=0.000100
FrameId=26:  cached_time=2.2 ms
  TumDataset->next_frame: Original=307200 -downsample-> 31937, --cropped--> 31936
  Registration->register: reg_points=torch.Size([1457, 6]), translation=tensor([-0.2870, -0.0874,  0.2123], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([31936, 6]) -> sampled_points=torch.Size([159680, 6]) time= 0.91 ms
  LatentFeature->update: samples=159680, new_points=4871 (closreSur>VoxDwn>Radius>Distance), all_points=126832
  TrainingPool->update: Nvs=159680 ->  close_surface_sample_idx=95183, all_points=4722880, increasement: 4563200
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([95183])
  TrainingPool->train: break at iter=56, cur_mean_loss=0.779467, mean_loss=0.779559, diff=-0.000092, thres=0.000100
FrameId=27:  cached_time=2.2 ms
  TumDataset->next_frame: Original=307200 -downsample-> 33048, --cropped--> 33047
  Registration->register: reg_points=torch.Size([1514, 6]), translation=tensor([-0.3037, -0.0846,  0.2110], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([33047, 6]) -> sampled_points=torch.Size([165235, 6]) time= 0.79 ms
  LatentFeature->update: samples=165235, new_points=5225 (closreSur>VoxDwn>Radius>Distance), all_points=132057
  TrainingPool->update: Nvs=165235 ->  close_surface_sample_idx=98614, all_points=4888115, increasement: 4722880
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([98614])
  TrainingPool->train: break at iter=57, cur_mean_loss=0.777580, mean_loss=0.777561, diff=0.000018, thres=0.000100
FrameId=28:  cached_time=2.2 ms
  TumDataset->next_frame: Original=307200 -downsample-> 33148, --cropped--> 33147
  Registration->register: reg_points=torch.Size([1549, 6]), translation=tensor([-0.3306, -0.0953,  0.2219], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([33147, 6]) -> sampled_points=torch.Size([165735, 6]) time= 0.89 ms
  LatentFeature->update: samples=165735, new_points=5291 (closreSur>VoxDwn>Radius>Distance), all_points=137348
  TrainingPool->update: Nvs=165735 ->  close_surface_sample_idx=98796, all_points=5053850, increasement: 4888115
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([98796])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.778905, mean_loss=0.778843, diff=0.000062, thres=0.000100
FrameId=29:  cached_time=2.1 ms
  TumDataset->next_frame: Original=307200 -downsample-> 32528, --cropped--> 32527
  Registration->register: reg_points=torch.Size([1472, 6]), translation=tensor([-0.3456, -0.1091,  0.2221], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([32527, 6]) -> sampled_points=torch.Size([162635, 6]) time= 0.88 ms
  LatentFeature->update: samples=162635, new_points=5150 (closreSur>VoxDwn>Radius>Distance), all_points=142498
  TrainingPool->update: Nvs=162635 ->  close_surface_sample_idx=97013, all_points=5216485, increasement: 5053850
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([97013])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.777879, mean_loss=0.777821, diff=0.000058, thres=0.000100
FrameId=30:  cached_time=2.0 ms
  TumDataset->next_frame: Original=307200 -downsample-> 34064, --cropped--> 34063
  Registration->register: reg_points=torch.Size([1569, 6]), translation=tensor([-0.3672, -0.1058,  0.2230], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([34063, 6]) -> sampled_points=torch.Size([170315, 6]) time= 1.04 ms
  LatentFeature->update: samples=170315, new_points=5458 (closreSur>VoxDwn>Radius>Distance), all_points=147956
  TrainingPool->update: Nvs=170315 ->  close_surface_sample_idx=101548, all_points=5386800, increasement: 5216485
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([101548])
  TrainingPool->train: break at iter=55, cur_mean_loss=0.777578, mean_loss=0.777664, diff=-0.000086, thres=0.000100
FrameId=31:  cached_time=2.1 ms
  TumDataset->next_frame: Original=307200 -downsample-> 34966, --cropped--> 34965
  Registration->register: reg_points=torch.Size([1639, 6]), translation=tensor([-0.3682, -0.1009,  0.2193], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([34965, 6]) -> sampled_points=torch.Size([174825, 6]) time= 0.96 ms
  LatentFeature->update: samples=174825, new_points=5703 (closreSur>VoxDwn>Radius>Distance), all_points=153659
  TrainingPool->update: Nvs=174825 ->  close_surface_sample_idx=104247, all_points=5561625, increasement: 5386800
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([104247])
  TrainingPool->train: break at iter=54, cur_mean_loss=0.776595, mean_loss=0.776638, diff=-0.000044, thres=0.000100
FrameId=32:  cached_time=2.3 ms
  TumDataset->next_frame: Original=307200 -downsample-> 35894, --cropped--> 35893
  Registration->register: reg_points=torch.Size([1680, 6]), translation=tensor([-0.3852, -0.1109,  0.2197], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([35893, 6]) -> sampled_points=torch.Size([179465, 6]) time= 1.03 ms
  LatentFeature->update: samples=179465, new_points=5921 (closreSur>VoxDwn>Radius>Distance), all_points=159580
  TrainingPool->update: Nvs=179465 ->  close_surface_sample_idx=106959, all_points=5741090, increasement: 5561625
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([106959])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.776442, mean_loss=0.776502, diff=-0.000060, thres=0.000100
FrameId=33:  cached_time=2.3 ms
  TumDataset->next_frame: Original=307200 -downsample-> 36905, --cropped--> 36904
  Registration->register: reg_points=torch.Size([1740, 6]), translation=tensor([-0.3893, -0.1273,  0.2187], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([36904, 6]) -> sampled_points=torch.Size([184520, 6]) time= 1.01 ms
  LatentFeature->update: samples=184520, new_points=6111 (closreSur>VoxDwn>Radius>Distance), all_points=165691
  TrainingPool->update: Nvs=184520 ->  close_surface_sample_idx=109969, all_points=5925610, increasement: 5741090
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([109969])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.775944, mean_loss=0.776022, diff=-0.000078, thres=0.000100
FrameId=34:  cached_time=2.2 ms
  TumDataset->next_frame: Original=307200 -downsample-> 36644, --cropped--> 36643
  Registration->register: reg_points=torch.Size([1728, 6]), translation=tensor([-0.4006, -0.1276,  0.2179], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([36643, 6]) -> sampled_points=torch.Size([183215, 6]) time= 0.87 ms
  LatentFeature->update: samples=183215, new_points=6025 (closreSur>VoxDwn>Radius>Distance), all_points=171716
  TrainingPool->update: Nvs=183215 ->  close_surface_sample_idx=109200, all_points=6108825, increasement: 5925610
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([109200])
  TrainingPool->train: break at iter=55, cur_mean_loss=0.775449, mean_loss=0.775401, diff=0.000048, thres=0.000100
FrameId=35:  cached_time=2.2 ms
  TumDataset->next_frame: Original=307200 -downsample-> 36659, --cropped--> 36658
  Registration->register: reg_points=torch.Size([1712, 6]), translation=tensor([-0.4081, -0.1326,  0.2186], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([36658, 6]) -> sampled_points=torch.Size([183290, 6]) time= 0.95 ms
  LatentFeature->update: samples=183290, new_points=6068 (closreSur>VoxDwn>Radius>Distance), all_points=177784
  TrainingPool->update: Nvs=183290 ->  close_surface_sample_idx=109231, all_points=6292115, increasement: 6108825
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([109231])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.777736, mean_loss=0.777835, diff=-0.000099, thres=0.000100
FrameId=36:  cached_time=2.2 ms
  TumDataset->next_frame: Original=307200 -downsample-> 35340, --cropped--> 35339
  Registration->register: reg_points=torch.Size([1654, 6]), translation=tensor([-0.4366, -0.1367,  0.2281], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([35339, 6]) -> sampled_points=torch.Size([176695, 6]) time= 0.97 ms
  LatentFeature->update: samples=176695, new_points=5778 (closreSur>VoxDwn>Radius>Distance), all_points=183562
  TrainingPool->update: Nvs=176695 ->  close_surface_sample_idx=105340, all_points=6468810, increasement: 6292115
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([105340])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.774710, mean_loss=0.774670, diff=0.000040, thres=0.000100
FrameId=37:  cached_time=2.1 ms
  TumDataset->next_frame: Original=307200 -downsample-> 34323, --cropped--> 34322
  Registration->register: reg_points=torch.Size([1577, 6]), translation=tensor([-0.4467, -0.1526,  0.2337], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([34322, 6]) -> sampled_points=torch.Size([171610, 6]) time= 0.96 ms
  LatentFeature->update: samples=171610, new_points=5546 (closreSur>VoxDwn>Radius>Distance), all_points=189108
  TrainingPool->update: Nvs=171610 ->  close_surface_sample_idx=102251, all_points=6640420, increasement: 6468810
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([102251])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.774611, mean_loss=0.774635, diff=-0.000024, thres=0.000100
FrameId=38:  cached_time=2.1 ms
  TumDataset->next_frame: Original=307200 -downsample-> 33361, --cropped--> 33360
  Registration->register: reg_points=torch.Size([1580, 6]), translation=tensor([-0.4327, -0.1369,  0.2154], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([33360, 6]) -> sampled_points=torch.Size([166800, 6]) time= 0.96 ms
  LatentFeature->update: samples=166800, new_points=5474 (closreSur>VoxDwn>Radius>Distance), all_points=194582
  TrainingPool->update: Nvs=166800 ->  close_surface_sample_idx=99474, all_points=6807220, increasement: 6640420
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([99474])
  TrainingPool->train: break at iter=54, cur_mean_loss=0.774613, mean_loss=0.774595, diff=0.000017, thres=0.000100
FrameId=39:  cached_time=2.2 ms
  TumDataset->next_frame: Original=307200 -downsample-> 33239, --cropped--> 33238
  Registration->register: reg_points=torch.Size([1521, 6]), translation=tensor([-0.4451, -0.1365,  0.2217], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([33238, 6]) -> sampled_points=torch.Size([166190, 6]) time= 0.92 ms
  LatentFeature->update: samples=166190, new_points=5370 (closreSur>VoxDwn>Radius>Distance), all_points=199952
  TrainingPool->update: Nvs=166190 ->  close_surface_sample_idx=99177, all_points=6973410, increasement: 6807220
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([99177])
  TrainingPool->train: break at iter=55, cur_mean_loss=0.774746, mean_loss=0.774827, diff=-0.000081, thres=0.000100
FrameId=40:  cached_time=2.1 ms
  TumDataset->next_frame: Original=307200 -downsample-> 32498, --cropped--> 32497
  Registration->register: reg_points=torch.Size([1448, 6]), translation=tensor([-0.4551, -0.1546,  0.2259], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([32497, 6]) -> sampled_points=torch.Size([162485, 6]) time= 1.06 ms
  LatentFeature->update: samples=162485, new_points=5159 (closreSur>VoxDwn>Radius>Distance), all_points=205111
  TrainingPool->update: Nvs=162485 ->  close_surface_sample_idx=97020, all_points=7135895, increasement: 6973410
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([97020])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.774267, mean_loss=0.774259, diff=0.000008, thres=0.000100
FrameId=41:  cached_time=2.0 ms
  TumDataset->next_frame: Original=307200 -downsample-> 32497, --cropped--> 32496
  Registration->register: reg_points=torch.Size([1473, 6]), translation=tensor([-0.4638, -0.1517,  0.2271], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([32496, 6]) -> sampled_points=torch.Size([162480, 6]) time= 1.01 ms
  LatentFeature->update: samples=162480, new_points=5120 (closreSur>VoxDwn>Radius>Distance), all_points=210231
  TrainingPool->update: Nvs=162480 ->  close_surface_sample_idx=96915, all_points=7298375, increasement: 7135895
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([96915])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.774710, mean_loss=0.774802, diff=-0.000092, thres=0.000100
FrameId=42:  cached_time=2.1 ms
  TumDataset->next_frame: Original=307200 -downsample-> 31620, --cropped--> 31619
  Registration->register: reg_points=torch.Size([1359, 6]), translation=tensor([-0.4723, -0.1657,  0.2296], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([31619, 6]) -> sampled_points=torch.Size([158095, 6]) time= 0.87 ms
  LatentFeature->update: samples=158095, new_points=4912 (closreSur>VoxDwn>Radius>Distance), all_points=215143
  TrainingPool->update: Nvs=158095 ->  close_surface_sample_idx=94400, all_points=7456470, increasement: 7298375
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([94400])
  TrainingPool->train: break at iter=56, cur_mean_loss=0.774133, mean_loss=0.774080, diff=0.000054, thres=0.000100
FrameId=43:  cached_time=2.4 ms
  TumDataset->next_frame: Original=307200 -downsample-> 31608, --cropped--> 31607
  Registration->register: reg_points=torch.Size([1409, 6]), translation=tensor([-0.4534, -0.1636,  0.2200], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([31607, 6]) -> sampled_points=torch.Size([158035, 6]) time= 0.94 ms
  LatentFeature->update: samples=158035, new_points=4956 (closreSur>VoxDwn>Radius>Distance), all_points=220099
  TrainingPool->update: Nvs=158035 ->  close_surface_sample_idx=94334, all_points=7614505, increasement: 7456470
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([94334])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.772619, mean_loss=0.772695, diff=-0.000076, thres=0.000100
FrameId=44:  cached_time=2.3 ms
  TumDataset->next_frame: Original=307200 -downsample-> 31176, --cropped--> 31175
  Registration->register: reg_points=torch.Size([1386, 6]), translation=tensor([-0.4387, -0.1832,  0.2143], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([31175, 6]) -> sampled_points=torch.Size([155875, 6]) time= 0.98 ms
  LatentFeature->update: samples=155875, new_points=4855 (closreSur>VoxDwn>Radius>Distance), all_points=224954
  TrainingPool->update: Nvs=155875 ->  close_surface_sample_idx=92947, all_points=7770380, increasement: 7614505
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([92947])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.772888, mean_loss=0.772816, diff=0.000072, thres=0.000100
FrameId=45:  cached_time=2.2 ms
  TumDataset->next_frame: Original=307200 -downsample-> 30351, --cropped--> 30350
  Registration->register: reg_points=torch.Size([1335, 6]), translation=tensor([-0.4384, -0.1910,  0.2161], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([30350, 6]) -> sampled_points=torch.Size([151750, 6]) time= 0.96 ms
  LatentFeature->update: samples=151750, new_points=4710 (closreSur>VoxDwn>Radius>Distance), all_points=229664
  TrainingPool->update: Nvs=151750 ->  close_surface_sample_idx=90438, all_points=7922130, increasement: 7770380
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([90438])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.772676, mean_loss=0.772702, diff=-0.000025, thres=0.000100
FrameId=46:  cached_time=2.4 ms
  TumDataset->next_frame: Original=307200 -downsample-> 29180, --cropped--> 29179
  Registration->register: reg_points=torch.Size([1252, 6]), translation=tensor([-0.4294, -0.1893,  0.2122], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([29179, 6]) -> sampled_points=torch.Size([145895, 6]) time= 1.00 ms
  LatentFeature->update: samples=145895, new_points=4466 (closreSur>VoxDwn>Radius>Distance), all_points=234130
  TrainingPool->update: Nvs=145895 ->  close_surface_sample_idx=86981, all_points=8068025, increasement: 7922130
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([86981])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.772591, mean_loss=0.772657, diff=-0.000067, thres=0.000100
FrameId=47:  cached_time=2.3 ms
  TumDataset->next_frame: Original=307200 -downsample-> 28375, --cropped--> 28374
  Registration->register: reg_points=torch.Size([1202, 6]), translation=tensor([-0.4456, -0.2123,  0.2220], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([28374, 6]) -> sampled_points=torch.Size([141870, 6]) time= 0.99 ms
  LatentFeature->update: samples=141870, new_points=4191 (closreSur>VoxDwn>Radius>Distance), all_points=238321
  TrainingPool->update: Nvs=141870 ->  close_surface_sample_idx=84637, all_points=8209895, increasement: 8068025
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([84637])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.773113, mean_loss=0.773033, diff=0.000080, thres=0.000100
FrameId=48:  cached_time=2.4 ms
  TumDataset->next_frame: Original=307200 -downsample-> 27813, --cropped--> 27812
  Registration->register: reg_points=torch.Size([1194, 6]), translation=tensor([-0.4353, -0.2232,  0.2251], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([27812, 6]) -> sampled_points=torch.Size([139060, 6]) time= 0.94 ms
  LatentFeature->update: samples=139060, new_points=4083 (closreSur>VoxDwn>Radius>Distance), all_points=242404
  TrainingPool->update: Nvs=139060 ->  close_surface_sample_idx=82972, all_points=8348955, increasement: 8209895
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([82972])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.773183, mean_loss=0.773269, diff=-0.000086, thres=0.000100
FrameId=49:  cached_time=2.2 ms
  TumDataset->next_frame: Original=307200 -downsample-> 27246, --cropped--> 27245
  Registration->register: reg_points=torch.Size([1145, 6]), translation=tensor([-0.4274, -0.2444,  0.2314], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([27245, 6]) -> sampled_points=torch.Size([136225, 6]) time= 0.88 ms
  LatentFeature->update: samples=136225, new_points=3969 (closreSur>VoxDwn>Radius>Distance), all_points=246373
  TrainingPool->update: Nvs=136225 ->  close_surface_sample_idx=81293, all_points=8485180, increasement: 8348955
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([81293])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.773687, mean_loss=0.773680, diff=0.000007, thres=0.000100
FrameId=50:  cached_time=2.3 ms
  TumDataset->next_frame: Original=307200 -downsample-> 27228, --cropped--> 27227
  Registration->register: reg_points=torch.Size([1165, 6]), translation=tensor([-0.4179, -0.2474,  0.2229], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([27227, 6]) -> sampled_points=torch.Size([136135, 6]) time= 0.90 ms
  LatentFeature->update: samples=136135, new_points=3974 (closreSur>VoxDwn>Radius>Distance), all_points=250347
  TrainingPool->update: Nvs=136135 ->  close_surface_sample_idx=81153, all_points=8621315, increasement: 8485180
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([81153])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.772579, mean_loss=0.772553, diff=0.000026, thres=0.000100
FrameId=51:  cached_time=2.3 ms
  TumDataset->next_frame: Original=307200 -downsample-> 26886, --cropped--> 26885
  Registration->register: reg_points=torch.Size([1148, 6]), translation=tensor([-0.4231, -0.2635,  0.2282], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([26885, 6]) -> sampled_points=torch.Size([134425, 6]) time= 0.92 ms
  LatentFeature->update: samples=134425, new_points=3904 (closreSur>VoxDwn>Radius>Distance), all_points=254251
  TrainingPool->update: Nvs=134425 ->  close_surface_sample_idx=80136, all_points=8755740, increasement: 8621315
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([80136])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.772833, mean_loss=0.772856, diff=-0.000023, thres=0.000100
FrameId=52:  cached_time=2.3 ms
  TumDataset->next_frame: Original=307200 -downsample-> 26627, --cropped--> 26626
  Registration->register: reg_points=torch.Size([1160, 6]), translation=tensor([-0.4326, -0.2770,  0.2330], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([26626, 6]) -> sampled_points=torch.Size([133130, 6]) time= 0.89 ms
  LatentFeature->update: samples=133130, new_points=3900 (closreSur>VoxDwn>Radius>Distance), all_points=258151
  TrainingPool->update: Nvs=133130 ->  close_surface_sample_idx=79432, all_points=8888870, increasement: 8755740
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([79432])
  TrainingPool->train: break at iter=54, cur_mean_loss=0.772553, mean_loss=0.772521, diff=0.000032, thres=0.000100
FrameId=53:  cached_time=2.2 ms
  TumDataset->next_frame: Original=307200 -downsample-> 26642, --cropped--> 26641
  Registration->register: reg_points=torch.Size([1145, 6]), translation=tensor([-0.4335, -0.2828,  0.2329], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([26641, 6]) -> sampled_points=torch.Size([133205, 6]) time= 0.98 ms
  LatentFeature->update: samples=133205, new_points=3898 (closreSur>VoxDwn>Radius>Distance), all_points=262049
  TrainingPool->update: Nvs=133205 ->  close_surface_sample_idx=79469, all_points=9022075, increasement: 8888870
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([79469])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.771074, mean_loss=0.771122, diff=-0.000049, thres=0.000100
FrameId=54:  cached_time=2.2 ms
  TumDataset->next_frame: Original=307200 -downsample-> 26495, --cropped--> 26494
  Registration->register: reg_points=torch.Size([1151, 6]), translation=tensor([-0.4521, -0.3120,  0.2440], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([26494, 6]) -> sampled_points=torch.Size([132470, 6]) time= 0.99 ms
  LatentFeature->update: samples=132470, new_points=3869 (closreSur>VoxDwn>Radius>Distance), all_points=265918
  TrainingPool->update: Nvs=132470 ->  close_surface_sample_idx=79028, all_points=9154545, increasement: 9022075
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([79028])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.771406, mean_loss=0.771445, diff=-0.000039, thres=0.000100
FrameId=55:  cached_time=2.5 ms
  TumDataset->next_frame: Original=307200 -downsample-> 26007, --cropped--> 26006
  Registration->register: reg_points=torch.Size([1121, 6]), translation=tensor([-0.4404, -0.3197,  0.2355], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([26006, 6]) -> sampled_points=torch.Size([130030, 6]) time= 0.97 ms
  LatentFeature->update: samples=130030, new_points=3787 (closreSur>VoxDwn>Radius>Distance), all_points=269705
  TrainingPool->update: Nvs=130030 ->  close_surface_sample_idx=77688, all_points=9284575, increasement: 9154545
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([77688])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.773298, mean_loss=0.773314, diff=-0.000016, thres=0.000100
FrameId=56:  cached_time=2.2 ms
  TumDataset->next_frame: Original=307200 -downsample-> 25520, --cropped--> 25519
  Registration->register: reg_points=torch.Size([1091, 6]), translation=tensor([-0.4433, -0.3443,  0.2372], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([25519, 6]) -> sampled_points=torch.Size([127595, 6]) time= 0.99 ms
  LatentFeature->update: samples=127595, new_points=3721 (closreSur>VoxDwn>Radius>Distance), all_points=273426
  TrainingPool->update: Nvs=127595 ->  close_surface_sample_idx=76132, all_points=9412170, increasement: 9284575
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([76132])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.771399, mean_loss=0.771487, diff=-0.000088, thres=0.000100
FrameId=57:  cached_time=2.3 ms
  TumDataset->next_frame: Original=307200 -downsample-> 25865, --cropped--> 25864
  Registration->register: reg_points=torch.Size([1102, 6]), translation=tensor([-0.4501, -0.3518,  0.2364], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([25864, 6]) -> sampled_points=torch.Size([129320, 6]) time= 0.99 ms
  LatentFeature->update: samples=129320, new_points=3746 (closreSur>VoxDwn>Radius>Distance), all_points=277172
  TrainingPool->update: Nvs=129320 ->  close_surface_sample_idx=77194, all_points=9541490, increasement: 9412170
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([77194])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.771958, mean_loss=0.772030, diff=-0.000072, thres=0.000100
FrameId=58:  cached_time=2.3 ms
  TumDataset->next_frame: Original=307200 -downsample-> 25118, --cropped--> 25117
  Registration->register: reg_points=torch.Size([1061, 6]), translation=tensor([-0.4551, -0.3616,  0.2307], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([25117, 6]) -> sampled_points=torch.Size([125585, 6]) time= 1.04 ms
  LatentFeature->update: samples=125585, new_points=3582 (closreSur>VoxDwn>Radius>Distance), all_points=280754
  TrainingPool->update: Nvs=125585 ->  close_surface_sample_idx=74910, all_points=9667075, increasement: 9541490
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([74910])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.771059, mean_loss=0.770966, diff=0.000092, thres=0.000100
FrameId=59:  cached_time=2.2 ms
  TumDataset->next_frame: Original=307200 -downsample-> 24689, --cropped--> 24688
  Registration->register: reg_points=torch.Size([1062, 6]), translation=tensor([-0.4553, -0.3881,  0.2328], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([24688, 6]) -> sampled_points=torch.Size([123440, 6]) time= 0.96 ms
  LatentFeature->update: samples=123440, new_points=3530 (closreSur>VoxDwn>Radius>Distance), all_points=284284
  TrainingPool->update: Nvs=123440 ->  close_surface_sample_idx=73657, all_points=9790515, increasement: 9667075
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([73657])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.771230, mean_loss=0.771320, diff=-0.000090, thres=0.000100
FrameId=60:  cached_time=2.3 ms
  TumDataset->next_frame: Original=307200 -downsample-> 24431, --cropped--> 24430
  Registration->register: reg_points=torch.Size([1067, 6]), translation=tensor([-0.4857, -0.4014,  0.2484], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([24430, 6]) -> sampled_points=torch.Size([122150, 6]) time= 0.95 ms
  LatentFeature->update: samples=122150, new_points=3526 (closreSur>VoxDwn>Radius>Distance), all_points=287810
  TrainingPool->update: Nvs=122150 ->  close_surface_sample_idx=72842, all_points=9912665, increasement: 9790515
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([72842])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.771375, mean_loss=0.771382, diff=-0.000007, thres=0.000100
FrameId=61:  cached_time=2.1 ms
  TumDataset->next_frame: Original=307200 -downsample-> 23154, --cropped--> 23153
  Registration->register: reg_points=torch.Size([991, 6]), translation=tensor([-0.4962, -0.4122,  0.2484], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([23153, 6]) -> sampled_points=torch.Size([115765, 6]) time= 0.91 ms
  LatentFeature->update: samples=115765, new_points=3272 (closreSur>VoxDwn>Radius>Distance), all_points=291082
  TrainingPool->update: Nvs=115765 ->  close_surface_sample_idx=68991, all_points=10028430, increasement: 9912665
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([68991])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.770429, mean_loss=0.770526, diff=-0.000096, thres=0.000100
FrameId=62:  cached_time=2.3 ms
  TumDataset->next_frame: Original=307200 -downsample-> 23378, --cropped--> 23377
  Registration->register: reg_points=torch.Size([1019, 6]), translation=tensor([-0.5046, -0.4116,  0.2373], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([23377, 6]) -> sampled_points=torch.Size([116885, 6]) time= 0.99 ms
  LatentFeature->update: samples=116885, new_points=3258 (closreSur>VoxDwn>Radius>Distance), all_points=294340
  TrainingPool->update: Nvs=116885 ->  close_surface_sample_idx=69612, all_points=10145315, increasement: 10028430
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([69612])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.770442, mean_loss=0.770466, diff=-0.000023, thres=0.000100
FrameId=63:  cached_time=2.3 ms
  TumDataset->next_frame: Original=307200 -downsample-> 22885, --cropped--> 22884
  Registration->register: reg_points=torch.Size([1008, 6]), translation=tensor([-0.5061, -0.4219,  0.2372], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([22884, 6]) -> sampled_points=torch.Size([114420, 6]) time= 0.84 ms
  LatentFeature->update: samples=114420, new_points=3228 (closreSur>VoxDwn>Radius>Distance), all_points=297568
  TrainingPool->update: Nvs=114420 ->  close_surface_sample_idx=68333, all_points=10259735, increasement: 10145315
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([68333])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.770357, mean_loss=0.770373, diff=-0.000016, thres=0.000100
FrameId=64:  cached_time=2.2 ms
  TumDataset->next_frame: Original=307200 -downsample-> 23092, --cropped--> 23091
  Registration->register: reg_points=torch.Size([1018, 6]), translation=tensor([-0.4719, -0.4291,  0.2266], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([23091, 6]) -> sampled_points=torch.Size([115455, 6]) time= 0.99 ms
  LatentFeature->update: samples=115455, new_points=3238 (closreSur>VoxDwn>Radius>Distance), all_points=300806
  TrainingPool->update: Nvs=115455 ->  close_surface_sample_idx=68831, all_points=10375190, increasement: 10259735
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([68831])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.769319, mean_loss=0.769290, diff=0.000029, thres=0.000100
FrameId=65:  cached_time=2.3 ms
  TumDataset->next_frame: Original=307200 -downsample-> 23277, --cropped--> 23276
  Registration->register: reg_points=torch.Size([1019, 6]), translation=tensor([-0.4816, -0.4226,  0.2316], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([23276, 6]) -> sampled_points=torch.Size([116380, 6]) time= 0.97 ms
  LatentFeature->update: samples=116380, new_points=3242 (closreSur>VoxDwn>Radius>Distance), all_points=304048
  TrainingPool->update: Nvs=116380 ->  close_surface_sample_idx=69380, all_points=10491570, increasement: 10375190
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([69380])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.768839, mean_loss=0.768936, diff=-0.000096, thres=0.000100
FrameId=66:  cached_time=2.3 ms
  TumDataset->next_frame: Original=307200 -downsample-> 24297, --cropped--> 24296
  Registration->register: reg_points=torch.Size([1069, 6]), translation=tensor([-0.4911, -0.4292,  0.2342], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([24296, 6]) -> sampled_points=torch.Size([121480, 6]) time= 0.93 ms
  LatentFeature->update: samples=121480, new_points=3449 (closreSur>VoxDwn>Radius>Distance), all_points=307497
  TrainingPool->update: Nvs=121480 ->  close_surface_sample_idx=72521, all_points=10613050, increasement: 10491570
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([72521])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.769486, mean_loss=0.769501, diff=-0.000015, thres=0.000100
FrameId=67:  cached_time=2.3 ms
  TumDataset->next_frame: Original=307200 -downsample-> 25584, --cropped--> 25583
  Registration->register: reg_points=torch.Size([1130, 6]), translation=tensor([-0.4699, -0.4430,  0.2299], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([25583, 6]) -> sampled_points=torch.Size([127915, 6]) time= 0.91 ms
  LatentFeature->update: samples=127915, new_points=3598 (closreSur>VoxDwn>Radius>Distance), all_points=311095
  TrainingPool->update: Nvs=127915 ->  close_surface_sample_idx=76376, all_points=10740965, increasement: 10613050
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([76376])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.770217, mean_loss=0.770199, diff=0.000018, thres=0.000100
FrameId=68:  cached_time=3.1 ms
  TumDataset->next_frame: Original=307200 -downsample-> 25834, --cropped--> 25833
  Registration->register: reg_points=torch.Size([1175, 6]), translation=tensor([-0.4539, -0.4437,  0.2318], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([25833, 6]) -> sampled_points=torch.Size([129165, 6]) time= 0.98 ms
  LatentFeature->update: samples=129165, new_points=3702 (closreSur>VoxDwn>Radius>Distance), all_points=314797
  TrainingPool->update: Nvs=129165 ->  close_surface_sample_idx=77106, all_points=10870130, increasement: 10740965
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([77106])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.769415, mean_loss=0.769361, diff=0.000055, thres=0.000100
FrameId=69:  cached_time=2.0 ms
  TumDataset->next_frame: Original=307200 -downsample-> 26583, --cropped--> 26582
  Registration->register: reg_points=torch.Size([1177, 6]), translation=tensor([-0.4722, -0.4547,  0.2514], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([26582, 6]) -> sampled_points=torch.Size([132910, 6]) time= 1.01 ms
  LatentFeature->update: samples=132910, new_points=3771 (closreSur>VoxDwn>Radius>Distance), all_points=318568
  TrainingPool->update: Nvs=132910 ->  close_surface_sample_idx=79309, all_points=11003040, increasement: 10870130
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([79309])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.769179, mean_loss=0.769268, diff=-0.000089, thres=0.000100
FrameId=70:  cached_time=2.2 ms
  TumDataset->next_frame: Original=307200 -downsample-> 27259, --cropped--> 27258
  Registration->register: reg_points=torch.Size([1198, 6]), translation=tensor([-0.4580, -0.4643,  0.2434], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([27258, 6]) -> sampled_points=torch.Size([136290, 6]) time= 0.93 ms
  LatentFeature->update: samples=136290, new_points=3890 (closreSur>VoxDwn>Radius>Distance), all_points=322458
  TrainingPool->update: Nvs=136290 ->  close_surface_sample_idx=81264, all_points=11139330, increasement: 11003040
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([81264])
  TrainingPool->train: break at iter=54, cur_mean_loss=0.767985, mean_loss=0.768042, diff=-0.000057, thres=0.000100
FrameId=71:  cached_time=2.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 27348, --cropped--> 27347
  Registration->register: reg_points=torch.Size([1223, 6]), translation=tensor([-0.4729, -0.4562,  0.2581], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([27347, 6]) -> sampled_points=torch.Size([136735, 6]) time= 0.90 ms
  LatentFeature->update: samples=136735, new_points=3975 (closreSur>VoxDwn>Radius>Distance), all_points=326433
  TrainingPool->update: Nvs=136735 ->  close_surface_sample_idx=81563, all_points=11276065, increasement: 11139330
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([81563])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.769979, mean_loss=0.770052, diff=-0.000073, thres=0.000100
FrameId=72:  cached_time=2.1 ms
  TumDataset->next_frame: Original=307200 -downsample-> 27115, --cropped--> 27114
  Registration->register: reg_points=torch.Size([1187, 6]), translation=tensor([-0.4994, -0.4748,  0.2875], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([27114, 6]) -> sampled_points=torch.Size([135570, 6]) time= 0.94 ms
  LatentFeature->update: samples=135570, new_points=3872 (closreSur>VoxDwn>Radius>Distance), all_points=330305
  TrainingPool->update: Nvs=135570 ->  close_surface_sample_idx=80766, all_points=11411635, increasement: 11276065
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([80766])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.767728, mean_loss=0.767812, diff=-0.000084, thres=0.000100
FrameId=73:  cached_time=2.0 ms
  TumDataset->next_frame: Original=307200 -downsample-> 28011, --cropped--> 28010
  Registration->register: reg_points=torch.Size([1250, 6]), translation=tensor([-0.5001, -0.4750,  0.2890], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([28010, 6]) -> sampled_points=torch.Size([140050, 6]) time= 0.95 ms
  LatentFeature->update: samples=140050, new_points=4075 (closreSur>VoxDwn>Radius>Distance), all_points=334380
  TrainingPool->update: Nvs=140050 ->  close_surface_sample_idx=83621, all_points=11551685, increasement: 11411635
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([83621])
  TrainingPool->train: break at iter=55, cur_mean_loss=0.767989, mean_loss=0.768028, diff=-0.000039, thres=0.000100
FrameId=74:  cached_time=2.0 ms
  TumDataset->next_frame: Original=307200 -downsample-> 28625, --cropped--> 28624
  Registration->register: reg_points=torch.Size([1254, 6]), translation=tensor([-0.4891, -0.4849,  0.2929], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([28624, 6]) -> sampled_points=torch.Size([143120, 6]) time= 0.95 ms
  LatentFeature->update: samples=143120, new_points=4203 (closreSur>VoxDwn>Radius>Distance), all_points=338583
  TrainingPool->update: Nvs=143120 ->  close_surface_sample_idx=85394, all_points=11694805, increasement: 11551685
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([85394])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.768374, mean_loss=0.768423, diff=-0.000049, thres=0.000100
FrameId=75:  cached_time=2.1 ms
  TumDataset->next_frame: Original=307200 -downsample-> 28770, --cropped--> 28769
  Registration->register: reg_points=torch.Size([1244, 6]), translation=tensor([-0.4990, -0.4965,  0.3121], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([28769, 6]) -> sampled_points=torch.Size([143845, 6]) time= 1.08 ms
  LatentFeature->update: samples=143845, new_points=4170 (closreSur>VoxDwn>Radius>Distance), all_points=342753
  TrainingPool->update: Nvs=143845 ->  close_surface_sample_idx=85735, all_points=11838650, increasement: 11694805
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([85735])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.766702, mean_loss=0.766724, diff=-0.000022, thres=0.000100
FrameId=76:  cached_time=2.1 ms
  TumDataset->next_frame: Original=307200 -downsample-> 29466, --cropped--> 29465
  Registration->register: reg_points=torch.Size([1292, 6]), translation=tensor([-0.5109, -0.4877,  0.3235], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([29465, 6]) -> sampled_points=torch.Size([147325, 6]) time= 1.01 ms
  LatentFeature->update: samples=147325, new_points=4290 (closreSur>VoxDwn>Radius>Distance), all_points=347043
  TrainingPool->update: Nvs=147325 ->  close_surface_sample_idx=87758, all_points=11985975, increasement: 11838650
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([87758])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.766382, mean_loss=0.766418, diff=-0.000036, thres=0.000100
FrameId=77:  cached_time=2.0 ms
  TumDataset->next_frame: Original=307200 -downsample-> 29679, --cropped--> 29678
  Registration->register: reg_points=torch.Size([1284, 6]), translation=tensor([-0.5131, -0.4730,  0.3411], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([29678, 6]) -> sampled_points=torch.Size([148390, 6]) time= 0.82 ms
  LatentFeature->update: samples=148390, new_points=4268 (closreSur>VoxDwn>Radius>Distance), all_points=351311
  TrainingPool->update: Nvs=148390 ->  close_surface_sample_idx=88471, all_points=12134365, increasement: 11985975
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([88471])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.766620, mean_loss=0.766648, diff=-0.000028, thres=0.000100
FrameId=78:  cached_time=2.1 ms
  TumDataset->next_frame: Original=307200 -downsample-> 29875, --cropped--> 29874
  Registration->register: reg_points=torch.Size([1311, 6]), translation=tensor([-0.5263, -0.4683,  0.3470], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([29874, 6]) -> sampled_points=torch.Size([149370, 6]) time= 0.97 ms
  LatentFeature->update: samples=149370, new_points=4415 (closreSur>VoxDwn>Radius>Distance), all_points=355726
  TrainingPool->update: Nvs=149370 ->  close_surface_sample_idx=89100, all_points=12283735, increasement: 12134365
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([89100])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.766946, mean_loss=0.766887, diff=0.000059, thres=0.000100
FrameId=79:  cached_time=2.1 ms
  TumDataset->next_frame: Original=307200 -downsample-> 29716, --cropped--> 29715
  Registration->register: reg_points=torch.Size([1315, 6]), translation=tensor([-0.5319, -0.4507,  0.3648], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([29715, 6]) -> sampled_points=torch.Size([148575, 6]) time= 0.96 ms
  LatentFeature->update: samples=148575, new_points=4347 (closreSur>VoxDwn>Radius>Distance), all_points=360073
  TrainingPool->update: Nvs=148575 ->  close_surface_sample_idx=88515, all_points=12432310, increasement: 12283735
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([88515])
  TrainingPool->train: break at iter=55, cur_mean_loss=0.764643, mean_loss=0.764732, diff=-0.000090, thres=0.000100
FrameId=80:  cached_time=2.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 30025, --cropped--> 30024
  Registration->register: reg_points=torch.Size([1318, 6]), translation=tensor([-0.5317, -0.4569,  0.3668], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([30024, 6]) -> sampled_points=torch.Size([150120, 6]) time= 0.94 ms
  LatentFeature->update: samples=150120, new_points=4303 (closreSur>VoxDwn>Radius>Distance), all_points=364376
  TrainingPool->update: Nvs=150120 ->  close_surface_sample_idx=89561, all_points=12582430, increasement: 12432310
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([89561])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.766188, mean_loss=0.766126, diff=0.000062, thres=0.000100
FrameId=81:  cached_time=5.6 ms
  TumDataset->next_frame: Original=307200 -downsample-> 29232, --cropped--> 29231
  Registration->register: reg_points=torch.Size([1262, 6]), translation=tensor([-0.5394, -0.4668,  0.3680], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([29231, 6]) -> sampled_points=torch.Size([146155, 6]) time= 0.93 ms
  LatentFeature->update: samples=146155, new_points=4194 (closreSur>VoxDwn>Radius>Distance), all_points=368570
  TrainingPool->update: Nvs=146155 ->  close_surface_sample_idx=87209, all_points=12728585, increasement: 12582430
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([87209])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.765153, mean_loss=0.765143, diff=0.000010, thres=0.000100
FrameId=82:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 28482, --cropped--> 28481
  Registration->register: reg_points=torch.Size([1221, 6]), translation=tensor([-0.5551, -0.4630,  0.3802], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([28481, 6]) -> sampled_points=torch.Size([142405, 6]) time= 0.99 ms
  LatentFeature->update: samples=142405, new_points=3966 (closreSur>VoxDwn>Radius>Distance), all_points=372536
  TrainingPool->update: Nvs=142405 ->  close_surface_sample_idx=84835, all_points=12870990, increasement: 12728585
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([84835])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.765198, mean_loss=0.765253, diff=-0.000054, thres=0.000100
FrameId=83:  cached_time=2.0 ms
  TumDataset->next_frame: Original=307200 -downsample-> 27924, --cropped--> 27923
  Registration->register: reg_points=torch.Size([1190, 6]), translation=tensor([-0.5688, -0.4562,  0.3884], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([27923, 6]) -> sampled_points=torch.Size([139615, 6]) time= 0.81 ms
  LatentFeature->update: samples=139615, new_points=3922 (closreSur>VoxDwn>Radius>Distance), all_points=376458
  TrainingPool->update: Nvs=139615 ->  close_surface_sample_idx=83196, all_points=13010605, increasement: 12870990
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([83196])
  TrainingPool->train: break at iter=55, cur_mean_loss=0.764649, mean_loss=0.764712, diff=-0.000064, thres=0.000100
FrameId=84:  cached_time=2.0 ms
  TumDataset->next_frame: Original=307200 -downsample-> 28618, --cropped--> 28617
  Registration->register: reg_points=torch.Size([1209, 6]), translation=tensor([-0.5776, -0.4643,  0.3977], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([28617, 6]) -> sampled_points=torch.Size([143085, 6]) time= 0.98 ms
  LatentFeature->update: samples=143085, new_points=3983 (closreSur>VoxDwn>Radius>Distance), all_points=380441
  TrainingPool->update: Nvs=143085 ->  close_surface_sample_idx=85333, all_points=13153690, increasement: 13010605
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([85333])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.765247, mean_loss=0.765269, diff=-0.000022, thres=0.000100
FrameId=85:  cached_time=2.1 ms
  TumDataset->next_frame: Original=307200 -downsample-> 28794, --cropped--> 28793
  Registration->register: reg_points=torch.Size([1224, 6]), translation=tensor([-0.5799, -0.4398,  0.4024], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([28793, 6]) -> sampled_points=torch.Size([143965, 6]) time= 0.96 ms
  LatentFeature->update: samples=143965, new_points=4003 (closreSur>VoxDwn>Radius>Distance), all_points=384444
  TrainingPool->update: Nvs=143965 ->  close_surface_sample_idx=85979, all_points=13297655, increasement: 13153690
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([85979])
  TrainingPool->train: break at iter=55, cur_mean_loss=0.764526, mean_loss=0.764557, diff=-0.000031, thres=0.000100
FrameId=86:  cached_time=2.0 ms
  TumDataset->next_frame: Original=307200 -downsample-> 28947, --cropped--> 28946
  Registration->register: reg_points=torch.Size([1223, 6]), translation=tensor([-0.5027, -0.4526,  0.3950], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([28946, 6]) -> sampled_points=torch.Size([144730, 6]) time= 0.97 ms
  LatentFeature->update: samples=144730, new_points=4026 (closreSur>VoxDwn>Radius>Distance), all_points=388470
  TrainingPool->update: Nvs=144730 ->  close_surface_sample_idx=86411, all_points=13442385, increasement: 13297655
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([86411])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.764850, mean_loss=0.764927, diff=-0.000076, thres=0.000100
FrameId=87:  cached_time=2.0 ms
  TumDataset->next_frame: Original=307200 -downsample-> 28377, --cropped--> 28376
  Registration->register: reg_points=torch.Size([1196, 6]), translation=tensor([-0.5079, -0.4473,  0.3927], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([28376, 6]) -> sampled_points=torch.Size([141880, 6]) time= 0.98 ms
  LatentFeature->update: samples=141880, new_points=3911 (closreSur>VoxDwn>Radius>Distance), all_points=392381
  TrainingPool->update: Nvs=141880 ->  close_surface_sample_idx=84505, all_points=13584265, increasement: 13442385
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([84505])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.762999, mean_loss=0.763040, diff=-0.000041, thres=0.000100
FrameId=88:  cached_time=2.1 ms
  TumDataset->next_frame: Original=307200 -downsample-> 27959, --cropped--> 27958
  Registration->register: reg_points=torch.Size([1123, 6]), translation=tensor([-0.5226, -0.4548,  0.3982], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([27958, 6]) -> sampled_points=torch.Size([139790, 6]) time= 0.93 ms
  LatentFeature->update: samples=139790, new_points=3756 (closreSur>VoxDwn>Radius>Distance), all_points=396137
  TrainingPool->update: Nvs=139790 ->  close_surface_sample_idx=83397, all_points=13724055, increasement: 13584265
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([83397])
  TrainingPool->train: break at iter=55, cur_mean_loss=0.763570, mean_loss=0.763662, diff=-0.000092, thres=0.000100
FrameId=89:  cached_time=2.0 ms
  TumDataset->next_frame: Original=307200 -downsample-> 27818, --cropped--> 27817
  Registration->register: reg_points=torch.Size([1139, 6]), translation=tensor([-0.5313, -0.4499,  0.3975], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([27817, 6]) -> sampled_points=torch.Size([139085, 6]) time= 0.98 ms
  LatentFeature->update: samples=139085, new_points=3736 (closreSur>VoxDwn>Radius>Distance), all_points=399873
  TrainingPool->update: Nvs=139085 ->  close_surface_sample_idx=82874, all_points=13863140, increasement: 13724055
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([82874])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.761499, mean_loss=0.761525, diff=-0.000026, thres=0.000100
FrameId=90:  cached_time=2.1 ms
  TumDataset->next_frame: Original=307200 -downsample-> 27594, --cropped--> 27593
  Registration->register: reg_points=torch.Size([1119, 6]), translation=tensor([-0.5245, -0.4344,  0.3986], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([27593, 6]) -> sampled_points=torch.Size([137965, 6]) time= 0.95 ms
  LatentFeature->update: samples=137965, new_points=3701 (closreSur>VoxDwn>Radius>Distance), all_points=403574
  TrainingPool->update: Nvs=137965 ->  close_surface_sample_idx=82233, all_points=14001105, increasement: 13863140
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([82233])
  TrainingPool->train: break at iter=54, cur_mean_loss=0.761854, mean_loss=0.761902, diff=-0.000049, thres=0.000100
FrameId=91:  cached_time=2.1 ms
  TumDataset->next_frame: Original=307200 -downsample-> 27148, --cropped--> 27147
  Registration->register: reg_points=torch.Size([1055, 6]), translation=tensor([-0.5580, -0.4448,  0.4066], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([27147, 6]) -> sampled_points=torch.Size([135735, 6]) time= 0.98 ms
  LatentFeature->update: samples=135735, new_points=3581 (closreSur>VoxDwn>Radius>Distance), all_points=407155
  TrainingPool->update: Nvs=135735 ->  close_surface_sample_idx=80964, all_points=14136840, increasement: 14001105
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([80964])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.762544, mean_loss=0.762597, diff=-0.000053, thres=0.000100
FrameId=92:  cached_time=2.1 ms
  TumDataset->next_frame: Original=307200 -downsample-> 27144, --cropped--> 27143
  Registration->register: reg_points=torch.Size([1070, 6]), translation=tensor([-0.5867, -0.4279,  0.4136], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([27143, 6]) -> sampled_points=torch.Size([135715, 6]) time= 0.85 ms
  LatentFeature->update: samples=135715, new_points=3586 (closreSur>VoxDwn>Radius>Distance), all_points=410741
  TrainingPool->update: Nvs=135715 ->  close_surface_sample_idx=81006, all_points=14272555, increasement: 14136840
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([81006])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.762177, mean_loss=0.762250, diff=-0.000073, thres=0.000100
FrameId=93:  cached_time=2.1 ms
  TumDataset->next_frame: Original=307200 -downsample-> 27057, --cropped--> 27056
  Registration->register: reg_points=torch.Size([1117, 6]), translation=tensor([-0.5935, -0.4484,  0.4066], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([27056, 6]) -> sampled_points=torch.Size([135280, 6]) time= 0.93 ms
  LatentFeature->update: samples=135280, new_points=3652 (closreSur>VoxDwn>Radius>Distance), all_points=414393
  TrainingPool->update: Nvs=135280 ->  close_surface_sample_idx=80652, all_points=14407835, increasement: 14272555
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([80652])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.761728, mean_loss=0.761647, diff=0.000081, thres=0.000100
FrameId=94:  cached_time=2.3 ms
  TumDataset->next_frame: Original=307200 -downsample-> 26682, --cropped--> 26681
  Registration->register: reg_points=torch.Size([1079, 6]), translation=tensor([-0.5851, -0.4514,  0.4067], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([26681, 6]) -> sampled_points=torch.Size([133405, 6]) time= 0.94 ms
  LatentFeature->update: samples=133405, new_points=3548 (closreSur>VoxDwn>Radius>Distance), all_points=417941
  TrainingPool->update: Nvs=133405 ->  close_surface_sample_idx=79380, all_points=14541240, increasement: 14407835
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([79380])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.761888, mean_loss=0.761927, diff=-0.000040, thres=0.000100
FrameId=95:  cached_time=2.0 ms
  TumDataset->next_frame: Original=307200 -downsample-> 25841, --cropped--> 25840
  Registration->register: reg_points=torch.Size([1047, 6]), translation=tensor([-0.5881, -0.4481,  0.3873], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([25840, 6]) -> sampled_points=torch.Size([129200, 6]) time= 0.98 ms
  LatentFeature->update: samples=129200, new_points=3427 (closreSur>VoxDwn>Radius>Distance), all_points=421368
  TrainingPool->update: Nvs=129200 ->  close_surface_sample_idx=76882, all_points=14670440, increasement: 14541240
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([76882])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.761705, mean_loss=0.761788, diff=-0.000082, thres=0.000100
FrameId=96:  cached_time=2.0 ms
  TumDataset->next_frame: Original=307200 -downsample-> 25294, --cropped--> 25293
  Registration->register: reg_points=torch.Size([1009, 6]), translation=tensor([-0.6107, -0.4437,  0.3881], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([25293, 6]) -> sampled_points=torch.Size([126465, 6]) time= 0.96 ms
  LatentFeature->update: samples=126465, new_points=3390 (closreSur>VoxDwn>Radius>Distance), all_points=424758
  TrainingPool->update: Nvs=126465 ->  close_surface_sample_idx=75422, all_points=14796905, increasement: 14670440
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([75422])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.762102, mean_loss=0.762177, diff=-0.000075, thres=0.000100
FrameId=97:  cached_time=2.0 ms
  TumDataset->next_frame: Original=307200 -downsample-> 25044, --cropped--> 25043
  Registration->register: reg_points=torch.Size([1000, 6]), translation=tensor([-0.6175, -0.4483,  0.3792], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([25043, 6]) -> sampled_points=torch.Size([125215, 6]) time= 1.02 ms
  LatentFeature->update: samples=125215, new_points=3330 (closreSur>VoxDwn>Radius>Distance), all_points=428088
  TrainingPool->update: Nvs=125215 ->  close_surface_sample_idx=74548, all_points=14922120, increasement: 14796905
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([74548])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.761102, mean_loss=0.761025, diff=0.000077, thres=0.000100
FrameId=98:  cached_time=2.0 ms
  TumDataset->next_frame: Original=307200 -downsample-> 24279, --cropped--> 24278
  Registration->register: reg_points=torch.Size([994, 6]), translation=tensor([-0.6391, -0.4536,  0.3715], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([24278, 6]) -> sampled_points=torch.Size([121390, 6]) time= 0.99 ms
  LatentFeature->update: samples=121390, new_points=3174 (closreSur>VoxDwn>Radius>Distance), all_points=431262
  TrainingPool->update: Nvs=121390 ->  close_surface_sample_idx=72399, all_points=15043510, increasement: 14922120
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([72399])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.761034, mean_loss=0.761102, diff=-0.000067, thres=0.000100
FrameId=99:  cached_time=2.0 ms
  TumDataset->next_frame: Original=307200 -downsample-> 23206, --cropped--> 23205
  Registration->register: reg_points=torch.Size([938, 6]), translation=tensor([-0.6464, -0.4728,  0.3649], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([23205, 6]) -> sampled_points=torch.Size([116025, 6]) time= 0.86 ms
  LatentFeature->update: samples=116025, new_points=3053 (closreSur>VoxDwn>Radius>Distance), all_points=434315
  TrainingPool->update: Nvs=116025 ->  close_surface_sample_idx=69129, all_points=15159535, increasement: 15043510
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([69129])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.761483, mean_loss=0.761387, diff=0.000096, thres=0.000100
FrameId=100:  cached_time=2.0 ms
  TumDataset->next_frame: Original=307200 -downsample-> 22496, --cropped--> 22495
  Registration->register: reg_points=torch.Size([905, 6]), translation=tensor([-0.6828, -0.4603,  0.3569], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([22495, 6]) -> sampled_points=torch.Size([112475, 6]) time= 0.86 ms
  LatentFeature->update: samples=112475, new_points=2961 (closreSur>VoxDwn>Radius>Distance), all_points=437276
  TrainingPool->update: Nvs=112475 ->  close_surface_sample_idx=66998, all_points=15272010, increasement: 15159535
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([66998])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.759767, mean_loss=0.759717, diff=0.000049, thres=0.000100
FrameId=101:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 22215, --cropped--> 22214
  Registration->register: reg_points=torch.Size([872, 6]), translation=tensor([-0.7212, -0.4616,  0.3589], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([22214, 6]) -> sampled_points=torch.Size([111070, 6]) time= 0.96 ms
  LatentFeature->update: samples=111070, new_points=2899 (closreSur>VoxDwn>Radius>Distance), all_points=440175
  TrainingPool->update: Nvs=111070 ->  close_surface_sample_idx=66011, all_points=15383080, increasement: 15272010
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([66011])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.760336, mean_loss=0.760365, diff=-0.000029, thres=0.000100
FrameId=102:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 21488, --cropped--> 21487
  Registration->register: reg_points=torch.Size([841, 6]), translation=tensor([-0.7291, -0.4623,  0.3499], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([21487, 6]) -> sampled_points=torch.Size([107435, 6]) time= 0.76 ms
  LatentFeature->update: samples=107435, new_points=2803 (closreSur>VoxDwn>Radius>Distance), all_points=442978
  TrainingPool->update: Nvs=107435 ->  close_surface_sample_idx=64081, all_points=15490515, increasement: 15383080
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([64081])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.760499, mean_loss=0.760536, diff=-0.000037, thres=0.000100
FrameId=103:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 21519, --cropped--> 21518
  Registration->register: reg_points=torch.Size([860, 6]), translation=tensor([-0.7926, -0.4601,  0.3547], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([21518, 6]) -> sampled_points=torch.Size([107590, 6]) time= 0.92 ms
  LatentFeature->update: samples=107590, new_points=2773 (closreSur>VoxDwn>Radius>Distance), all_points=445751
  TrainingPool->update: Nvs=107590 ->  close_surface_sample_idx=63926, all_points=15598105, increasement: 15490515
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([63926])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.760222, mean_loss=0.760322, diff=-0.000100, thres=0.000100
FrameId=104:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 21323, --cropped--> 21322
  Registration->register: reg_points=torch.Size([859, 6]), translation=tensor([-0.7895, -0.4514,  0.3474], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([21322, 6]) -> sampled_points=torch.Size([106610, 6]) time= 0.88 ms
  LatentFeature->update: samples=106610, new_points=2751 (closreSur>VoxDwn>Radius>Distance), all_points=448502
  TrainingPool->update: Nvs=106610 ->  close_surface_sample_idx=63439, all_points=15704715, increasement: 15598105
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([63439])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.760008, mean_loss=0.759922, diff=0.000086, thres=0.000100
FrameId=105:  cached_time=2.0 ms
  TumDataset->next_frame: Original=307200 -downsample-> 20281, --cropped--> 20280
  Registration->register: reg_points=torch.Size([805, 6]), translation=tensor([-0.7882, -0.4679,  0.3322], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([20280, 6]) -> sampled_points=torch.Size([101400, 6]) time= 0.90 ms
  LatentFeature->update: samples=101400, new_points=2588 (closreSur>VoxDwn>Radius>Distance), all_points=451090
  TrainingPool->update: Nvs=101400 ->  close_surface_sample_idx=60386, all_points=15806115, increasement: 15704715
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([60386])
  TrainingPool->train: break at iter=56, cur_mean_loss=0.760235, mean_loss=0.760320, diff=-0.000085, thres=0.000100
FrameId=106:  cached_time=2.0 ms
  TumDataset->next_frame: Original=307200 -downsample-> 19899, --cropped--> 19898
  Registration->register: reg_points=torch.Size([795, 6]), translation=tensor([-0.7911, -0.4886,  0.3244], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([19898, 6]) -> sampled_points=torch.Size([99490, 6]) time= 0.97 ms
  LatentFeature->update: samples=99490, new_points=2596 (closreSur>VoxDwn>Radius>Distance), all_points=453686
  TrainingPool->update: Nvs=99490 ->  close_surface_sample_idx=59296, all_points=15905605, increasement: 15806115
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([59296])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.759918, mean_loss=0.759883, diff=0.000035, thres=0.000100
FrameId=107:  cached_time=2.0 ms
  TumDataset->next_frame: Original=307200 -downsample-> 19731, --cropped--> 19730
  Registration->register: reg_points=torch.Size([769, 6]), translation=tensor([-0.8224, -0.4700,  0.3175], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([19730, 6]) -> sampled_points=torch.Size([98650, 6]) time= 0.82 ms
  LatentFeature->update: samples=98650, new_points=2563 (closreSur>VoxDwn>Radius>Distance), all_points=456249
  TrainingPool->update: Nvs=98650 ->  close_surface_sample_idx=58742, all_points=16004255, increasement: 15905605
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([58742])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.759280, mean_loss=0.759368, diff=-0.000088, thres=0.000100
FrameId=108:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 19264, --cropped--> 19263
  Registration->register: reg_points=torch.Size([775, 6]), translation=tensor([-0.8345, -0.4494,  0.3079], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([19263, 6]) -> sampled_points=torch.Size([96315, 6]) time= 0.85 ms
  LatentFeature->update: samples=96315, new_points=2505 (closreSur>VoxDwn>Radius>Distance), all_points=458754
  TrainingPool->update: Nvs=96315 ->  close_surface_sample_idx=57305, all_points=16100570, increasement: 16004255
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([57305])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.759774, mean_loss=0.759719, diff=0.000056, thres=0.000100
FrameId=109:  cached_time=3.0 ms
  TumDataset->next_frame: Original=307200 -downsample-> 18375, --cropped--> 18374
  Registration->register: reg_points=torch.Size([736, 6]), translation=tensor([-0.8320, -0.4724,  0.2987], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([18374, 6]) -> sampled_points=torch.Size([91870, 6]) time= 0.94 ms
  LatentFeature->update: samples=91870, new_points=2341 (closreSur>VoxDwn>Radius>Distance), all_points=461095
  TrainingPool->update: Nvs=91870 ->  close_surface_sample_idx=54650, all_points=16192440, increasement: 16100570
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([54650])
  TrainingPool->train: break at iter=55, cur_mean_loss=0.760563, mean_loss=0.760515, diff=0.000047, thres=0.000100
FrameId=110:  cached_time=2.1 ms
  TumDataset->next_frame: Original=307200 -downsample-> 18081, --cropped--> 18080
  Registration->register: reg_points=torch.Size([738, 6]), translation=tensor([-0.8313, -0.4722,  0.2828], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([18080, 6]) -> sampled_points=torch.Size([90400, 6]) time= 0.94 ms
  LatentFeature->update: samples=90400, new_points=2368 (closreSur>VoxDwn>Radius>Distance), all_points=463463
  TrainingPool->update: Nvs=90400 ->  close_surface_sample_idx=53890, all_points=16282840, increasement: 16192440
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([53890])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.759716, mean_loss=0.759777, diff=-0.000061, thres=0.000100
FrameId=111:  cached_time=2.0 ms
  TumDataset->next_frame: Original=307200 -downsample-> 17883, --cropped--> 17882
  Registration->register: reg_points=torch.Size([729, 6]), translation=tensor([-0.8393, -0.4724,  0.2804], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([17882, 6]) -> sampled_points=torch.Size([89410, 6]) time= 0.93 ms
  LatentFeature->update: samples=89410, new_points=2308 (closreSur>VoxDwn>Radius>Distance), all_points=465771
  TrainingPool->update: Nvs=89410 ->  close_surface_sample_idx=53229, all_points=16372250, increasement: 16282840
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([53229])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.760991, mean_loss=0.761052, diff=-0.000061, thres=0.000100
FrameId=112:  cached_time=2.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 16975, --cropped--> 16974
  Registration->register: reg_points=torch.Size([668, 6]), translation=tensor([-0.8609, -0.4823,  0.2849], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([16974, 6]) -> sampled_points=torch.Size([84870, 6]) time= 0.91 ms
  LatentFeature->update: samples=84870, new_points=2186 (closreSur>VoxDwn>Radius>Distance), all_points=467957
  TrainingPool->update: Nvs=84870 ->  close_surface_sample_idx=50550, all_points=16457120, increasement: 16372250
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([50550])
  TrainingPool->train: break at iter=54, cur_mean_loss=0.759458, mean_loss=0.759511, diff=-0.000052, thres=0.000100
FrameId=113:  cached_time=2.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 16817, --cropped--> 16816
  Registration->register: reg_points=torch.Size([656, 6]), translation=tensor([-0.8691, -0.4529,  0.2784], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([16816, 6]) -> sampled_points=torch.Size([84080, 6]) time= 1.02 ms
  LatentFeature->update: samples=84080, new_points=2148 (closreSur>VoxDwn>Radius>Distance), all_points=470105
  TrainingPool->update: Nvs=84080 ->  close_surface_sample_idx=50036, all_points=16541200, increasement: 16457120
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([50036])
  TrainingPool->train: break at iter=56, cur_mean_loss=0.758869, mean_loss=0.758865, diff=0.000004, thres=0.000100
FrameId=114:  cached_time=2.0 ms
  TumDataset->next_frame: Original=307200 -downsample-> 17006, --cropped--> 17005
  Registration->register: reg_points=torch.Size([665, 6]), translation=tensor([-0.9018, -0.4426,  0.2819], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([17005, 6]) -> sampled_points=torch.Size([85025, 6]) time= 0.92 ms
  LatentFeature->update: samples=85025, new_points=2159 (closreSur>VoxDwn>Radius>Distance), all_points=472264
  TrainingPool->update: Nvs=85025 ->  close_surface_sample_idx=50601, all_points=16626225, increasement: 16541200
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([50601])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.759047, mean_loss=0.758954, diff=0.000093, thres=0.000100
FrameId=115:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 17356, --cropped--> 17355
  Registration->register: reg_points=torch.Size([679, 6]), translation=tensor([-0.9285, -0.4590,  0.2854], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([17355, 6]) -> sampled_points=torch.Size([86775, 6]) time= 0.93 ms
  LatentFeature->update: samples=86775, new_points=2205 (closreSur>VoxDwn>Radius>Distance), all_points=474469
  TrainingPool->update: Nvs=86775 ->  close_surface_sample_idx=51725, all_points=16713000, increasement: 16626225
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([51725])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.758410, mean_loss=0.758414, diff=-0.000005, thres=0.000100
FrameId=116:  cached_time=3.0 ms
  TumDataset->next_frame: Original=307200 -downsample-> 17355, --cropped--> 17354
  Registration->register: reg_points=torch.Size([679, 6]), translation=tensor([-0.9345, -0.4520,  0.2879], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([17354, 6]) -> sampled_points=torch.Size([86770, 6]) time= 0.94 ms
  LatentFeature->update: samples=86770, new_points=2198 (closreSur>VoxDwn>Radius>Distance), all_points=476667
  TrainingPool->update: Nvs=86770 ->  close_surface_sample_idx=51611, all_points=16799770, increasement: 16713000
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([51611])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.759281, mean_loss=0.759309, diff=-0.000027, thres=0.000100
FrameId=117:  cached_time=3.0 ms
  TumDataset->next_frame: Original=307200 -downsample-> 17346, --cropped--> 17345
  Registration->register: reg_points=torch.Size([687, 6]), translation=tensor([-0.9490, -0.4568,  0.3008], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([17345, 6]) -> sampled_points=torch.Size([86725, 6]) time= 0.81 ms
  LatentFeature->update: samples=86725, new_points=2176 (closreSur>VoxDwn>Radius>Distance), all_points=478843
  TrainingPool->update: Nvs=86725 ->  close_surface_sample_idx=51626, all_points=16886495, increasement: 16799770
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([51626])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.759280, mean_loss=0.759326, diff=-0.000045, thres=0.000100
FrameId=118:  cached_time=3.0 ms
  TumDataset->next_frame: Original=307200 -downsample-> 18143, --cropped--> 18142
  Registration->register: reg_points=torch.Size([665, 6]), translation=tensor([-0.9801, -0.4456,  0.3103], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([18142, 6]) -> sampled_points=torch.Size([90710, 6]) time= 0.83 ms
  LatentFeature->update: samples=90710, new_points=2270 (closreSur>VoxDwn>Radius>Distance), all_points=481113
  TrainingPool->update: Nvs=90710 ->  close_surface_sample_idx=53881, all_points=16977205, increasement: 16886495
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([53881])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.759511, mean_loss=0.759517, diff=-0.000006, thres=0.000100
FrameId=119:  cached_time=2.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 18966, --cropped--> 18965
  Registration->register: reg_points=torch.Size([708, 6]), translation=tensor([-0.9723, -0.4359,  0.3144], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([18965, 6]) -> sampled_points=torch.Size([94825, 6]) time= 0.95 ms
  LatentFeature->update: samples=94825, new_points=2397 (closreSur>VoxDwn>Radius>Distance), all_points=483510
  TrainingPool->update: Nvs=94825 ->  close_surface_sample_idx=56435, all_points=17072030, increasement: 16977205
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([56435])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.758670, mean_loss=0.758642, diff=0.000028, thres=0.000100
FrameId=120:  cached_time=2.0 ms
  TumDataset->next_frame: Original=307200 -downsample-> 19253, --cropped--> 19252
  Registration->register: reg_points=torch.Size([738, 6]), translation=tensor([-1.0080, -0.4303,  0.3338], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([19252, 6]) -> sampled_points=torch.Size([96260, 6]) time= 0.91 ms
  LatentFeature->update: samples=96260, new_points=2418 (closreSur>VoxDwn>Radius>Distance), all_points=485928
  TrainingPool->update: Nvs=96260 ->  close_surface_sample_idx=57135, all_points=17168290, increasement: 17072030
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([57135])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.759249, mean_loss=0.759336, diff=-0.000087, thres=0.000100
FrameId=121:  cached_time=2.0 ms
  TumDataset->next_frame: Original=307200 -downsample-> 20002, --cropped--> 20001
  Registration->register: reg_points=torch.Size([774, 6]), translation=tensor([-1.0324, -0.4346,  0.3476], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([20001, 6]) -> sampled_points=torch.Size([100005, 6]) time= 0.95 ms
  LatentFeature->update: samples=100005, new_points=2542 (closreSur>VoxDwn>Radius>Distance), all_points=488470
  TrainingPool->update: Nvs=100005 ->  close_surface_sample_idx=59608, all_points=17268295, increasement: 17168290
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([59608])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.758567, mean_loss=0.758665, diff=-0.000098, thres=0.000100
FrameId=122:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 20547, --cropped--> 20546
  Registration->register: reg_points=torch.Size([780, 6]), translation=tensor([-1.0270, -0.4251,  0.3553], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([20546, 6]) -> sampled_points=torch.Size([102730, 6]) time= 0.84 ms
  LatentFeature->update: samples=102730, new_points=2649 (closreSur>VoxDwn>Radius>Distance), all_points=491119
  TrainingPool->update: Nvs=102730 ->  close_surface_sample_idx=61254, all_points=17371025, increasement: 17268295
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([61254])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.758696, mean_loss=0.758649, diff=0.000047, thres=0.000100
FrameId=123:  cached_time=2.1 ms
  TumDataset->next_frame: Original=307200 -downsample-> 20915, --cropped--> 20914
  Registration->register: reg_points=torch.Size([812, 6]), translation=tensor([-1.0219, -0.4387,  0.3640], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([20914, 6]) -> sampled_points=torch.Size([104570, 6]) time= 0.96 ms
  LatentFeature->update: samples=104570, new_points=2720 (closreSur>VoxDwn>Radius>Distance), all_points=493839
  TrainingPool->update: Nvs=104570 ->  close_surface_sample_idx=62253, all_points=17475595, increasement: 17371025
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([62253])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.759015, mean_loss=0.758965, diff=0.000050, thres=0.000100
FrameId=124:  cached_time=2.0 ms
  TumDataset->next_frame: Original=307200 -downsample-> 21897, --cropped--> 21896
  Registration->register: reg_points=torch.Size([846, 6]), translation=tensor([-1.0394, -0.4432,  0.3752], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([21896, 6]) -> sampled_points=torch.Size([109480, 6]) time= 0.90 ms
  LatentFeature->update: samples=109480, new_points=2799 (closreSur>VoxDwn>Radius>Distance), all_points=496638
  TrainingPool->update: Nvs=109480 ->  close_surface_sample_idx=65200, all_points=17585075, increasement: 17475595
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([65200])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.759195, mean_loss=0.759228, diff=-0.000032, thres=0.000100
FrameId=125:  cached_time=2.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 22433, --cropped--> 22432
  Registration->register: reg_points=torch.Size([880, 6]), translation=tensor([-1.0358, -0.4459,  0.3813], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([22432, 6]) -> sampled_points=torch.Size([112160, 6]) time= 0.93 ms
  LatentFeature->update: samples=112160, new_points=2891 (closreSur>VoxDwn>Radius>Distance), all_points=499529
  TrainingPool->update: Nvs=112160 ->  close_surface_sample_idx=66582, all_points=17697235, increasement: 17585075
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([66582])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.758921, mean_loss=0.759001, diff=-0.000080, thres=0.000100
FrameId=126:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 23393, --cropped--> 23392
  Registration->register: reg_points=torch.Size([923, 6]), translation=tensor([-1.0375, -0.4540,  0.3996], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([23392, 6]) -> sampled_points=torch.Size([116960, 6]) time= 0.99 ms
  LatentFeature->update: samples=116960, new_points=3079 (closreSur>VoxDwn>Radius>Distance), all_points=502608
  TrainingPool->update: Nvs=116960 ->  close_surface_sample_idx=69609, all_points=17814195, increasement: 17697235
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([69609])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.759465, mean_loss=0.759561, diff=-0.000096, thres=0.000100
FrameId=127:  cached_time=2.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 24264, --cropped--> 24263
  Registration->register: reg_points=torch.Size([970, 6]), translation=tensor([-1.0370, -0.4626,  0.4170], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([24263, 6]) -> sampled_points=torch.Size([121315, 6]) time= 0.95 ms
  LatentFeature->update: samples=121315, new_points=3233 (closreSur>VoxDwn>Radius>Distance), all_points=505841
  TrainingPool->update: Nvs=121315 ->  close_surface_sample_idx=72218, all_points=17935510, increasement: 17814195
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([72218])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.759686, mean_loss=0.759720, diff=-0.000035, thres=0.000100
FrameId=128:  cached_time=2.0 ms
  TumDataset->next_frame: Original=307200 -downsample-> 24785, --cropped--> 24784
  Registration->register: reg_points=torch.Size([1005, 6]), translation=tensor([-1.0499, -0.4593,  0.4316], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([24784, 6]) -> sampled_points=torch.Size([123920, 6]) time= 1.00 ms
  LatentFeature->update: samples=123920, new_points=3308 (closreSur>VoxDwn>Radius>Distance), all_points=509149
  TrainingPool->update: Nvs=123920 ->  close_surface_sample_idx=73803, all_points=18059430, increasement: 17935510
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([73803])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.759796, mean_loss=0.759884, diff=-0.000089, thres=0.000100
FrameId=129:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 25270, --cropped--> 25269
  Registration->register: reg_points=torch.Size([1018, 6]), translation=tensor([-1.0686, -0.4690,  0.4435], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([25269, 6]) -> sampled_points=torch.Size([126345, 6]) time= 0.98 ms
  LatentFeature->update: samples=126345, new_points=3409 (closreSur>VoxDwn>Radius>Distance), all_points=512558
  TrainingPool->update: Nvs=126345 ->  close_surface_sample_idx=75254, all_points=18185775, increasement: 18059430
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([75254])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.758558, mean_loss=0.758637, diff=-0.000080, thres=0.000100
FrameId=130:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 25306, --cropped--> 25305
  Registration->register: reg_points=torch.Size([1012, 6]), translation=tensor([-1.0827, -0.4655,  0.4499], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([25305, 6]) -> sampled_points=torch.Size([126525, 6]) time= 0.88 ms
  LatentFeature->update: samples=126525, new_points=3385 (closreSur>VoxDwn>Radius>Distance), all_points=515943
  TrainingPool->update: Nvs=126525 ->  close_surface_sample_idx=75437, all_points=18312300, increasement: 18185775
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([75437])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.758892, mean_loss=0.758965, diff=-0.000074, thres=0.000100
FrameId=131:  cached_time=2.0 ms
  TumDataset->next_frame: Original=307200 -downsample-> 25763, --cropped--> 25762
  Registration->register: reg_points=torch.Size([1024, 6]), translation=tensor([-1.0919, -0.4603,  0.4535], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([25762, 6]) -> sampled_points=torch.Size([128810, 6]) time= 0.98 ms
  LatentFeature->update: samples=128810, new_points=3430 (closreSur>VoxDwn>Radius>Distance), all_points=519373
  TrainingPool->update: Nvs=128810 ->  close_surface_sample_idx=76765, all_points=18441110, increasement: 18312300
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([76765])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.758793, mean_loss=0.758822, diff=-0.000029, thres=0.000100
FrameId=132:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 26732, --cropped--> 26731
  Registration->register: reg_points=torch.Size([1098, 6]), translation=tensor([-1.1238, -0.4406,  0.4707], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([26731, 6]) -> sampled_points=torch.Size([133655, 6]) time= 0.89 ms
  LatentFeature->update: samples=133655, new_points=3621 (closreSur>VoxDwn>Radius>Distance), all_points=522994
  TrainingPool->update: Nvs=133655 ->  close_surface_sample_idx=79582, all_points=18574765, increasement: 18441110
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([79582])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.759140, mean_loss=0.759227, diff=-0.000087, thres=0.000100
FrameId=133:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 27820, --cropped--> 27819
  Registration->register: reg_points=torch.Size([1138, 6]), translation=tensor([-1.1435, -0.4224,  0.4809], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([27819, 6]) -> sampled_points=torch.Size([139095, 6]) time= 0.96 ms
  LatentFeature->update: samples=139095, new_points=3691 (closreSur>VoxDwn>Radius>Distance), all_points=526685
  TrainingPool->update: Nvs=139095 ->  close_surface_sample_idx=82885, all_points=18713860, increasement: 18574765
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([82885])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.759224, mean_loss=0.759139, diff=0.000085, thres=0.000100
FrameId=134:  cached_time=2.0 ms
  TumDataset->next_frame: Original=307200 -downsample-> 30209, --cropped--> 30208
  Registration->register: reg_points=torch.Size([1279, 6]), translation=tensor([-1.1468, -0.4139,  0.4963], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([30208, 6]) -> sampled_points=torch.Size([151040, 6]) time= 0.97 ms
  LatentFeature->update: samples=151040, new_points=4198 (closreSur>VoxDwn>Radius>Distance), all_points=530883
  TrainingPool->update: Nvs=151040 ->  close_surface_sample_idx=89996, all_points=18864900, increasement: 18713860
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([89996])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.759922, mean_loss=0.759944, diff=-0.000022, thres=0.000100
FrameId=135:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 31553, --cropped--> 31552
  Registration->register: reg_points=torch.Size([1381, 6]), translation=tensor([-1.1458, -0.4246,  0.5063], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([31552, 6]) -> sampled_points=torch.Size([157760, 6]) time= 0.97 ms
  LatentFeature->update: samples=157760, new_points=4506 (closreSur>VoxDwn>Radius>Distance), all_points=535389
  TrainingPool->update: Nvs=157760 ->  close_surface_sample_idx=94108, all_points=19022660, increasement: 18864900
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([94108])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.759318, mean_loss=0.759357, diff=-0.000039, thres=0.000100
FrameId=136:  cached_time=2.0 ms
  TumDataset->next_frame: Original=307200 -downsample-> 33181, --cropped--> 33180
  Registration->register: reg_points=torch.Size([1472, 6]), translation=tensor([-1.1723, -0.4153,  0.5179], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([33180, 6]) -> sampled_points=torch.Size([165900, 6]) time= 0.98 ms
  LatentFeature->update: samples=165900, new_points=4831 (closreSur>VoxDwn>Radius>Distance), all_points=540220
  TrainingPool->update: Nvs=165900 ->  close_surface_sample_idx=98783, all_points=19188560, increasement: 19022660
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([98783])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.759436, mean_loss=0.759387, diff=0.000049, thres=0.000100
FrameId=137:  cached_time=2.0 ms
  TumDataset->next_frame: Original=307200 -downsample-> 35636, --cropped--> 35635
  Registration->register: reg_points=torch.Size([1597, 6]), translation=tensor([-1.1919, -0.4055,  0.5285], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([35635, 6]) -> sampled_points=torch.Size([178175, 6]) time= 0.83 ms
  LatentFeature->update: samples=178175, new_points=5336 (closreSur>VoxDwn>Radius>Distance), all_points=545556
  TrainingPool->update: Nvs=178175 ->  close_surface_sample_idx=106345, all_points=19366735, increasement: 19188560
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([106345])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.759286, mean_loss=0.759222, diff=0.000065, thres=0.000100
FrameId=138:  cached_time=2.0 ms
  TumDataset->next_frame: Original=307200 -downsample-> 36768, --cropped--> 36767
  Registration->register: reg_points=torch.Size([1707, 6]), translation=tensor([-1.2200, -0.3998,  0.5296], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([36767, 6]) -> sampled_points=torch.Size([183835, 6]) time= 0.92 ms
  LatentFeature->update: samples=183835, new_points=5602 (closreSur>VoxDwn>Radius>Distance), all_points=551158
  TrainingPool->update: Nvs=183835 ->  close_surface_sample_idx=109496, all_points=19550570, increasement: 19366735
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([109496])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.759095, mean_loss=0.759086, diff=0.000009, thres=0.000100
FrameId=139:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 37902, --cropped--> 37901
  Registration->register: reg_points=torch.Size([1745, 6]), translation=tensor([-1.2490, -0.3750,  0.5324], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([37901, 6]) -> sampled_points=torch.Size([189505, 6]) time= 0.99 ms
  LatentFeature->update: samples=189505, new_points=5817 (closreSur>VoxDwn>Radius>Distance), all_points=556975
  TrainingPool->update: Nvs=189505 ->  close_surface_sample_idx=112807, all_points=19740075, increasement: 19550570
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([112807])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.757987, mean_loss=0.757900, diff=0.000087, thres=0.000100
FrameId=140:  cached_time=2.1 ms
  TumDataset->next_frame: Original=307200 -downsample-> 39512, --cropped--> 39511
  Registration->register: reg_points=torch.Size([1875, 6]), translation=tensor([-1.2519, -0.3591,  0.5397], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([39511, 6]) -> sampled_points=torch.Size([197555, 6]) time= 0.97 ms
  LatentFeature->update: samples=197555, new_points=6192 (closreSur>VoxDwn>Radius>Distance), all_points=563167
  TrainingPool->update: Nvs=197555 ->  close_surface_sample_idx=117549, all_points=19937630, increasement: 19740075
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([117549])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.758220, mean_loss=0.758189, diff=0.000031, thres=0.000100
FrameId=141:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 40890, --cropped--> 40889
  Registration->register: reg_points=torch.Size([2010, 6]), translation=tensor([-1.2697, -0.3406,  0.5396], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([40889, 6]) -> sampled_points=torch.Size([204445, 6]) time= 0.84 ms
  LatentFeature->update: samples=204445, new_points=6531 (closreSur>VoxDwn>Radius>Distance), all_points=569698
  TrainingPool->update: Nvs=204445 ->  close_surface_sample_idx=121717, all_points=20142075, increasement: 19937630
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([121717])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.759106, mean_loss=0.759204, diff=-0.000098, thres=0.000100
FrameId=142:  cached_time=2.0 ms
  TumDataset->next_frame: Original=307200 -downsample-> 40245, --cropped--> 40244
  Registration->register: reg_points=torch.Size([1953, 6]), translation=tensor([-1.3152, -0.3587,  0.5363], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([40244, 6]) -> sampled_points=torch.Size([201220, 6]) time= 1.00 ms
  LatentFeature->update: samples=201220, new_points=6499 (closreSur>VoxDwn>Radius>Distance), all_points=576197
  TrainingPool->update: Nvs=201220 ->  close_surface_sample_idx=119844, all_points=20343295, increasement: 20142075
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([119844])
  TrainingPool->train: break at iter=57, cur_mean_loss=0.758004, mean_loss=0.757973, diff=0.000032, thres=0.000100
FrameId=143:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 39898, --cropped--> 39897
  Registration->register: reg_points=torch.Size([1966, 6]), translation=tensor([-1.3019, -0.3604,  0.5336], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([39897, 6]) -> sampled_points=torch.Size([199485, 6]) time= 0.98 ms
  LatentFeature->update: samples=199485, new_points=6445 (closreSur>VoxDwn>Radius>Distance), all_points=582642
  TrainingPool->update: Nvs=199485 ->  close_surface_sample_idx=118778, all_points=20542780, increasement: 20343295
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([118778])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.757780, mean_loss=0.757878, diff=-0.000098, thres=0.000100
FrameId=144:  cached_time=2.0 ms
  TumDataset->next_frame: Original=307200 -downsample-> 40665, --cropped--> 40664
  Registration->register: reg_points=torch.Size([1993, 6]), translation=tensor([-1.3510, -0.3468,  0.5175], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([40664, 6]) -> sampled_points=torch.Size([203320, 6]) time= 0.87 ms
  LatentFeature->update: samples=203320, new_points=6567 (closreSur>VoxDwn>Radius>Distance), all_points=589209
  TrainingPool->update: Nvs=203320 ->  close_surface_sample_idx=120887, all_points=20746100, increasement: 20542780
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([120887])
  TrainingPool->train: break at iter=56, cur_mean_loss=0.756534, mean_loss=0.756596, diff=-0.000062, thres=0.000100
FrameId=145:  cached_time=2.0 ms
  TumDataset->next_frame: Original=307200 -downsample-> 40157, --cropped--> 40156
  Registration->register: reg_points=torch.Size([1945, 6]), translation=tensor([-1.3575, -0.3322,  0.5197], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([40156, 6]) -> sampled_points=torch.Size([200780, 6]) time= 1.03 ms
  LatentFeature->update: samples=200780, new_points=6452 (closreSur>VoxDwn>Radius>Distance), all_points=595661
  TrainingPool->update: Nvs=200780 ->  close_surface_sample_idx=119519, all_points=20946880, increasement: 20746100
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([119519])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.756755, mean_loss=0.756770, diff=-0.000016, thres=0.000100
FrameId=146:  cached_time=2.0 ms
  TumDataset->next_frame: Original=307200 -downsample-> 39143, --cropped--> 39142
  Registration->register: reg_points=torch.Size([1871, 6]), translation=tensor([-1.3831, -0.3478,  0.5131], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([39142, 6]) -> sampled_points=torch.Size([195710, 6]) time= 0.88 ms
  LatentFeature->update: samples=195710, new_points=6160 (closreSur>VoxDwn>Radius>Distance), all_points=601821
  TrainingPool->update: Nvs=195710 ->  close_surface_sample_idx=116584, all_points=21142590, increasement: 20946880
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([116584])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.756615, mean_loss=0.756676, diff=-0.000061, thres=0.000100
FrameId=147:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 37878, --cropped--> 37877
  Registration->register: reg_points=torch.Size([1773, 6]), translation=tensor([-1.4120, -0.3341,  0.4974], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([37877, 6]) -> sampled_points=torch.Size([189385, 6]) time= 0.98 ms
  LatentFeature->update: samples=189385, new_points=5899 (closreSur>VoxDwn>Radius>Distance), all_points=607720
  TrainingPool->update: Nvs=189385 ->  close_surface_sample_idx=112879, all_points=21331975, increasement: 21142590
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([112879])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.757008, mean_loss=0.756994, diff=0.000014, thres=0.000100
FrameId=148:  cached_time=2.1 ms
  TumDataset->next_frame: Original=307200 -downsample-> 39039, --cropped--> 39038
  Registration->register: reg_points=torch.Size([1839, 6]), translation=tensor([-1.4075, -0.3019,  0.4944], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([39038, 6]) -> sampled_points=torch.Size([195190, 6]) time= 0.97 ms
  LatentFeature->update: samples=195190, new_points=6090 (closreSur>VoxDwn>Radius>Distance), all_points=613810
  TrainingPool->update: Nvs=195190 ->  close_surface_sample_idx=116292, all_points=21527165, increasement: 21331975
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([116292])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.755929, mean_loss=0.755881, diff=0.000048, thres=0.000100
FrameId=149:  cached_time=2.0 ms
  TumDataset->next_frame: Original=307200 -downsample-> 38971, --cropped--> 38970
  Registration->register: reg_points=torch.Size([1861, 6]), translation=tensor([-1.4370, -0.3073,  0.4832], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([38970, 6]) -> sampled_points=torch.Size([194850, 6]) time= 0.98 ms
  LatentFeature->update: samples=194850, new_points=6080 (closreSur>VoxDwn>Radius>Distance), all_points=619890
  TrainingPool->update: Nvs=194850 ->  close_surface_sample_idx=115990, all_points=21722015, increasement: 21527165
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([115990])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.756290, mean_loss=0.756384, diff=-0.000094, thres=0.000100
FrameId=150:  cached_time=2.2 ms
  TumDataset->next_frame: Original=307200 -downsample-> 39634, --cropped--> 39633
  Registration->register: reg_points=torch.Size([1902, 6]), translation=tensor([-1.4559, -0.2705,  0.4639], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([39633, 6]) -> sampled_points=torch.Size([198165, 6]) time= 1.02 ms
  LatentFeature->update: samples=198165, new_points=6294 (closreSur>VoxDwn>Radius>Distance), all_points=626184
  TrainingPool->update: Nvs=198165 ->  close_surface_sample_idx=118192, all_points=21920180, increasement: 21722015
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([118192])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.755749, mean_loss=0.755844, diff=-0.000094, thres=0.000100
FrameId=151:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 41159, --cropped--> 41158
  Registration->register: reg_points=torch.Size([1992, 6]), translation=tensor([-1.4764, -0.2324,  0.4496], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([41158, 6]) -> sampled_points=torch.Size([205790, 6]) time= 0.90 ms
  LatentFeature->update: samples=205790, new_points=6627 (closreSur>VoxDwn>Radius>Distance), all_points=632811
  TrainingPool->update: Nvs=205790 ->  close_surface_sample_idx=122585, all_points=22125970, increasement: 21920180
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([122585])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.755110, mean_loss=0.755127, diff=-0.000017, thres=0.000100
FrameId=152:  cached_time=2.1 ms
  TumDataset->next_frame: Original=307200 -downsample-> 40952, --cropped--> 40951
  Registration->register: reg_points=torch.Size([2022, 6]), translation=tensor([-1.4819, -0.2270,  0.4346], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([40951, 6]) -> sampled_points=torch.Size([204755, 6]) time= 0.96 ms
  LatentFeature->update: samples=204755, new_points=6702 (closreSur>VoxDwn>Radius>Distance), all_points=639513
  TrainingPool->update: Nvs=204755 ->  close_surface_sample_idx=121939, all_points=22330725, increasement: 22125970
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([121939])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.754654, mean_loss=0.754665, diff=-0.000011, thres=0.000100
FrameId=153:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 42285, --cropped--> 42284
  Registration->register: reg_points=torch.Size([2064, 6]), translation=tensor([-1.5080, -0.2199,  0.4200], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([42284, 6]) -> sampled_points=torch.Size([211420, 6]) time= 0.96 ms
  LatentFeature->update: samples=211420, new_points=6975 (closreSur>VoxDwn>Radius>Distance), all_points=646488
  TrainingPool->update: Nvs=211420 ->  close_surface_sample_idx=125852, all_points=22542145, increasement: 22330725
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([125852])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.757074, mean_loss=0.757021, diff=0.000053, thres=0.000100
FrameId=154:  cached_time=2.0 ms
  TumDataset->next_frame: Original=307200 -downsample-> 45343, --cropped--> 45309
  Registration->register: reg_points=torch.Size([2143, 6]), translation=tensor([-1.5240, -0.2136,  0.3951], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([45309, 6]) -> sampled_points=torch.Size([226545, 6]) time= 0.96 ms
  LatentFeature->update: samples=226545, new_points=7202 (closreSur>VoxDwn>Radius>Distance), all_points=653690
  TrainingPool->update: Nvs=226545 ->  close_surface_sample_idx=134833, all_points=22768690, increasement: 22542145
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([134833])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.757740, mean_loss=0.757806, diff=-0.000066, thres=0.000100
FrameId=155:  cached_time=2.2 ms
  TumDataset->next_frame: Original=307200 -downsample-> 45908, --cropped--> 45907
  Registration->register: reg_points=torch.Size([2147, 6]), translation=tensor([-1.5367, -0.2128,  0.3834], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([45907, 6]) -> sampled_points=torch.Size([229535, 6]) time= 1.02 ms
  LatentFeature->update: samples=229535, new_points=7491 (closreSur>VoxDwn>Radius>Distance), all_points=661181
  TrainingPool->update: Nvs=229535 ->  close_surface_sample_idx=136402, all_points=22998225, increasement: 22768690
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([136402])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.756858, mean_loss=0.756933, diff=-0.000075, thres=0.000100
FrameId=156:  cached_time=2.1 ms
  TumDataset->next_frame: Original=307200 -downsample-> 45850, --cropped--> 45849
  Registration->register: reg_points=torch.Size([2133, 6]), translation=tensor([-1.5387, -0.2305,  0.3612], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([45849, 6]) -> sampled_points=torch.Size([229245, 6]) time= 1.03 ms
  LatentFeature->update: samples=229245, new_points=7481 (closreSur>VoxDwn>Radius>Distance), all_points=668662
  TrainingPool->update: Nvs=229245 ->  close_surface_sample_idx=136250, all_points=23227470, increasement: 22998225
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([136250])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.754916, mean_loss=0.754938, diff=-0.000023, thres=0.000100
FrameId=157:  cached_time=2.1 ms
  TumDataset->next_frame: Original=307200 -downsample-> 46273, --cropped--> 46272
  Registration->register: reg_points=torch.Size([2164, 6]), translation=tensor([-1.5404, -0.2497,  0.3510], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([46272, 6]) -> sampled_points=torch.Size([231360, 6]) time= 1.00 ms
  LatentFeature->update: samples=231360, new_points=7569 (closreSur>VoxDwn>Radius>Distance), all_points=676231
  TrainingPool->update: Nvs=231360 ->  close_surface_sample_idx=137822, all_points=23458830, increasement: 23227470
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([137822])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.755902, mean_loss=0.755987, diff=-0.000085, thres=0.000100
FrameId=158:  cached_time=2.1 ms
  TumDataset->next_frame: Original=307200 -downsample-> 45381, --cropped--> 45380
  Registration->register: reg_points=torch.Size([2129, 6]), translation=tensor([-1.5570, -0.2438,  0.3258], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([45380, 6]) -> sampled_points=torch.Size([226900, 6]) time= 0.97 ms
  LatentFeature->update: samples=226900, new_points=7379 (closreSur>VoxDwn>Radius>Distance), all_points=683610
  TrainingPool->update: Nvs=226900 ->  close_surface_sample_idx=135156, all_points=23685730, increasement: 23458830
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([135156])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.755718, mean_loss=0.755723, diff=-0.000005, thres=0.000100
FrameId=159:  cached_time=2.3 ms
  TumDataset->next_frame: Original=307200 -downsample-> 44046, --cropped--> 44045
  Registration->register: reg_points=torch.Size([2066, 6]), translation=tensor([-1.5696, -0.2440,  0.3027], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([44045, 6]) -> sampled_points=torch.Size([220225, 6]) time= 1.04 ms
  LatentFeature->update: samples=220225, new_points=7119 (closreSur>VoxDwn>Radius>Distance), all_points=690729
  TrainingPool->update: Nvs=220225 ->  close_surface_sample_idx=131004, all_points=23905955, increasement: 23685730
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([131004])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.755227, mean_loss=0.755216, diff=0.000010, thres=0.000100
FrameId=160:  cached_time=2.1 ms
  TumDataset->next_frame: Original=307200 -downsample-> 42719, --cropped--> 42718
  Registration->register: reg_points=torch.Size([1937, 6]), translation=tensor([-1.5751, -0.2644,  0.2646], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([42718, 6]) -> sampled_points=torch.Size([213590, 6]) time= 0.97 ms
  LatentFeature->update: samples=213590, new_points=6828 (closreSur>VoxDwn>Radius>Distance), all_points=697557
  TrainingPool->update: Nvs=213590 ->  close_surface_sample_idx=126936, all_points=24119545, increasement: 23905955
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([126936])
  TrainingPool->train: break at iter=55, cur_mean_loss=0.755663, mean_loss=0.755673, diff=-0.000011, thres=0.000100
FrameId=161:  cached_time=2.1 ms
  TumDataset->next_frame: Original=307200 -downsample-> 40814, --cropped--> 40813
  Registration->register: reg_points=torch.Size([1891, 6]), translation=tensor([-1.5889, -0.2472,  0.2412], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([40813, 6]) -> sampled_points=torch.Size([204065, 6]) time= 1.02 ms
  LatentFeature->update: samples=204065, new_points=6554 (closreSur>VoxDwn>Radius>Distance), all_points=704111
  TrainingPool->update: Nvs=204065 ->  close_surface_sample_idx=121592, all_points=24323610, increasement: 24119545
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([121592])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.754670, mean_loss=0.754737, diff=-0.000067, thres=0.000100
FrameId=162:  cached_time=2.0 ms
  TumDataset->next_frame: Original=307200 -downsample-> 41635, --cropped--> 41634
  Registration->register: reg_points=torch.Size([1957, 6]), translation=tensor([-1.5687, -0.2371,  0.2318], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([41634, 6]) -> sampled_points=torch.Size([208170, 6]) time= 1.08 ms
  LatentFeature->update: samples=208170, new_points=6736 (closreSur>VoxDwn>Radius>Distance), all_points=710847
  TrainingPool->update: Nvs=208170 ->  close_surface_sample_idx=123991, all_points=24531780, increasement: 24323610
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([123991])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.755946, mean_loss=0.756004, diff=-0.000059, thres=0.000100
FrameId=163:  cached_time=2.1 ms
  TumDataset->next_frame: Original=307200 -downsample-> 41187, --cropped--> 41186
  Registration->register: reg_points=torch.Size([1912, 6]), translation=tensor([-1.5689, -0.2393,  0.2201], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([41186, 6]) -> sampled_points=torch.Size([205930, 6]) time= 0.95 ms
  LatentFeature->update: samples=205930, new_points=6659 (closreSur>VoxDwn>Radius>Distance), all_points=717506
  TrainingPool->update: Nvs=205930 ->  close_surface_sample_idx=122491, all_points=24737710, increasement: 24531780
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([122491])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.755143, mean_loss=0.755157, diff=-0.000015, thres=0.000100
FrameId=164:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 39288, --cropped--> 39287
  Registration->register: reg_points=torch.Size([1915, 6]), translation=tensor([-1.5750, -0.2404,  0.1970], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([39287, 6]) -> sampled_points=torch.Size([196435, 6]) time= 0.99 ms
  LatentFeature->update: samples=196435, new_points=6406 (closreSur>VoxDwn>Radius>Distance), all_points=723912
  TrainingPool->update: Nvs=196435 ->  close_surface_sample_idx=116987, all_points=24934145, increasement: 24737710
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([116987])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.755271, mean_loss=0.755347, diff=-0.000077, thres=0.000100
FrameId=165:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 39225, --cropped--> 39224
  Registration->register: reg_points=torch.Size([1955, 6]), translation=tensor([-1.5836, -0.2452,  0.1867], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([39224, 6]) -> sampled_points=torch.Size([196120, 6]) time= 0.87 ms
  LatentFeature->update: samples=196120, new_points=6503 (closreSur>VoxDwn>Radius>Distance), all_points=730415
  TrainingPool->update: Nvs=196120 ->  close_surface_sample_idx=116768, all_points=25130265, increasement: 24934145
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([116768])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.753412, mean_loss=0.753503, diff=-0.000091, thres=0.000100
FrameId=166:  cached_time=2.1 ms
  TumDataset->next_frame: Original=307200 -downsample-> 38916, --cropped--> 38915
  Registration->register: reg_points=torch.Size([1918, 6]), translation=tensor([-1.5977, -0.2393,  0.1728], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([38915, 6]) -> sampled_points=torch.Size([194575, 6]) time= 1.02 ms
  LatentFeature->update: samples=194575, new_points=6398 (closreSur>VoxDwn>Radius>Distance), all_points=736813
  TrainingPool->update: Nvs=194575 ->  close_surface_sample_idx=115660, all_points=25324840, increasement: 25130265
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([115660])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.754073, mean_loss=0.754069, diff=0.000004, thres=0.000100
FrameId=167:  cached_time=2.1 ms
  TumDataset->next_frame: Original=307200 -downsample-> 38878, --cropped--> 38877
  Registration->register: reg_points=torch.Size([1895, 6]), translation=tensor([-1.5951, -0.2324,  0.1646], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([38877, 6]) -> sampled_points=torch.Size([194385, 6]) time= 0.98 ms
  LatentFeature->update: samples=194385, new_points=6352 (closreSur>VoxDwn>Radius>Distance), all_points=743165
  TrainingPool->update: Nvs=194385 ->  close_surface_sample_idx=115509, all_points=25519225, increasement: 25324840
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([115509])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.753951, mean_loss=0.754009, diff=-0.000059, thres=0.000100
FrameId=168:  cached_time=2.0 ms
  TumDataset->next_frame: Original=307200 -downsample-> 37914, --cropped--> 37913
  Registration->register: reg_points=torch.Size([1883, 6]), translation=tensor([-1.5850, -0.2345,  0.1543], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([37913, 6]) -> sampled_points=torch.Size([189565, 6]) time= 0.95 ms
  LatentFeature->update: samples=189565, new_points=6168 (closreSur>VoxDwn>Radius>Distance), all_points=749333
  TrainingPool->update: Nvs=189565 ->  close_surface_sample_idx=112817, all_points=25708790, increasement: 25519225
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([112817])
  TrainingPool->train: break at iter=54, cur_mean_loss=0.754679, mean_loss=0.754678, diff=0.000001, thres=0.000100
FrameId=169:  cached_time=2.1 ms
  TumDataset->next_frame: Original=307200 -downsample-> 36916, --cropped--> 36915
  Registration->register: reg_points=torch.Size([1797, 6]), translation=tensor([-1.6019, -0.2335,  0.1472], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([36915, 6]) -> sampled_points=torch.Size([184575, 6]) time= 1.07 ms
  LatentFeature->update: samples=184575, new_points=5905 (closreSur>VoxDwn>Radius>Distance), all_points=755238
  TrainingPool->update: Nvs=184575 ->  close_surface_sample_idx=109241, all_points=25893365, increasement: 25708790
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([109241])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.753397, mean_loss=0.753389, diff=0.000009, thres=0.000100
FrameId=170:  cached_time=2.2 ms
  TumDataset->next_frame: Original=307200 -downsample-> 38457, --cropped--> 38456
  Registration->register: reg_points=torch.Size([1842, 6]), translation=tensor([-1.6064, -0.2089,  0.1434], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([38456, 6]) -> sampled_points=torch.Size([192280, 6]) time= 1.00 ms
  LatentFeature->update: samples=192280, new_points=6235 (closreSur>VoxDwn>Radius>Distance), all_points=761473
  TrainingPool->update: Nvs=192280 ->  close_surface_sample_idx=114409, all_points=26085645, increasement: 25893365
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([114409])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.753706, mean_loss=0.753696, diff=0.000010, thres=0.000100
FrameId=171:  cached_time=2.1 ms
  TumDataset->next_frame: Original=307200 -downsample-> 40378, --cropped--> 40377
  Registration->register: reg_points=torch.Size([1880, 6]), translation=tensor([-1.6372, -0.2001,  0.1311], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([40377, 6]) -> sampled_points=torch.Size([201885, 6]) time= 1.00 ms
  LatentFeature->update: samples=201885, new_points=6495 (closreSur>VoxDwn>Radius>Distance), all_points=767968
  TrainingPool->update: Nvs=201885 ->  close_surface_sample_idx=120114, all_points=26287530, increasement: 26085645
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([120114])
  TrainingPool->train: break at iter=58, cur_mean_loss=0.753034, mean_loss=0.753003, diff=0.000031, thres=0.000100
FrameId=172:  cached_time=2.0 ms
  TumDataset->next_frame: Original=307200 -downsample-> 43974, --cropped--> 43973
  Registration->register: reg_points=torch.Size([1986, 6]), translation=tensor([-1.6545, -0.1851,  0.1281], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([43973, 6]) -> sampled_points=torch.Size([219865, 6]) time= 1.05 ms
  LatentFeature->update: samples=219865, new_points=7003 (closreSur>VoxDwn>Radius>Distance), all_points=774971
  TrainingPool->update: Nvs=219865 ->  close_surface_sample_idx=131130, all_points=26507395, increasement: 26287530
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([131130])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.752819, mean_loss=0.752892, diff=-0.000073, thres=0.000100
FrameId=173:  cached_time=2.1 ms
  TumDataset->next_frame: Original=307200 -downsample-> 46831, --cropped--> 46830
  Registration->register: reg_points=torch.Size([2093, 6]), translation=tensor([-1.6721, -0.1772,  0.1100], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([46830, 6]) -> sampled_points=torch.Size([234150, 6]) time= 0.97 ms
  LatentFeature->update: samples=234150, new_points=7459 (closreSur>VoxDwn>Radius>Distance), all_points=782430
  TrainingPool->update: Nvs=234150 ->  close_surface_sample_idx=139691, all_points=26741545, increasement: 26507395
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([139691])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.753831, mean_loss=0.753893, diff=-0.000062, thres=0.000100
FrameId=174:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 47603, --cropped--> 47602
  Registration->register: reg_points=torch.Size([2215, 6]), translation=tensor([-1.7167, -0.1729,  0.0874], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([47602, 6]) -> sampled_points=torch.Size([238010, 6]) time= 1.02 ms
  LatentFeature->update: samples=238010, new_points=7736 (closreSur>VoxDwn>Radius>Distance), all_points=790166
  TrainingPool->update: Nvs=238010 ->  close_surface_sample_idx=141897, all_points=26979555, increasement: 26741545
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([141897])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.752616, mean_loss=0.752584, diff=0.000032, thres=0.000100
FrameId=175:  cached_time=2.0 ms
  TumDataset->next_frame: Original=307200 -downsample-> 49340, --cropped--> 49339
  Registration->register: reg_points=torch.Size([2372, 6]), translation=tensor([-1.7295, -0.1539,  0.0747], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([49339, 6]) -> sampled_points=torch.Size([246695, 6]) time= 0.89 ms
  LatentFeature->update: samples=246695, new_points=8320 (closreSur>VoxDwn>Radius>Distance), all_points=798486
  TrainingPool->update: Nvs=246695 ->  close_surface_sample_idx=147138, all_points=27226250, increasement: 26979555
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([147138])
  TrainingPool->train: break at iter=56, cur_mean_loss=0.753446, mean_loss=0.753366, diff=0.000081, thres=0.000100
FrameId=176:  cached_time=2.0 ms
  TumDataset->next_frame: Original=307200 -downsample-> 48191, --cropped--> 48190
  Registration->register: reg_points=torch.Size([2325, 6]), translation=tensor([-1.7659, -0.1405,  0.0417], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([48190, 6]) -> sampled_points=torch.Size([240950, 6]) time= 0.96 ms
  LatentFeature->update: samples=240950, new_points=8196 (closreSur>VoxDwn>Radius>Distance), all_points=806682
  TrainingPool->update: Nvs=240950 ->  close_surface_sample_idx=143651, all_points=27467200, increasement: 27226250
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([143651])
  TrainingPool->train: break at iter=55, cur_mean_loss=0.752845, mean_loss=0.752847, diff=-0.000002, thres=0.000100
FrameId=177:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 46559, --cropped--> 46558
  Registration->register: reg_points=torch.Size([2150, 6]), translation=tensor([-1.7674, -0.1505,  0.0290], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([46558, 6]) -> sampled_points=torch.Size([232790, 6]) time= 1.04 ms
  LatentFeature->update: samples=232790, new_points=7663 (closreSur>VoxDwn>Radius>Distance), all_points=814345
  TrainingPool->update: Nvs=232790 ->  close_surface_sample_idx=138678, all_points=27699990, increasement: 27467200
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([138678])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.753455, mean_loss=0.753414, diff=0.000041, thres=0.000100
FrameId=178:  cached_time=2.1 ms
  TumDataset->next_frame: Original=307200 -downsample-> 44176, --cropped--> 44175
  Registration->register: reg_points=torch.Size([2025, 6]), translation=tensor([-1.7647, -0.1474,  0.0121], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([44175, 6]) -> sampled_points=torch.Size([220875, 6]) time= 1.05 ms
  LatentFeature->update: samples=220875, new_points=7195 (closreSur>VoxDwn>Radius>Distance), all_points=821540
  TrainingPool->update: Nvs=220875 ->  close_surface_sample_idx=131313, all_points=27920865, increasement: 27699990
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([131313])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.752349, mean_loss=0.752265, diff=0.000084, thres=0.000100
FrameId=179:  cached_time=2.0 ms
  TumDataset->next_frame: Original=307200 -downsample-> 42217, --cropped--> 42216
  Registration->register: reg_points=torch.Size([1894, 6]), translation=tensor([-1.7673, -0.1578,  0.0073], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([42216, 6]) -> sampled_points=torch.Size([211080, 6]) time= 1.01 ms
  LatentFeature->update: samples=211080, new_points=6766 (closreSur>VoxDwn>Radius>Distance), all_points=828306
  TrainingPool->update: Nvs=211080 ->  close_surface_sample_idx=125776, all_points=28131945, increasement: 27920865
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([125776])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.752616, mean_loss=0.752567, diff=0.000048, thres=0.000100
FrameId=180:  cached_time=2.1 ms
  TumDataset->next_frame: Original=307200 -downsample-> 41040, --cropped--> 41039
  Registration->register: reg_points=torch.Size([1837, 6]), translation=tensor([-1.7797, -0.1760, -0.0044], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([41039, 6]) -> sampled_points=torch.Size([205195, 6]) time= 0.97 ms
  LatentFeature->update: samples=205195, new_points=6598 (closreSur>VoxDwn>Radius>Distance), all_points=834904
  TrainingPool->update: Nvs=205195 ->  close_surface_sample_idx=122263, all_points=28337140, increasement: 28131945
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([122263])
  TrainingPool->train: break at iter=55, cur_mean_loss=0.752058, mean_loss=0.752133, diff=-0.000075, thres=0.000100
FrameId=181:  cached_time=2.1 ms
  TumDataset->next_frame: Original=307200 -downsample-> 37345, --cropped--> 37344
  Registration->register: reg_points=torch.Size([1688, 6]), translation=tensor([-1.7908e+00, -1.9778e-01, -9.9328e-04], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([37344, 6]) -> sampled_points=torch.Size([186720, 6]) time= 0.86 ms
  LatentFeature->update: samples=186720, new_points=5868 (closreSur>VoxDwn>Radius>Distance), all_points=840772
  TrainingPool->update: Nvs=186720 ->  close_surface_sample_idx=111372, all_points=28523860, increasement: 28337140
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([111372])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.752100, mean_loss=0.752165, diff=-0.000065, thres=0.000100
FrameId=182:  cached_time=2.1 ms
  TumDataset->next_frame: Original=307200 -downsample-> 34390, --cropped--> 34389
  Registration->register: reg_points=torch.Size([1555, 6]), translation=tensor([-1.7849, -0.2129,  0.0109], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([34389, 6]) -> sampled_points=torch.Size([171945, 6]) time= 0.96 ms
  LatentFeature->update: samples=171945, new_points=5348 (closreSur>VoxDwn>Radius>Distance), all_points=846120
  TrainingPool->update: Nvs=171945 ->  close_surface_sample_idx=102418, all_points=28695805, increasement: 28523860
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([102418])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.751950, mean_loss=0.752035, diff=-0.000085, thres=0.000100
FrameId=183:  cached_time=2.0 ms
  TumDataset->next_frame: Original=307200 -downsample-> 31255, --cropped--> 31254
  Registration->register: reg_points=torch.Size([1385, 6]), translation=tensor([-1.8250, -0.2370,  0.0104], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([31254, 6]) -> sampled_points=torch.Size([156270, 6]) time= 0.99 ms
  LatentFeature->update: samples=156270, new_points=4688 (closreSur>VoxDwn>Radius>Distance), all_points=850808
  TrainingPool->update: Nvs=156270 ->  close_surface_sample_idx=93207, all_points=28852075, increasement: 28695805
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([93207])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.753559, mean_loss=0.753647, diff=-0.000088, thres=0.000100
FrameId=184:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 28119, --cropped--> 28118
  Registration->register: reg_points=torch.Size([1245, 6]), translation=tensor([-1.8201, -0.2515,  0.0163], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([28118, 6]) -> sampled_points=torch.Size([140590, 6]) time= 1.00 ms
  LatentFeature->update: samples=140590, new_points=4116 (closreSur>VoxDwn>Radius>Distance), all_points=854924
  TrainingPool->update: Nvs=140590 ->  close_surface_sample_idx=83758, all_points=28992665, increasement: 28852075
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([83758])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.753151, mean_loss=0.753155, diff=-0.000004, thres=0.000100
FrameId=185:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 24260, --cropped--> 24259
  Registration->register: reg_points=torch.Size([1079, 6]), translation=tensor([-1.8285, -0.2788,  0.0042], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([24259, 6]) -> sampled_points=torch.Size([121295, 6]) time= 1.00 ms
  LatentFeature->update: samples=121295, new_points=3486 (closreSur>VoxDwn>Radius>Distance), all_points=858410
  TrainingPool->update: Nvs=121295 ->  close_surface_sample_idx=72305, all_points=29113960, increasement: 28992665
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([72305])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.752886, mean_loss=0.752857, diff=0.000029, thres=0.000100
FrameId=186:  cached_time=2.0 ms
  TumDataset->next_frame: Original=307200 -downsample-> 22763, --cropped--> 22758
  Registration->register: reg_points=torch.Size([1033, 6]), translation=tensor([-1.8807, -0.2688, -0.0071], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([22758, 6]) -> sampled_points=torch.Size([113790, 6]) time= 0.96 ms
  LatentFeature->update: samples=113790, new_points=3279 (closreSur>VoxDwn>Radius>Distance), all_points=861689
  TrainingPool->update: Nvs=113790 ->  close_surface_sample_idx=67766, all_points=29227750, increasement: 29113960
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([67766])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.751240, mean_loss=0.751189, diff=0.000051, thres=0.000100
FrameId=187:  cached_time=2.1 ms
  TumDataset->next_frame: Original=307200 -downsample-> 21180, --cropped--> 21171
  Registration->register: reg_points=torch.Size([955, 6]), translation=tensor([-1.8859, -0.2721,  0.0120], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([21171, 6]) -> sampled_points=torch.Size([105855, 6]) time= 0.97 ms
  LatentFeature->update: samples=105855, new_points=3009 (closreSur>VoxDwn>Radius>Distance), all_points=864698
  TrainingPool->update: Nvs=105855 ->  close_surface_sample_idx=63015, all_points=29333605, increasement: 29227750
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([63015])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.752131, mean_loss=0.752228, diff=-0.000097, thres=0.000100
FrameId=188:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 21433, --cropped--> 21422
  Registration->register: reg_points=torch.Size([986, 6]), translation=tensor([-1.8913, -0.2669,  0.0072], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([21422, 6]) -> sampled_points=torch.Size([107110, 6]) time= 0.93 ms
  LatentFeature->update: samples=107110, new_points=3038 (closreSur>VoxDwn>Radius>Distance), all_points=867736
  TrainingPool->update: Nvs=107110 ->  close_surface_sample_idx=63729, all_points=29440715, increasement: 29333605
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([63729])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.750472, mean_loss=0.750439, diff=0.000034, thres=0.000100
FrameId=189:  cached_time=2.2 ms
  TumDataset->next_frame: Original=307200 -downsample-> 19847, --cropped--> 19836
  Registration->register: reg_points=torch.Size([878, 6]), translation=tensor([-1.9040, -0.2704,  0.0062], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([19836, 6]) -> sampled_points=torch.Size([99180, 6]) time= 0.98 ms
  LatentFeature->update: samples=99180, new_points=2714 (closreSur>VoxDwn>Radius>Distance), all_points=870450
  TrainingPool->update: Nvs=99180 ->  close_surface_sample_idx=59038, all_points=29539895, increasement: 29440715
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([59038])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.750881, mean_loss=0.750829, diff=0.000052, thres=0.000100
FrameId=190:  cached_time=2.2 ms
  TumDataset->next_frame: Original=307200 -downsample-> 18867, --cropped--> 18862
  Registration->register: reg_points=torch.Size([843, 6]), translation=tensor([-1.9178, -0.2708,  0.0049], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([18862, 6]) -> sampled_points=torch.Size([94310, 6]) time= 0.96 ms
  LatentFeature->update: samples=94310, new_points=2630 (closreSur>VoxDwn>Radius>Distance), all_points=873080
  TrainingPool->update: Nvs=94310 ->  close_surface_sample_idx=56145, all_points=29634205, increasement: 29539895
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([56145])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.750897, mean_loss=0.750980, diff=-0.000082, thres=0.000100
FrameId=191:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 19319, --cropped--> 19318
  Registration->register: reg_points=torch.Size([882, 6]), translation=tensor([-1.9295, -0.2702,  0.0020], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([19318, 6]) -> sampled_points=torch.Size([96590, 6]) time= 0.82 ms
  LatentFeature->update: samples=96590, new_points=2756 (closreSur>VoxDwn>Radius>Distance), all_points=875836
  TrainingPool->update: Nvs=96590 ->  close_surface_sample_idx=57429, all_points=29730795, increasement: 29634205
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([57429])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.751250, mean_loss=0.751287, diff=-0.000038, thres=0.000100
FrameId=192:  cached_time=2.2 ms
  TumDataset->next_frame: Original=307200 -downsample-> 20116, --cropped--> 20115
  Registration->register: reg_points=torch.Size([937, 6]), translation=tensor([-1.9412, -0.2636,  0.0066], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([20115, 6]) -> sampled_points=torch.Size([100575, 6]) time= 0.96 ms
  LatentFeature->update: samples=100575, new_points=2870 (closreSur>VoxDwn>Radius>Distance), all_points=878706
  TrainingPool->update: Nvs=100575 ->  close_surface_sample_idx=59780, all_points=29831370, increasement: 29730795
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([59780])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.749749, mean_loss=0.749732, diff=0.000017, thres=0.000100
FrameId=193:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 21159, --cropped--> 21158
  Registration->register: reg_points=torch.Size([963, 6]), translation=tensor([-1.9369, -0.2437,  0.0102], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([21158, 6]) -> sampled_points=torch.Size([105790, 6]) time= 0.99 ms
  LatentFeature->update: samples=105790, new_points=3038 (closreSur>VoxDwn>Radius>Distance), all_points=881744
  TrainingPool->update: Nvs=105790 ->  close_surface_sample_idx=63084, all_points=29937160, increasement: 29831370
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([63084])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.750876, mean_loss=0.750844, diff=0.000032, thres=0.000100
FrameId=194:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 22127, --cropped--> 22126
  Registration->register: reg_points=torch.Size([991, 6]), translation=tensor([-1.9520, -0.2267,  0.0126], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([22126, 6]) -> sampled_points=torch.Size([110630, 6]) time= 0.99 ms
  LatentFeature->update: samples=110630, new_points=3183 (closreSur>VoxDwn>Radius>Distance), all_points=884927
  TrainingPool->update: Nvs=110630 ->  close_surface_sample_idx=65906, all_points=30047790, increasement: 29937160
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([65906])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.749844, mean_loss=0.749889, diff=-0.000045, thres=0.000100
FrameId=195:  cached_time=2.0 ms
  TumDataset->next_frame: Original=307200 -downsample-> 23014, --cropped--> 23013
  Registration->register: reg_points=torch.Size([1042, 6]), translation=tensor([-1.9718e+00, -2.3404e-01,  1.6477e-03], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([23013, 6]) -> sampled_points=torch.Size([115065, 6]) time= 0.83 ms
  LatentFeature->update: samples=115065, new_points=3332 (closreSur>VoxDwn>Radius>Distance), all_points=888259
  TrainingPool->update: Nvs=115065 ->  close_surface_sample_idx=68571, all_points=30162855, increasement: 30047790
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([68571])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.750270, mean_loss=0.750294, diff=-0.000024, thres=0.000100
FrameId=196:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 23345, --cropped--> 23344
  Registration->register: reg_points=torch.Size([1058, 6]), translation=tensor([-1.9599, -0.2080, -0.0021], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([23344, 6]) -> sampled_points=torch.Size([116720, 6]) time= 0.99 ms
  LatentFeature->update: samples=116720, new_points=3336 (closreSur>VoxDwn>Radius>Distance), all_points=891595
  TrainingPool->update: Nvs=116720 ->  close_surface_sample_idx=69430, all_points=30279575, increasement: 30162855
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([69430])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.750330, mean_loss=0.750414, diff=-0.000083, thres=0.000100
FrameId=197:  cached_time=2.0 ms
  TumDataset->next_frame: Original=307200 -downsample-> 24372, --cropped--> 24371
  Registration->register: reg_points=torch.Size([1112, 6]), translation=tensor([-1.9981, -0.1724, -0.0121], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([24371, 6]) -> sampled_points=torch.Size([121855, 6]) time= 0.90 ms
  LatentFeature->update: samples=121855, new_points=3518 (closreSur>VoxDwn>Radius>Distance), all_points=895113
  TrainingPool->update: Nvs=121855 ->  close_surface_sample_idx=72723, all_points=30401430, increasement: 30279575
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([72723])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.750394, mean_loss=0.750414, diff=-0.000020, thres=0.000100
FrameId=198:  cached_time=2.0 ms
  TumDataset->next_frame: Original=307200 -downsample-> 24480, --cropped--> 24479
  Registration->register: reg_points=torch.Size([1100, 6]), translation=tensor([-2.0133, -0.1790, -0.0197], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([24479, 6]) -> sampled_points=torch.Size([122395, 6]) time= 0.94 ms
  LatentFeature->update: samples=122395, new_points=3531 (closreSur>VoxDwn>Radius>Distance), all_points=898644
  TrainingPool->update: Nvs=122395 ->  close_surface_sample_idx=72940, all_points=30523825, increasement: 30401430
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([72940])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.751058, mean_loss=0.751116, diff=-0.000058, thres=0.000100
FrameId=199:  cached_time=2.1 ms
  TumDataset->next_frame: Original=307200 -downsample-> 24933, --cropped--> 24932
  Registration->register: reg_points=torch.Size([1095, 6]), translation=tensor([-2.0160, -0.1565, -0.0173], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([24932, 6]) -> sampled_points=torch.Size([124660, 6]) time= 0.88 ms
  LatentFeature->update: samples=124660, new_points=3530 (closreSur>VoxDwn>Radius>Distance), all_points=902174
  TrainingPool->update: Nvs=124660 ->  close_surface_sample_idx=74215, all_points=30648485, increasement: 30523825
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([74215])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.749986, mean_loss=0.749978, diff=0.000008, thres=0.000100
FrameId=200:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 25688, --cropped--> 25687
  Registration->register: reg_points=torch.Size([1129, 6]), translation=tensor([-2.0203, -0.1470, -0.0286], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([25687, 6]) -> sampled_points=torch.Size([128435, 6]) time= 0.95 ms
  LatentFeature->update: samples=128435, new_points=3695 (closreSur>VoxDwn>Radius>Distance), all_points=905869
  TrainingPool->update: Nvs=128435 ->  close_surface_sample_idx=76626, all_points=30776920, increasement: 30648485
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([76626])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.749865, mean_loss=0.749840, diff=0.000025, thres=0.000100
FrameId=201:  cached_time=2.1 ms
  TumDataset->next_frame: Original=307200 -downsample-> 27643, --cropped--> 27642
  Registration->register: reg_points=torch.Size([1221, 6]), translation=tensor([-2.0382, -0.1097, -0.0335], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([27642, 6]) -> sampled_points=torch.Size([138210, 6]) time= 0.97 ms
  LatentFeature->update: samples=138210, new_points=4006 (closreSur>VoxDwn>Radius>Distance), all_points=909875
  TrainingPool->update: Nvs=138210 ->  close_surface_sample_idx=82426, all_points=30915130, increasement: 30776920
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([82426])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.749449, mean_loss=0.749399, diff=0.000050, thres=0.000100
FrameId=202:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 29041, --cropped--> 29040
  Registration->register: reg_points=torch.Size([1246, 6]), translation=tensor([-2.0522, -0.1044, -0.0328], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([29040, 6]) -> sampled_points=torch.Size([145200, 6]) time= 1.02 ms
  LatentFeature->update: samples=145200, new_points=4167 (closreSur>VoxDwn>Radius>Distance), all_points=914042
  TrainingPool->update: Nvs=145200 ->  close_surface_sample_idx=86499, all_points=31060330, increasement: 30915130
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([86499])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.750072, mean_loss=0.750124, diff=-0.000052, thres=0.000100
FrameId=203:  cached_time=2.0 ms
  TumDataset->next_frame: Original=307200 -downsample-> 30812, --cropped--> 30811
  Registration->register: reg_points=torch.Size([1345, 6]), translation=tensor([-2.0428, -0.1027, -0.0335], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([30811, 6]) -> sampled_points=torch.Size([154055, 6]) time= 0.97 ms
  LatentFeature->update: samples=154055, new_points=4456 (closreSur>VoxDwn>Radius>Distance), all_points=918498
  TrainingPool->update: Nvs=154055 ->  close_surface_sample_idx=91896, all_points=31214385, increasement: 31060330
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([91896])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.750118, mean_loss=0.750064, diff=0.000054, thres=0.000100
FrameId=204:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 31416, --cropped--> 31415
  Registration->register: reg_points=torch.Size([1407, 6]), translation=tensor([-2.0950, -0.0678, -0.0607], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([31415, 6]) -> sampled_points=torch.Size([157075, 6]) time= 1.01 ms
  LatentFeature->update: samples=157075, new_points=4623 (closreSur>VoxDwn>Radius>Distance), all_points=923121
  TrainingPool->update: Nvs=157075 ->  close_surface_sample_idx=93676, all_points=31371460, increasement: 31214385
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([93676])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.749981, mean_loss=0.750061, diff=-0.000080, thres=0.000100
FrameId=205:  cached_time=2.0 ms
  TumDataset->next_frame: Original=307200 -downsample-> 30774, --cropped--> 30773
  Registration->register: reg_points=torch.Size([1343, 6]), translation=tensor([-2.0970, -0.0429, -0.0721], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([30773, 6]) -> sampled_points=torch.Size([153865, 6]) time= 0.95 ms
  LatentFeature->update: samples=153865, new_points=4465 (closreSur>VoxDwn>Radius>Distance), all_points=927586
  TrainingPool->update: Nvs=153865 ->  close_surface_sample_idx=91702, all_points=31525325, increasement: 31371460
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([91702])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.748861, mean_loss=0.748868, diff=-0.000007, thres=0.000100
FrameId=206:  cached_time=2.0 ms
  TumDataset->next_frame: Original=307200 -downsample-> 31402, --cropped--> 31401
  Registration->register: reg_points=torch.Size([1359, 6]), translation=tensor([-2.1113, -0.0449, -0.0752], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([31401, 6]) -> sampled_points=torch.Size([157005, 6]) time= 1.00 ms
  LatentFeature->update: samples=157005, new_points=4608 (closreSur>VoxDwn>Radius>Distance), all_points=932194
  TrainingPool->update: Nvs=157005 ->  close_surface_sample_idx=93620, all_points=31682330, increasement: 31525325
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([93620])
  TrainingPool->train: break at iter=54, cur_mean_loss=0.750318, mean_loss=0.750338, diff=-0.000020, thres=0.000100
FrameId=207:  cached_time=2.0 ms
  TumDataset->next_frame: Original=307200 -downsample-> 31240, --cropped--> 31239
  Registration->register: reg_points=torch.Size([1335, 6]), translation=tensor([-2.0925, -0.0377, -0.0722], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([31239, 6]) -> sampled_points=torch.Size([156195, 6]) time= 0.99 ms
  LatentFeature->update: samples=156195, new_points=4493 (closreSur>VoxDwn>Radius>Distance), all_points=936687
  TrainingPool->update: Nvs=156195 ->  close_surface_sample_idx=93112, all_points=31838525, increasement: 31682330
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([93112])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.749411, mean_loss=0.749456, diff=-0.000045, thres=0.000100
FrameId=208:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 30759, --cropped--> 30758
  Registration->register: reg_points=torch.Size([1311, 6]), translation=tensor([-2.0891, -0.0260, -0.0725], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([30758, 6]) -> sampled_points=torch.Size([153790, 6]) time= 0.99 ms
  LatentFeature->update: samples=153790, new_points=4376 (closreSur>VoxDwn>Radius>Distance), all_points=941063
  TrainingPool->update: Nvs=153790 ->  close_surface_sample_idx=91680, all_points=31992315, increasement: 31838525
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([91680])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.749705, mean_loss=0.749654, diff=0.000051, thres=0.000100
FrameId=209:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 30251, --cropped--> 30250
  Registration->register: reg_points=torch.Size([1270, 6]), translation=tensor([-2.0737, -0.0066, -0.0681], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([30250, 6]) -> sampled_points=torch.Size([151250, 6]) time= 1.01 ms
  LatentFeature->update: samples=151250, new_points=4264 (closreSur>VoxDwn>Radius>Distance), all_points=945327
  TrainingPool->update: Nvs=151250 ->  close_surface_sample_idx=90159, all_points=32143565, increasement: 31992315
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([90159])
  TrainingPool->train: break at iter=54, cur_mean_loss=0.748674, mean_loss=0.748689, diff=-0.000014, thres=0.000100
FrameId=210:  cached_time=2.0 ms
  TumDataset->next_frame: Original=307200 -downsample-> 29425, --cropped--> 29424
  Registration->register: reg_points=torch.Size([1227, 6]), translation=tensor([-2.0562, -0.0049, -0.0690], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([29424, 6]) -> sampled_points=torch.Size([147120, 6]) time= 1.01 ms
  LatentFeature->update: samples=147120, new_points=4147 (closreSur>VoxDwn>Radius>Distance), all_points=949474
  TrainingPool->update: Nvs=147120 ->  close_surface_sample_idx=87690, all_points=32290685, increasement: 32143565
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([87690])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.748804, mean_loss=0.748866, diff=-0.000062, thres=0.000100
FrameId=211:  cached_time=2.1 ms
  TumDataset->next_frame: Original=307200 -downsample-> 28156, --cropped--> 28155
  Registration->register: reg_points=torch.Size([1171, 6]), translation=tensor([-2.0649,  0.0077, -0.0749], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([28155, 6]) -> sampled_points=torch.Size([140775, 6]) time= 1.01 ms
  LatentFeature->update: samples=140775, new_points=3934 (closreSur>VoxDwn>Radius>Distance), all_points=953408
  TrainingPool->update: Nvs=140775 ->  close_surface_sample_idx=84059, all_points=32431460, increasement: 32290685
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([84059])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.748989, mean_loss=0.748890, diff=0.000099, thres=0.000100
FrameId=212:  cached_time=2.0 ms
  TumDataset->next_frame: Original=307200 -downsample-> 26769, --cropped--> 26768
  Registration->register: reg_points=torch.Size([1127, 6]), translation=tensor([-2.0483,  0.0226, -0.0688], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([26768, 6]) -> sampled_points=torch.Size([133840, 6]) time= 0.99 ms
  LatentFeature->update: samples=133840, new_points=3729 (closreSur>VoxDwn>Radius>Distance), all_points=957137
  TrainingPool->update: Nvs=133840 ->  close_surface_sample_idx=79705, all_points=32565300, increasement: 32431460
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([79705])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.749507, mean_loss=0.749546, diff=-0.000039, thres=0.000100
FrameId=213:  cached_time=2.0 ms
  TumDataset->next_frame: Original=307200 -downsample-> 24980, --cropped--> 24979
  Registration->register: reg_points=torch.Size([1048, 6]), translation=tensor([-2.0438,  0.0253, -0.0636], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([24979, 6]) -> sampled_points=torch.Size([124895, 6]) time= 0.86 ms
  LatentFeature->update: samples=124895, new_points=3448 (closreSur>VoxDwn>Radius>Distance), all_points=960585
  TrainingPool->update: Nvs=124895 ->  close_surface_sample_idx=74483, all_points=32690195, increasement: 32565300
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([74483])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.748286, mean_loss=0.748195, diff=0.000091, thres=0.000100
FrameId=214:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 23218, --cropped--> 23217
  Registration->register: reg_points=torch.Size([977, 6]), translation=tensor([-2.0448,  0.0242, -0.0641], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([23217, 6]) -> sampled_points=torch.Size([116085, 6]) time= 0.99 ms
  LatentFeature->update: samples=116085, new_points=3181 (closreSur>VoxDwn>Radius>Distance), all_points=963766
  TrainingPool->update: Nvs=116085 ->  close_surface_sample_idx=69184, all_points=32806280, increasement: 32690195
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([69184])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.748440, mean_loss=0.748417, diff=0.000023, thres=0.000100
FrameId=215:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 21545, --cropped--> 21544
  Registration->register: reg_points=torch.Size([928, 6]), translation=tensor([-2.0611,  0.0584, -0.0838], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([21544, 6]) -> sampled_points=torch.Size([107720, 6]) time= 0.93 ms
  LatentFeature->update: samples=107720, new_points=2927 (closreSur>VoxDwn>Radius>Distance), all_points=966693
  TrainingPool->update: Nvs=107720 ->  close_surface_sample_idx=64232, all_points=32914000, increasement: 32806280
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([64232])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.748933, mean_loss=0.748934, diff=-0.000001, thres=0.000100
FrameId=216:  cached_time=2.0 ms
  TumDataset->next_frame: Original=307200 -downsample-> 20846, --cropped--> 20845
  Registration->register: reg_points=torch.Size([884, 6]), translation=tensor([-2.0793,  0.0848, -0.1009], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([20845, 6]) -> sampled_points=torch.Size([104225, 6]) time= 0.93 ms
  LatentFeature->update: samples=104225, new_points=2827 (closreSur>VoxDwn>Radius>Distance), all_points=969520
  TrainingPool->update: Nvs=104225 ->  close_surface_sample_idx=62119, all_points=33018225, increasement: 32914000
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([62119])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.749052, mean_loss=0.748987, diff=0.000065, thres=0.000100
FrameId=217:  cached_time=2.0 ms
  TumDataset->next_frame: Original=307200 -downsample-> 19844, --cropped--> 19843
  Registration->register: reg_points=torch.Size([868, 6]), translation=tensor([-2.0895,  0.1010, -0.1109], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([19843, 6]) -> sampled_points=torch.Size([99215, 6]) time= 0.95 ms
  LatentFeature->update: samples=99215, new_points=2704 (closreSur>VoxDwn>Radius>Distance), all_points=972224
  TrainingPool->update: Nvs=99215 ->  close_surface_sample_idx=59001, all_points=33117440, increasement: 33018225
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([59001])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.748639, mean_loss=0.748543, diff=0.000096, thres=0.000100
FrameId=218:  cached_time=2.0 ms
  TumDataset->next_frame: Original=307200 -downsample-> 18969, --cropped--> 18968
  Registration->register: reg_points=torch.Size([864, 6]), translation=tensor([-2.0944,  0.1141, -0.1122], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([18968, 6]) -> sampled_points=torch.Size([94840, 6]) time= 0.99 ms
  LatentFeature->update: samples=94840, new_points=2597 (closreSur>VoxDwn>Radius>Distance), all_points=974821
  TrainingPool->update: Nvs=94840 ->  close_surface_sample_idx=56459, all_points=33212280, increasement: 33117440
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([56459])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.747757, mean_loss=0.747788, diff=-0.000031, thres=0.000100
FrameId=219:  cached_time=2.0 ms
  TumDataset->next_frame: Original=307200 -downsample-> 18575, --cropped--> 18574
  Registration->register: reg_points=torch.Size([817, 6]), translation=tensor([-2.0974,  0.1180, -0.1311], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([18574, 6]) -> sampled_points=torch.Size([92870, 6]) time= 1.01 ms
  LatentFeature->update: samples=92870, new_points=2529 (closreSur>VoxDwn>Radius>Distance), all_points=977350
  TrainingPool->update: Nvs=92870 ->  close_surface_sample_idx=55278, all_points=33305150, increasement: 33212280
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([55278])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.747812, mean_loss=0.747832, diff=-0.000019, thres=0.000100
FrameId=220:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 18384, --cropped--> 18383
  Registration->register: reg_points=torch.Size([809, 6]), translation=tensor([-2.1060,  0.1212, -0.1250], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([18383, 6]) -> sampled_points=torch.Size([91915, 6]) time= 0.86 ms
  LatentFeature->update: samples=91915, new_points=2473 (closreSur>VoxDwn>Radius>Distance), all_points=979823
  TrainingPool->update: Nvs=91915 ->  close_surface_sample_idx=54753, all_points=33397065, increasement: 33305150
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([54753])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.749097, mean_loss=0.749041, diff=0.000056, thres=0.000100
FrameId=221:  cached_time=2.2 ms
  TumDataset->next_frame: Original=307200 -downsample-> 17734, --cropped--> 17733
  Registration->register: reg_points=torch.Size([786, 6]), translation=tensor([-2.1210,  0.1502, -0.1512], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([17733, 6]) -> sampled_points=torch.Size([88665, 6]) time= 0.84 ms
  LatentFeature->update: samples=88665, new_points=2450 (closreSur>VoxDwn>Radius>Distance), all_points=982273
  TrainingPool->update: Nvs=88665 ->  close_surface_sample_idx=52832, all_points=33485730, increasement: 33397065
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([52832])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.748902, mean_loss=0.748991, diff=-0.000089, thres=0.000100
FrameId=222:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 17815, --cropped--> 17814
  Registration->register: reg_points=torch.Size([802, 6]), translation=tensor([-2.1231,  0.1545, -0.1542], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([17814, 6]) -> sampled_points=torch.Size([89070, 6]) time= 0.91 ms
  LatentFeature->update: samples=89070, new_points=2451 (closreSur>VoxDwn>Radius>Distance), all_points=984724
  TrainingPool->update: Nvs=89070 ->  close_surface_sample_idx=52982, all_points=33574800, increasement: 33485730
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([52982])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.747559, mean_loss=0.747501, diff=0.000057, thres=0.000100
FrameId=223:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 17965, --cropped--> 17964
  Registration->register: reg_points=torch.Size([797, 6]), translation=tensor([-2.1269,  0.1726, -0.1647], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([17964, 6]) -> sampled_points=torch.Size([89820, 6]) time= 0.83 ms
  LatentFeature->update: samples=89820, new_points=2443 (closreSur>VoxDwn>Radius>Distance), all_points=987167
  TrainingPool->update: Nvs=89820 ->  close_surface_sample_idx=53409, all_points=33664620, increasement: 33574800
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([53409])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.748257, mean_loss=0.748214, diff=0.000042, thres=0.000100
FrameId=224:  cached_time=2.0 ms
  TumDataset->next_frame: Original=307200 -downsample-> 17292, --cropped--> 17291
  Registration->register: reg_points=torch.Size([748, 6]), translation=tensor([-2.1379,  0.1851, -0.1704], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([17291, 6]) -> sampled_points=torch.Size([86455, 6]) time= 0.93 ms
  LatentFeature->update: samples=86455, new_points=2286 (closreSur>VoxDwn>Radius>Distance), all_points=989453
  TrainingPool->update: Nvs=86455 ->  close_surface_sample_idx=51367, all_points=33751075, increasement: 33664620
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([51367])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.747554, mean_loss=0.747488, diff=0.000066, thres=0.000100
FrameId=225:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 16522, --cropped--> 16521
  Registration->register: reg_points=torch.Size([712, 6]), translation=tensor([-2.1477,  0.1855, -0.1918], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([16521, 6]) -> sampled_points=torch.Size([82605, 6]) time= 0.96 ms
  LatentFeature->update: samples=82605, new_points=2211 (closreSur>VoxDwn>Radius>Distance), all_points=991664
  TrainingPool->update: Nvs=82605 ->  close_surface_sample_idx=49075, all_points=33833680, increasement: 33751075
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([49075])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.747693, mean_loss=0.747699, diff=-0.000006, thres=0.000100
FrameId=226:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 16086, --cropped--> 16085
  Registration->register: reg_points=torch.Size([693, 6]), translation=tensor([-2.1365,  0.2025, -0.2014], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([16085, 6]) -> sampled_points=torch.Size([80425, 6]) time= 1.01 ms
  LatentFeature->update: samples=80425, new_points=2194 (closreSur>VoxDwn>Radius>Distance), all_points=993858
  TrainingPool->update: Nvs=80425 ->  close_surface_sample_idx=47687, all_points=33914105, increasement: 33833680
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([47687])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.748008, mean_loss=0.748084, diff=-0.000076, thres=0.000100
FrameId=227:  cached_time=2.0 ms
  TumDataset->next_frame: Original=307200 -downsample-> 15487, --cropped--> 15486
  Registration->register: reg_points=torch.Size([648, 6]), translation=tensor([-2.1363,  0.2244, -0.2136], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([15486, 6]) -> sampled_points=torch.Size([77430, 6]) time= 0.92 ms
  LatentFeature->update: samples=77430, new_points=2050 (closreSur>VoxDwn>Radius>Distance), all_points=995908
  TrainingPool->update: Nvs=77430 ->  close_surface_sample_idx=46056, all_points=33991535, increasement: 33914105
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([46056])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.748358, mean_loss=0.748426, diff=-0.000068, thres=0.000100
FrameId=228:  cached_time=2.1 ms
  TumDataset->next_frame: Original=307200 -downsample-> 16228, --cropped--> 16227
  Registration->register: reg_points=torch.Size([697, 6]), translation=tensor([-2.1188,  0.2292, -0.2229], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([16227, 6]) -> sampled_points=torch.Size([81135, 6]) time= 0.93 ms
  LatentFeature->update: samples=81135, new_points=2200 (closreSur>VoxDwn>Radius>Distance), all_points=998108
  TrainingPool->update: Nvs=81135 ->  close_surface_sample_idx=48255, all_points=34072670, increasement: 33991535
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([48255])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.747410, mean_loss=0.747402, diff=0.000008, thres=0.000100
FrameId=229:  cached_time=2.0 ms
  TumDataset->next_frame: Original=307200 -downsample-> 16377, --cropped--> 16376
  Registration->register: reg_points=torch.Size([702, 6]), translation=tensor([-2.1027,  0.2476, -0.2277], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([16376, 6]) -> sampled_points=torch.Size([81880, 6]) time= 0.92 ms
  LatentFeature->update: samples=81880, new_points=2194 (closreSur>VoxDwn>Radius>Distance), all_points=1000302
  TrainingPool->update: Nvs=81880 ->  close_surface_sample_idx=48719, all_points=34154550, increasement: 34072670
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([48719])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.748282, mean_loss=0.748199, diff=0.000082, thres=0.000100
FrameId=230:  cached_time=2.0 ms
  TumDataset->next_frame: Original=307200 -downsample-> 16696, --cropped--> 16695
  Registration->register: reg_points=torch.Size([715, 6]), translation=tensor([-2.0997,  0.2528, -0.2267], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([16695, 6]) -> sampled_points=torch.Size([83475, 6]) time= 0.96 ms
  LatentFeature->update: samples=83475, new_points=2296 (closreSur>VoxDwn>Radius>Distance), all_points=1002598
  TrainingPool->update: Nvs=83475 ->  close_surface_sample_idx=49695, all_points=34238025, increasement: 34154550
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([49695])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.748643, mean_loss=0.748625, diff=0.000018, thres=0.000100
FrameId=231:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 16629, --cropped--> 16628
  Registration->register: reg_points=torch.Size([734, 6]), translation=tensor([-2.0995,  0.2622, -0.2389], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([16628, 6]) -> sampled_points=torch.Size([83140, 6]) time= 0.98 ms
  LatentFeature->update: samples=83140, new_points=2280 (closreSur>VoxDwn>Radius>Distance), all_points=1004878
  TrainingPool->update: Nvs=83140 ->  close_surface_sample_idx=49384, all_points=34321165, increasement: 34238025
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([49384])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.748475, mean_loss=0.748453, diff=0.000022, thres=0.000100
FrameId=232:  cached_time=2.0 ms
  TumDataset->next_frame: Original=307200 -downsample-> 16150, --cropped--> 16149
  Registration->register: reg_points=torch.Size([697, 6]), translation=tensor([-2.1125,  0.2678, -0.2462], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([16149, 6]) -> sampled_points=torch.Size([80745, 6]) time= 0.97 ms
  LatentFeature->update: samples=80745, new_points=2206 (closreSur>VoxDwn>Radius>Distance), all_points=1007084
  TrainingPool->update: Nvs=80745 ->  close_surface_sample_idx=48066, all_points=34401910, increasement: 34321165
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([48066])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.747774, mean_loss=0.747862, diff=-0.000087, thres=0.000100
FrameId=233:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 16534, --cropped--> 16533
  Registration->register: reg_points=torch.Size([718, 6]), translation=tensor([-2.1011,  0.2804, -0.2481], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([16533, 6]) -> sampled_points=torch.Size([82665, 6]) time= 0.92 ms
  LatentFeature->update: samples=82665, new_points=2255 (closreSur>VoxDwn>Radius>Distance), all_points=1009339
  TrainingPool->update: Nvs=82665 ->  close_surface_sample_idx=49211, all_points=34484575, increasement: 34401910
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([49211])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.748246, mean_loss=0.748334, diff=-0.000088, thres=0.000100
FrameId=234:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 16515, --cropped--> 16514
  Registration->register: reg_points=torch.Size([743, 6]), translation=tensor([-2.0971,  0.2924, -0.2521], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([16514, 6]) -> sampled_points=torch.Size([82570, 6]) time= 0.94 ms
  LatentFeature->update: samples=82570, new_points=2306 (closreSur>VoxDwn>Radius>Distance), all_points=1011645
  TrainingPool->update: Nvs=82570 ->  close_surface_sample_idx=49190, all_points=34567145, increasement: 34484575
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([49190])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.747838, mean_loss=0.747795, diff=0.000043, thres=0.000100
FrameId=235:  cached_time=2.0 ms
  TumDataset->next_frame: Original=307200 -downsample-> 16273, --cropped--> 16272
  Registration->register: reg_points=torch.Size([720, 6]), translation=tensor([-2.0795,  0.3060, -0.2479], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([16272, 6]) -> sampled_points=torch.Size([81360, 6]) time= 0.96 ms
  LatentFeature->update: samples=81360, new_points=2245 (closreSur>VoxDwn>Radius>Distance), all_points=1013890
  TrainingPool->update: Nvs=81360 ->  close_surface_sample_idx=48420, all_points=34648505, increasement: 34567145
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([48420])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.746564, mean_loss=0.746611, diff=-0.000047, thres=0.000100
FrameId=236:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 16757, --cropped--> 16756
  Registration->register: reg_points=torch.Size([755, 6]), translation=tensor([-2.0809,  0.3151, -0.2521], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([16756, 6]) -> sampled_points=torch.Size([83780, 6]) time= 0.97 ms
  LatentFeature->update: samples=83780, new_points=2322 (closreSur>VoxDwn>Radius>Distance), all_points=1016212
  TrainingPool->update: Nvs=83780 ->  close_surface_sample_idx=49912, all_points=34732285, increasement: 34648505
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([49912])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.748695, mean_loss=0.748659, diff=0.000036, thres=0.000100
FrameId=237:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 16882, --cropped--> 16881
  Registration->register: reg_points=torch.Size([739, 6]), translation=tensor([-2.0819,  0.3376, -0.2706], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([16881, 6]) -> sampled_points=torch.Size([84405, 6]) time= 0.95 ms
  LatentFeature->update: samples=84405, new_points=2379 (closreSur>VoxDwn>Radius>Distance), all_points=1018591
  TrainingPool->update: Nvs=84405 ->  close_surface_sample_idx=50265, all_points=34816690, increasement: 34732285
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([50265])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.747356, mean_loss=0.747295, diff=0.000061, thres=0.000100
FrameId=238:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 16276, --cropped--> 16275
  Registration->register: reg_points=torch.Size([748, 6]), translation=tensor([-2.0687,  0.3217, -0.2576], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([16275, 6]) -> sampled_points=torch.Size([81375, 6]) time= 0.97 ms
  LatentFeature->update: samples=81375, new_points=2315 (closreSur>VoxDwn>Radius>Distance), all_points=1020906
  TrainingPool->update: Nvs=81375 ->  close_surface_sample_idx=48421, all_points=34898065, increasement: 34816690
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([48421])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.747908, mean_loss=0.747989, diff=-0.000081, thres=0.000100
FrameId=239:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 16554, --cropped--> 16553
  Registration->register: reg_points=torch.Size([723, 6]), translation=tensor([-2.0534,  0.3161, -0.2572], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([16553, 6]) -> sampled_points=torch.Size([82765, 6]) time= 0.95 ms
  LatentFeature->update: samples=82765, new_points=2323 (closreSur>VoxDwn>Radius>Distance), all_points=1023229
  TrainingPool->update: Nvs=82765 ->  close_surface_sample_idx=49171, all_points=34980830, increasement: 34898065
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([49171])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.748989, mean_loss=0.749073, diff=-0.000084, thres=0.000100
FrameId=240:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 15169, --cropped--> 15168
  Registration->register: reg_points=torch.Size([675, 6]), translation=tensor([-2.0555,  0.3072, -0.2687], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([15168, 6]) -> sampled_points=torch.Size([75840, 6]) time= 0.99 ms
  LatentFeature->update: samples=75840, new_points=2114 (closreSur>VoxDwn>Radius>Distance), all_points=1025343
  TrainingPool->update: Nvs=75840 ->  close_surface_sample_idx=45041, all_points=35056670, increasement: 34980830
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([45041])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.747906, mean_loss=0.747956, diff=-0.000050, thres=0.000100
FrameId=241:  cached_time=2.0 ms
  TumDataset->next_frame: Original=307200 -downsample-> 14801, --cropped--> 14800
  Registration->register: reg_points=torch.Size([659, 6]), translation=tensor([-2.0459,  0.3157, -0.2820], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([14800, 6]) -> sampled_points=torch.Size([74000, 6]) time= 0.94 ms
  LatentFeature->update: samples=74000, new_points=2071 (closreSur>VoxDwn>Radius>Distance), all_points=1027414
  TrainingPool->update: Nvs=74000 ->  close_surface_sample_idx=43997, all_points=35130670, increasement: 35056670
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([43997])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.747596, mean_loss=0.747630, diff=-0.000034, thres=0.000100
FrameId=242:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 14759, --cropped--> 14758
  Registration->register: reg_points=torch.Size([671, 6]), translation=tensor([-2.0352,  0.3380, -0.2834], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([14758, 6]) -> sampled_points=torch.Size([73790, 6]) time= 1.08 ms
  LatentFeature->update: samples=73790, new_points=2052 (closreSur>VoxDwn>Radius>Distance), all_points=1029466
  TrainingPool->update: Nvs=73790 ->  close_surface_sample_idx=43823, all_points=35204460, increasement: 35130670
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([43823])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.748676, mean_loss=0.748746, diff=-0.000070, thres=0.000100
FrameId=243:  cached_time=2.0 ms
  TumDataset->next_frame: Original=307200 -downsample-> 14203, --cropped--> 14202
  Registration->register: reg_points=torch.Size([643, 6]), translation=tensor([-2.0361,  0.3249, -0.2954], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([14202, 6]) -> sampled_points=torch.Size([71010, 6]) time= 0.93 ms
  LatentFeature->update: samples=71010, new_points=1963 (closreSur>VoxDwn>Radius>Distance), all_points=1031429
  TrainingPool->update: Nvs=71010 ->  close_surface_sample_idx=42014, all_points=35275470, increasement: 35204460
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([42014])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.747087, mean_loss=0.747149, diff=-0.000062, thres=0.000100
FrameId=244:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 14246, --cropped--> 14245
  Registration->register: reg_points=torch.Size([632, 6]), translation=tensor([-2.0274,  0.3495, -0.2977], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([14245, 6]) -> sampled_points=torch.Size([71225, 6]) time= 0.91 ms
  LatentFeature->update: samples=71225, new_points=1974 (closreSur>VoxDwn>Radius>Distance), all_points=1033403
  TrainingPool->update: Nvs=71225 ->  close_surface_sample_idx=42113, all_points=35346695, increasement: 35275470
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([42113])
  TrainingPool->train: break at iter=54, cur_mean_loss=0.748632, mean_loss=0.748606, diff=0.000026, thres=0.000100
FrameId=245:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 14472, --cropped--> 14471
  Registration->register: reg_points=torch.Size([648, 6]), translation=tensor([-2.0309,  0.3243, -0.2869], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([14471, 6]) -> sampled_points=torch.Size([72355, 6]) time= 0.94 ms
  LatentFeature->update: samples=72355, new_points=2031 (closreSur>VoxDwn>Radius>Distance), all_points=1035434
  TrainingPool->update: Nvs=72355 ->  close_surface_sample_idx=42936, all_points=35419050, increasement: 35346695
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([42936])
  TrainingPool->train: break at iter=54, cur_mean_loss=0.747285, mean_loss=0.747383, diff=-0.000098, thres=0.000100
FrameId=246:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 14622, --cropped--> 14621
  Registration->register: reg_points=torch.Size([664, 6]), translation=tensor([-2.0206,  0.3293, -0.2777], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([14621, 6]) -> sampled_points=torch.Size([73105, 6]) time= 0.98 ms
  LatentFeature->update: samples=73105, new_points=2041 (closreSur>VoxDwn>Radius>Distance), all_points=1037475
  TrainingPool->update: Nvs=73105 ->  close_surface_sample_idx=43470, all_points=35492155, increasement: 35419050
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([43470])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.747149, mean_loss=0.747087, diff=0.000062, thres=0.000100
FrameId=247:  cached_time=2.0 ms
  TumDataset->next_frame: Original=307200 -downsample-> 14762, --cropped--> 14761
  Registration->register: reg_points=torch.Size([662, 6]), translation=tensor([-2.0165,  0.3399, -0.2867], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([14761, 6]) -> sampled_points=torch.Size([73805, 6]) time= 0.98 ms
  LatentFeature->update: samples=73805, new_points=2047 (closreSur>VoxDwn>Radius>Distance), all_points=1039522
  TrainingPool->update: Nvs=73805 ->  close_surface_sample_idx=43826, all_points=35565960, increasement: 35492155
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([43826])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.754521, mean_loss=0.754540, diff=-0.000019, thres=0.000100
FrameId=248:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 14482, --cropped--> 14481
  Registration->register: reg_points=torch.Size([665, 6]), translation=tensor([-2.0132,  0.2994, -0.2776], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([14481, 6]) -> sampled_points=torch.Size([72405, 6]) time= 0.99 ms
  LatentFeature->update: samples=72405, new_points=1993 (closreSur>VoxDwn>Radius>Distance), all_points=1041515
  TrainingPool->update: Nvs=72405 ->  close_surface_sample_idx=43033, all_points=35638365, increasement: 35565960
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([43033])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.760237, mean_loss=0.760289, diff=-0.000052, thres=0.000100
FrameId=249:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 14274, --cropped--> 14273
  Registration->register: reg_points=torch.Size([625, 6]), translation=tensor([-1.9879,  0.3154, -0.2703], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([14273, 6]) -> sampled_points=torch.Size([71365, 6]) time= 0.96 ms
  LatentFeature->update: samples=71365, new_points=1946 (closreSur>VoxDwn>Radius>Distance), all_points=1043461
  TrainingPool->update: Nvs=71365 ->  close_surface_sample_idx=42296, all_points=35709730, increasement: 35638365
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([42296])
  TrainingPool->train: break at iter=54, cur_mean_loss=0.762097, mean_loss=0.762176, diff=-0.000079, thres=0.000100
FrameId=250:  cached_time=2.0 ms
  TumDataset->next_frame: Original=307200 -downsample-> 13853, --cropped--> 13852
  Registration->register: reg_points=torch.Size([591, 6]), translation=tensor([-1.9976,  0.3056, -0.2731], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([13852, 6]) -> sampled_points=torch.Size([69260, 6]) time= 0.98 ms
  LatentFeature->update: samples=69260, new_points=1897 (closreSur>VoxDwn>Radius>Distance), all_points=1045358
  TrainingPool->update: Nvs=69260 ->  close_surface_sample_idx=41115, all_points=35778990, increasement: 35709730
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([41115])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.764065, mean_loss=0.764148, diff=-0.000083, thres=0.000100
FrameId=251:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 13942, --cropped--> 13941
  Registration->register: reg_points=torch.Size([607, 6]), translation=tensor([-1.9989,  0.2899, -0.2629], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([13941, 6]) -> sampled_points=torch.Size([69705, 6]) time= 0.88 ms
  LatentFeature->update: samples=69705, new_points=1911 (closreSur>VoxDwn>Radius>Distance), all_points=1047269
  TrainingPool->update: Nvs=69705 ->  close_surface_sample_idx=41276, all_points=35848695, increasement: 35778990
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([41276])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.767186, mean_loss=0.767236, diff=-0.000051, thres=0.000100
FrameId=252:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 13725, --cropped--> 13724
  Registration->register: reg_points=torch.Size([597, 6]), translation=tensor([-1.9926,  0.2738, -0.2451], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([13724, 6]) -> sampled_points=torch.Size([68620, 6]) time= 1.04 ms
  LatentFeature->update: samples=68620, new_points=1857 (closreSur>VoxDwn>Radius>Distance), all_points=1049126
  TrainingPool->update: Nvs=68620 ->  close_surface_sample_idx=40759, all_points=35917315, increasement: 35848695
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([40759])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.769426, mean_loss=0.769519, diff=-0.000093, thres=0.000100
FrameId=253:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 13420, --cropped--> 13419
  Registration->register: reg_points=torch.Size([590, 6]), translation=tensor([-1.9749,  0.2643, -0.2456], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([13419, 6]) -> sampled_points=torch.Size([67095, 6]) time= 0.87 ms
  LatentFeature->update: samples=67095, new_points=1851 (closreSur>VoxDwn>Radius>Distance), all_points=1050977
  TrainingPool->update: Nvs=67095 ->  close_surface_sample_idx=40028, all_points=35984410, increasement: 35917315
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([40028])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.772745, mean_loss=0.772708, diff=0.000037, thres=0.000100
FrameId=254:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 13161, --cropped--> 13160
  Registration->register: reg_points=torch.Size([548, 6]), translation=tensor([-1.9881,  0.2385, -0.2537], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([13160, 6]) -> sampled_points=torch.Size([65800, 6]) time= 0.89 ms
  LatentFeature->update: samples=65800, new_points=1784 (closreSur>VoxDwn>Radius>Distance), all_points=1052761
  TrainingPool->update: Nvs=65800 ->  close_surface_sample_idx=39143, all_points=36050210, increasement: 35984410
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([39143])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.771631, mean_loss=0.771692, diff=-0.000061, thres=0.000100
FrameId=255:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 12140, --cropped--> 12139
  Registration->register: reg_points=torch.Size([501, 6]), translation=tensor([-1.9895,  0.2163, -0.2478], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([12139, 6]) -> sampled_points=torch.Size([60695, 6]) time= 0.97 ms
  LatentFeature->update: samples=60695, new_points=1591 (closreSur>VoxDwn>Radius>Distance), all_points=1054352
  TrainingPool->update: Nvs=60695 ->  close_surface_sample_idx=35948, all_points=36110905, increasement: 36050210
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([35948])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.772541, mean_loss=0.772617, diff=-0.000076, thres=0.000100
FrameId=256:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 12099, --cropped--> 12098
  Registration->register: reg_points=torch.Size([490, 6]), translation=tensor([-1.9787,  0.2237, -0.2484], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([12098, 6]) -> sampled_points=torch.Size([60490, 6]) time= 1.01 ms
  LatentFeature->update: samples=60490, new_points=1571 (closreSur>VoxDwn>Radius>Distance), all_points=1055923
  TrainingPool->update: Nvs=60490 ->  close_surface_sample_idx=35902, all_points=36171395, increasement: 36110905
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([35902])
  TrainingPool->train: break at iter=55, cur_mean_loss=0.774879, mean_loss=0.774841, diff=0.000038, thres=0.000100
FrameId=257:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 11981, --cropped--> 11980
  Registration->register: reg_points=torch.Size([486, 6]), translation=tensor([-1.9836,  0.1785, -0.2408], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([11980, 6]) -> sampled_points=torch.Size([59900, 6]) time= 0.92 ms
  LatentFeature->update: samples=59900, new_points=1536 (closreSur>VoxDwn>Radius>Distance), all_points=1057459
  TrainingPool->update: Nvs=59900 ->  close_surface_sample_idx=35548, all_points=36231295, increasement: 36171395
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([35548])
  TrainingPool->train: break at iter=55, cur_mean_loss=0.774463, mean_loss=0.774404, diff=0.000059, thres=0.000100
FrameId=258:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 11831, --cropped--> 11830
  Registration->register: reg_points=torch.Size([470, 6]), translation=tensor([-2.0138,  0.1394, -0.2397], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([11830, 6]) -> sampled_points=torch.Size([59150, 6]) time= 0.90 ms
  LatentFeature->update: samples=59150, new_points=1475 (closreSur>VoxDwn>Radius>Distance), all_points=1058934
  TrainingPool->update: Nvs=59150 ->  close_surface_sample_idx=35083, all_points=36290445, increasement: 36231295
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([35083])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.775709, mean_loss=0.775776, diff=-0.000067, thres=0.000100
FrameId=259:  cached_time=2.3 ms
  TumDataset->next_frame: Original=307200 -downsample-> 11284, --cropped--> 11283
  Registration->register: reg_points=torch.Size([442, 6]), translation=tensor([-1.9735,  0.1814, -0.2362], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([11283, 6]) -> sampled_points=torch.Size([56415, 6]) time= 0.88 ms
  LatentFeature->update: samples=56415, new_points=1413 (closreSur>VoxDwn>Radius>Distance), all_points=1060347
  TrainingPool->update: Nvs=56415 ->  close_surface_sample_idx=33608, all_points=36346860, increasement: 36290445
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([33608])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.776350, mean_loss=0.776419, diff=-0.000069, thres=0.000100
FrameId=260:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 10656, --cropped--> 10655
  Registration->register: reg_points=torch.Size([417, 6]), translation=tensor([-1.9733,  0.1335, -0.2232], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([10655, 6]) -> sampled_points=torch.Size([53275, 6]) time= 0.38 ms
  LatentFeature->update: samples=53275, new_points=1335 (closreSur>VoxDwn>Radius>Distance), all_points=1061682
  TrainingPool->update: Nvs=53275 ->  close_surface_sample_idx=31734, all_points=36400135, increasement: 36346860
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([31734])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.776422, mean_loss=0.776439, diff=-0.000017, thres=0.000100
FrameId=261:  cached_time=5.3 ms
  TumDataset->next_frame: Original=307200 -downsample-> 10392, --cropped--> 10391
  Registration->register: reg_points=torch.Size([400, 6]), translation=tensor([-1.9703,  0.1283, -0.2203], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([10391, 6]) -> sampled_points=torch.Size([51955, 6]) time= 0.43 ms
  LatentFeature->update: samples=51955, new_points=1274 (closreSur>VoxDwn>Radius>Distance), all_points=1062956
  TrainingPool->update: Nvs=51955 ->  close_surface_sample_idx=30927, all_points=36452090, increasement: 36400135
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([30927])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.776927, mean_loss=0.776995, diff=-0.000068, thres=0.000100
FrameId=262:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 10020, --cropped--> 10019
  Registration->register: reg_points=torch.Size([374, 6]), translation=tensor([-1.9914,  0.1359, -0.2274], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([10019, 6]) -> sampled_points=torch.Size([50095, 6]) time= 0.36 ms
  LatentFeature->update: samples=50095, new_points=1220 (closreSur>VoxDwn>Radius>Distance), all_points=1064176
  TrainingPool->update: Nvs=50095 ->  close_surface_sample_idx=29724, all_points=36502185, increasement: 36452090
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([29724])
  TrainingPool->train: break at iter=56, cur_mean_loss=0.776502, mean_loss=0.776539, diff=-0.000037, thres=0.000100
FrameId=263:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 9763, --cropped--> 9762
  Registration->register: reg_points=torch.Size([362, 6]), translation=tensor([-1.9967,  0.1989, -0.2541], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([9762, 6]) -> sampled_points=torch.Size([48810, 6]) time= 0.38 ms
  LatentFeature->update: samples=48810, new_points=1177 (closreSur>VoxDwn>Radius>Distance), all_points=1065353
  TrainingPool->update: Nvs=48810 ->  close_surface_sample_idx=29070, all_points=36550995, increasement: 36502185
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([29070])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.778097, mean_loss=0.778144, diff=-0.000047, thres=0.000100
FrameId=264:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 9802, --cropped--> 9801
  Registration->register: reg_points=torch.Size([355, 6]), translation=tensor([-2.0179,  0.1607, -0.2554], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([9801, 6]) -> sampled_points=torch.Size([49005, 6]) time= 0.38 ms
  LatentFeature->update: samples=49005, new_points=1172 (closreSur>VoxDwn>Radius>Distance), all_points=1066525
  TrainingPool->update: Nvs=49005 ->  close_surface_sample_idx=29179, all_points=36600000, increasement: 36550995
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([29179])
  TrainingPool->train: break at iter=54, cur_mean_loss=0.777977, mean_loss=0.777970, diff=0.000007, thres=0.000100
FrameId=265:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 9564, --cropped--> 9563
  Registration->register: reg_points=torch.Size([349, 6]), translation=tensor([-2.0094,  0.1410, -0.2428], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([9563, 6]) -> sampled_points=torch.Size([47815, 6]) time= 0.38 ms
  LatentFeature->update: samples=47815, new_points=1155 (closreSur>VoxDwn>Radius>Distance), all_points=1067680
  TrainingPool->update: Nvs=47815 ->  close_surface_sample_idx=28496, all_points=36647815, increasement: 36600000
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([28496])
  TrainingPool->train: break at iter=54, cur_mean_loss=0.778450, mean_loss=0.778537, diff=-0.000087, thres=0.000100
FrameId=266:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 9487, --cropped--> 9486
  Registration->register: reg_points=torch.Size([333, 6]), translation=tensor([-2.0063,  0.1549, -0.2311], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([9486, 6]) -> sampled_points=torch.Size([47430, 6]) time= 0.38 ms
  LatentFeature->update: samples=47430, new_points=1145 (closreSur>VoxDwn>Radius>Distance), all_points=1068825
  TrainingPool->update: Nvs=47430 ->  close_surface_sample_idx=28293, all_points=36695245, increasement: 36647815
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([28293])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.781386, mean_loss=0.781457, diff=-0.000071, thres=0.000100
FrameId=267:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 9393, --cropped--> 9392
  Registration->register: reg_points=torch.Size([326, 6]), translation=tensor([-2.0318,  0.1162, -0.2582], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([9392, 6]) -> sampled_points=torch.Size([46960, 6]) time= 0.42 ms
  LatentFeature->update: samples=46960, new_points=1146 (closreSur>VoxDwn>Radius>Distance), all_points=1069971
  TrainingPool->update: Nvs=46960 ->  close_surface_sample_idx=27864, all_points=36742205, increasement: 36695245
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([27864])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.784101, mean_loss=0.784142, diff=-0.000041, thres=0.000100
FrameId=268:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 9023, --cropped--> 9022
  Registration->register: reg_points=torch.Size([315, 6]), translation=tensor([-2.0389,  0.1103, -0.2810], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([9022, 6]) -> sampled_points=torch.Size([45110, 6]) time= 0.38 ms
  LatentFeature->update: samples=45110, new_points=1100 (closreSur>VoxDwn>Radius>Distance), all_points=1071071
  TrainingPool->update: Nvs=45110 ->  close_surface_sample_idx=26967, all_points=36787315, increasement: 36742205
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([26967])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.784841, mean_loss=0.784810, diff=0.000030, thres=0.000100
FrameId=269:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 8907, --cropped--> 8906
  Registration->register: reg_points=torch.Size([306, 6]), translation=tensor([-2.0755,  0.0582, -0.2991], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([8906, 6]) -> sampled_points=torch.Size([44530, 6]) time= 0.38 ms
  LatentFeature->update: samples=44530, new_points=1051 (closreSur>VoxDwn>Radius>Distance), all_points=1072122
  TrainingPool->update: Nvs=44530 ->  close_surface_sample_idx=26504, all_points=36831845, increasement: 36787315
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([26504])
  TrainingPool->train: break at iter=55, cur_mean_loss=0.783994, mean_loss=0.784036, diff=-0.000042, thres=0.000100
FrameId=270:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 8474, --cropped--> 8473
  Registration->register: reg_points=torch.Size([286, 6]), translation=tensor([-1.9955, -0.0119, -0.2258], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([8473, 6]) -> sampled_points=torch.Size([42365, 6]) time= 0.41 ms
  LatentFeature->update: samples=42365, new_points=997 (closreSur>VoxDwn>Radius>Distance), all_points=1073119
  TrainingPool->update: Nvs=42365 ->  close_surface_sample_idx=25263, all_points=36874210, increasement: 36831845
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([25263])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.784820, mean_loss=0.784854, diff=-0.000034, thres=0.000100
FrameId=271:  cached_time=2.0 ms
  TumDataset->next_frame: Original=307200 -downsample-> 8191, --cropped--> 8190
  Registration->register: reg_points=torch.Size([280, 6]), translation=tensor([-1.8852, -0.0481, -0.1490], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([8190, 6]) -> sampled_points=torch.Size([40950, 6]) time= 0.36 ms
  LatentFeature->update: samples=40950, new_points=959 (closreSur>VoxDwn>Radius>Distance), all_points=1074078
  TrainingPool->update: Nvs=40950 ->  close_surface_sample_idx=24454, all_points=36915160, increasement: 36874210
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([24454])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.785544, mean_loss=0.785479, diff=0.000064, thres=0.000100
FrameId=272:  cached_time=2.0 ms
  TumDataset->next_frame: Original=307200 -downsample-> 7946, --cropped--> 7945
  Registration->register: reg_points=torch.Size([264, 6]), translation=tensor([-1.8491, -0.1323, -0.1167], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([7945, 6]) -> sampled_points=torch.Size([39725, 6]) time= 0.35 ms
  LatentFeature->update: samples=39725, new_points=951 (closreSur>VoxDwn>Radius>Distance), all_points=1075029
  TrainingPool->update: Nvs=39725 ->  close_surface_sample_idx=23721, all_points=36954885, increasement: 36915160
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([23721])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.786421, mean_loss=0.786406, diff=0.000015, thres=0.000100
FrameId=273:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 7777, --cropped--> 7744
  Registration->register: reg_points=torch.Size([260, 6]), translation=tensor([-1.8526, -0.1468, -0.1139], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([7744, 6]) -> sampled_points=torch.Size([38720, 6]) time= 0.37 ms
  LatentFeature->update: samples=38720, new_points=919 (closreSur>VoxDwn>Radius>Distance), all_points=1075948
  TrainingPool->update: Nvs=38720 ->  close_surface_sample_idx=23113, all_points=36993605, increasement: 36954885
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([23113])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.786006, mean_loss=0.785960, diff=0.000046, thres=0.000100
FrameId=274:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 7535, --cropped--> 7468
  Registration->register: reg_points=torch.Size([251, 6]), translation=tensor([-1.8546, -0.1672, -0.1228], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([7468, 6]) -> sampled_points=torch.Size([37340, 6]) time= 0.36 ms
  LatentFeature->update: samples=37340, new_points=900 (closreSur>VoxDwn>Radius>Distance), all_points=1076848
  TrainingPool->update: Nvs=37340 ->  close_surface_sample_idx=22326, all_points=37030945, increasement: 36993605
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([22326])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.786639, mean_loss=0.786551, diff=0.000089, thres=0.000100
FrameId=275:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 7520, --cropped--> 7436
  Registration->register: reg_points=torch.Size([268, 6]), translation=tensor([-1.7316, -0.1388, -0.1346], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([7436, 6]) -> sampled_points=torch.Size([37180, 6]) time= 0.37 ms
  LatentFeature->update: samples=37180, new_points=913 (closreSur>VoxDwn>Radius>Distance), all_points=1077761
  TrainingPool->update: Nvs=37180 ->  close_surface_sample_idx=22204, all_points=37068125, increasement: 37030945
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([22204])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.786768, mean_loss=0.786805, diff=-0.000037, thres=0.000100
FrameId=276:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 7462, --cropped--> 7375
  Registration->register: reg_points=torch.Size([270, 6]), translation=tensor([-1.6875, -0.1486, -0.1511], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([7375, 6]) -> sampled_points=torch.Size([36875, 6]) time= 0.37 ms
  LatentFeature->update: samples=36875, new_points=899 (closreSur>VoxDwn>Radius>Distance), all_points=1078660
  TrainingPool->update: Nvs=36875 ->  close_surface_sample_idx=22036, all_points=37105000, increasement: 37068125
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([22036])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.786621, mean_loss=0.786527, diff=0.000094, thres=0.000100
FrameId=277:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 7496, --cropped--> 7420
  Registration->register: reg_points=torch.Size([270, 6]), translation=tensor([-1.5092, -0.2280, -0.0488], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([7420, 6]) -> sampled_points=torch.Size([37100, 6]) time= 0.38 ms
  LatentFeature->update: samples=37100, new_points=890 (closreSur>VoxDwn>Radius>Distance), all_points=1079550
  TrainingPool->update: Nvs=37100 ->  close_surface_sample_idx=22121, all_points=37142100, increasement: 37105000
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([22121])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.785559, mean_loss=0.785606, diff=-0.000047, thres=0.000100
FrameId=278:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 7602, --cropped--> 7531
  Registration->register: reg_points=torch.Size([263, 6]), translation=tensor([-1.5037, -0.2179, -0.0445], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([7531, 6]) -> sampled_points=torch.Size([37655, 6]) time= 0.37 ms
  LatentFeature->update: samples=37655, new_points=928 (closreSur>VoxDwn>Radius>Distance), all_points=1080478
  TrainingPool->update: Nvs=37655 ->  close_surface_sample_idx=22461, all_points=37179755, increasement: 37142100
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([22461])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.786057, mean_loss=0.785994, diff=0.000063, thres=0.000100
FrameId=279:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 7972, --cropped--> 7893
  Registration->register: reg_points=torch.Size([280, 6]), translation=tensor([-1.4469, -0.1761, -0.0784], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([7893, 6]) -> sampled_points=torch.Size([39465, 6]) time= 0.36 ms
  LatentFeature->update: samples=39465, new_points=963 (closreSur>VoxDwn>Radius>Distance), all_points=1081441
  TrainingPool->update: Nvs=39465 ->  close_surface_sample_idx=23544, all_points=37219220, increasement: 37179755
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([23544])
  TrainingPool->train: break at iter=54, cur_mean_loss=0.785967, mean_loss=0.785907, diff=0.000060, thres=0.000100
FrameId=280:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 8390, --cropped--> 8318
  Registration->register: reg_points=torch.Size([291, 6]), translation=tensor([-1.3421, -0.2799, -0.0221], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([8318, 6]) -> sampled_points=torch.Size([41590, 6]) time= 0.36 ms
  LatentFeature->update: samples=41590, new_points=1024 (closreSur>VoxDwn>Radius>Distance), all_points=1082465
  TrainingPool->update: Nvs=41590 ->  close_surface_sample_idx=24859, all_points=37260810, increasement: 37219220
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([24859])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.784984, mean_loss=0.784978, diff=0.000006, thres=0.000100
FrameId=281:  cached_time=3.0 ms
  TumDataset->next_frame: Original=307200 -downsample-> 8685, --cropped--> 8616
  Registration->register: reg_points=torch.Size([309, 6]), translation=tensor([-1.3655, -0.3306, -0.0152], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([8616, 6]) -> sampled_points=torch.Size([43080, 6]) time= 0.37 ms
  LatentFeature->update: samples=43080, new_points=1046 (closreSur>VoxDwn>Radius>Distance), all_points=1083511
  TrainingPool->update: Nvs=43080 ->  close_surface_sample_idx=25712, all_points=37303890, increasement: 37260810
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([25712])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.785665, mean_loss=0.785600, diff=0.000065, thres=0.000100
FrameId=282:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 9022, --cropped--> 8955
  Registration->register: reg_points=torch.Size([338, 6]), translation=tensor([-1.3331, -0.3230, -0.0079], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([8955, 6]) -> sampled_points=torch.Size([44775, 6]) time= 0.37 ms
  LatentFeature->update: samples=44775, new_points=1097 (closreSur>VoxDwn>Radius>Distance), all_points=1084608
  TrainingPool->update: Nvs=44775 ->  close_surface_sample_idx=26720, all_points=37348665, increasement: 37303890
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([26720])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.785160, mean_loss=0.785141, diff=0.000019, thres=0.000100
FrameId=283:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 9317, --cropped--> 9240
  Registration->register: reg_points=torch.Size([343, 6]), translation=tensor([-1.3643, -0.2872,  0.0027], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([9240, 6]) -> sampled_points=torch.Size([46200, 6]) time= 0.37 ms
  LatentFeature->update: samples=46200, new_points=1135 (closreSur>VoxDwn>Radius>Distance), all_points=1085743
  TrainingPool->update: Nvs=46200 ->  close_surface_sample_idx=27589, all_points=37394865, increasement: 37348665
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([27589])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.785608, mean_loss=0.785516, diff=0.000092, thres=0.000100
FrameId=284:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 9394, --cropped--> 9327
  Registration->register: reg_points=torch.Size([343, 6]), translation=tensor([-1.2876, -0.2784,  0.0039], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([9327, 6]) -> sampled_points=torch.Size([46635, 6]) time= 0.38 ms
  LatentFeature->update: samples=46635, new_points=1131 (closreSur>VoxDwn>Radius>Distance), all_points=1086874
  TrainingPool->update: Nvs=46635 ->  close_surface_sample_idx=27742, all_points=37441500, increasement: 37394865
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([27742])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.785120, mean_loss=0.785186, diff=-0.000066, thres=0.000100
FrameId=285:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 9535, --cropped--> 9473
  Registration->register: reg_points=torch.Size([342, 6]), translation=tensor([-1.2606, -0.2766,  0.0019], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([9473, 6]) -> sampled_points=torch.Size([47365, 6]) time= 0.38 ms
  LatentFeature->update: samples=47365, new_points=1126 (closreSur>VoxDwn>Radius>Distance), all_points=1088000
  TrainingPool->update: Nvs=47365 ->  close_surface_sample_idx=28137, all_points=37488865, increasement: 37441500
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([28137])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.785146, mean_loss=0.785103, diff=0.000043, thres=0.000100
FrameId=286:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 9549, --cropped--> 9500
  Registration->register: reg_points=torch.Size([333, 6]), translation=tensor([-1.2544, -0.2749,  0.0118], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([9500, 6]) -> sampled_points=torch.Size([47500, 6]) time= 0.39 ms
  LatentFeature->update: samples=47500, new_points=1177 (closreSur>VoxDwn>Radius>Distance), all_points=1089177
  TrainingPool->update: Nvs=47500 ->  close_surface_sample_idx=28350, all_points=37536365, increasement: 37488865
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([28350])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.785069, mean_loss=0.785036, diff=0.000032, thres=0.000100
FrameId=287:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 9716, --cropped--> 9671
  Registration->register: reg_points=torch.Size([347, 6]), translation=tensor([-1.2404, -0.2869,  0.0125], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([9671, 6]) -> sampled_points=torch.Size([48355, 6]) time= 0.38 ms
  LatentFeature->update: samples=48355, new_points=1196 (closreSur>VoxDwn>Radius>Distance), all_points=1090373
  TrainingPool->update: Nvs=48355 ->  close_surface_sample_idx=28900, all_points=37584720, increasement: 37536365
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([28900])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.785083, mean_loss=0.785166, diff=-0.000083, thres=0.000100
FrameId=288:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 10065, --cropped--> 10058
  Registration->register: reg_points=torch.Size([360, 6]), translation=tensor([-1.2714, -0.3507,  0.0589], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([10058, 6]) -> sampled_points=torch.Size([50290, 6]) time= 0.37 ms
  LatentFeature->update: samples=50290, new_points=1213 (closreSur>VoxDwn>Radius>Distance), all_points=1091586
  TrainingPool->update: Nvs=50290 ->  close_surface_sample_idx=30030, all_points=37635010, increasement: 37584720
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([30030])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.784697, mean_loss=0.784687, diff=0.000010, thres=0.000100
FrameId=289:  cached_time=2.0 ms
  TumDataset->next_frame: Original=307200 -downsample-> 10421, --cropped--> 10420
  Registration->register: reg_points=torch.Size([383, 6]), translation=tensor([-1.2431, -0.3707,  0.0722], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([10420, 6]) -> sampled_points=torch.Size([52100, 6]) time= 0.41 ms
  LatentFeature->update: samples=52100, new_points=1265 (closreSur>VoxDwn>Radius>Distance), all_points=1092851
  TrainingPool->update: Nvs=52100 ->  close_surface_sample_idx=31109, all_points=37687110, increasement: 37635010
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([31109])
  TrainingPool->train: break at iter=54, cur_mean_loss=0.783680, mean_loss=0.783690, diff=-0.000010, thres=0.000100
FrameId=290:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 10981, --cropped--> 10980
  Registration->register: reg_points=torch.Size([410, 6]), translation=tensor([-1.2530, -0.3634,  0.0934], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([10980, 6]) -> sampled_points=torch.Size([54900, 6]) time= 0.97 ms
  LatentFeature->update: samples=54900, new_points=1323 (closreSur>VoxDwn>Radius>Distance), all_points=1094174
  TrainingPool->update: Nvs=54900 ->  close_surface_sample_idx=32763, all_points=37742010, increasement: 37687110
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([32763])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.784212, mean_loss=0.784288, diff=-0.000075, thres=0.000100
FrameId=291:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 11230, --cropped--> 11229
  Registration->register: reg_points=torch.Size([418, 6]), translation=tensor([-1.2160, -0.4325,  0.1134], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([11229, 6]) -> sampled_points=torch.Size([56145, 6]) time= 0.96 ms
  LatentFeature->update: samples=56145, new_points=1375 (closreSur>VoxDwn>Radius>Distance), all_points=1095549
  TrainingPool->update: Nvs=56145 ->  close_surface_sample_idx=33509, all_points=37798155, increasement: 37742010
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([33509])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.784668, mean_loss=0.784692, diff=-0.000024, thres=0.000100
FrameId=292:  cached_time=2.0 ms
  TumDataset->next_frame: Original=307200 -downsample-> 11627, --cropped--> 11626
  Registration->register: reg_points=torch.Size([431, 6]), translation=tensor([-1.2015, -0.4498,  0.1533], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([11626, 6]) -> sampled_points=torch.Size([58130, 6]) time= 0.96 ms
  LatentFeature->update: samples=58130, new_points=1408 (closreSur>VoxDwn>Radius>Distance), all_points=1096957
  TrainingPool->update: Nvs=58130 ->  close_surface_sample_idx=34610, all_points=37856285, increasement: 37798155
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([34610])
  TrainingPool->train: break at iter=55, cur_mean_loss=0.784245, mean_loss=0.784182, diff=0.000062, thres=0.000100
FrameId=293:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 11824, --cropped--> 11823
  Registration->register: reg_points=torch.Size([425, 6]), translation=tensor([-1.1948, -0.4810,  0.1568], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([11823, 6]) -> sampled_points=torch.Size([59115, 6]) time= 0.81 ms
  LatentFeature->update: samples=59115, new_points=1429 (closreSur>VoxDwn>Radius>Distance), all_points=1098386
  TrainingPool->update: Nvs=59115 ->  close_surface_sample_idx=35257, all_points=37915400, increasement: 37856285
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([35257])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.785426, mean_loss=0.785401, diff=0.000025, thres=0.000100
FrameId=294:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 12025, --cropped--> 12024
  Registration->register: reg_points=torch.Size([437, 6]), translation=tensor([-1.1522, -0.3927,  0.1749], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([12024, 6]) -> sampled_points=torch.Size([60120, 6]) time= 0.84 ms
  LatentFeature->update: samples=60120, new_points=1452 (closreSur>VoxDwn>Radius>Distance), all_points=1099838
  TrainingPool->update: Nvs=60120 ->  close_surface_sample_idx=35808, all_points=37975520, increasement: 37915400
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([35808])
  TrainingPool->train: break at iter=55, cur_mean_loss=0.783698, mean_loss=0.783636, diff=0.000061, thres=0.000100
FrameId=295:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 12088, --cropped--> 12087
  Registration->register: reg_points=torch.Size([429, 6]), translation=tensor([-1.1011, -0.4032,  0.1940], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([12087, 6]) -> sampled_points=torch.Size([60435, 6]) time= 0.94 ms
  LatentFeature->update: samples=60435, new_points=1488 (closreSur>VoxDwn>Radius>Distance), all_points=1101326
  TrainingPool->update: Nvs=60435 ->  close_surface_sample_idx=36109, all_points=38035955, increasement: 37975520
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([36109])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.783185, mean_loss=0.783254, diff=-0.000070, thres=0.000100
FrameId=296:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 12254, --cropped--> 12253
  Registration->register: reg_points=torch.Size([447, 6]), translation=tensor([-1.1963, -0.4851,  0.2585], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([12253, 6]) -> sampled_points=torch.Size([61265, 6]) time= 0.87 ms
  LatentFeature->update: samples=61265, new_points=1479 (closreSur>VoxDwn>Radius>Distance), all_points=1102805
  TrainingPool->update: Nvs=61265 ->  close_surface_sample_idx=36595, all_points=38097220, increasement: 38035955
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([36595])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.784234, mean_loss=0.784281, diff=-0.000047, thres=0.000100
FrameId=297:  cached_time=2.0 ms
  TumDataset->next_frame: Original=307200 -downsample-> 12251, --cropped--> 12250
  Registration->register: reg_points=torch.Size([449, 6]), translation=tensor([-1.2113, -0.4432,  0.2520], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([12250, 6]) -> sampled_points=torch.Size([61250, 6]) time= 0.91 ms
  LatentFeature->update: samples=61250, new_points=1507 (closreSur>VoxDwn>Radius>Distance), all_points=1104312
  TrainingPool->update: Nvs=61250 ->  close_surface_sample_idx=36597, all_points=38158470, increasement: 38097220
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([36597])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.782460, mean_loss=0.782468, diff=-0.000009, thres=0.000100
FrameId=298:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 12238, --cropped--> 12237
  Registration->register: reg_points=torch.Size([443, 6]), translation=tensor([-1.2242, -0.4732,  0.2653], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([12237, 6]) -> sampled_points=torch.Size([61185, 6]) time= 0.84 ms
  LatentFeature->update: samples=61185, new_points=1474 (closreSur>VoxDwn>Radius>Distance), all_points=1105786
  TrainingPool->update: Nvs=61185 ->  close_surface_sample_idx=36474, all_points=38219655, increasement: 38158470
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([36474])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.783188, mean_loss=0.783266, diff=-0.000078, thres=0.000100
FrameId=299:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 12732, --cropped--> 12731
  Registration->register: reg_points=torch.Size([460, 6]), translation=tensor([-1.2365, -0.5101,  0.2599], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([12731, 6]) -> sampled_points=torch.Size([63655, 6]) time= 1.09 ms
  LatentFeature->update: samples=63655, new_points=1542 (closreSur>VoxDwn>Radius>Distance), all_points=1107328
  TrainingPool->update: Nvs=63655 ->  close_surface_sample_idx=37971, all_points=38283310, increasement: 38219655
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([37971])
  TrainingPool->train: break at iter=54, cur_mean_loss=0.783759, mean_loss=0.783817, diff=-0.000058, thres=0.000100
FrameId=300:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 12835, --cropped--> 12834
  Registration->register: reg_points=torch.Size([457, 6]), translation=tensor([-1.2069, -0.5612,  0.2667], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([12834, 6]) -> sampled_points=torch.Size([64170, 6]) time= 0.89 ms
  LatentFeature->update: samples=64170, new_points=1543 (closreSur>VoxDwn>Radius>Distance), all_points=1108871
  TrainingPool->update: Nvs=64170 ->  close_surface_sample_idx=38289, all_points=38347480, increasement: 38283310
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([38289])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.783660, mean_loss=0.783690, diff=-0.000031, thres=0.000100
FrameId=301:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 12678, --cropped--> 12677
  Registration->register: reg_points=torch.Size([459, 6]), translation=tensor([-1.2110, -0.5862,  0.2771], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([12677, 6]) -> sampled_points=torch.Size([63385, 6]) time= 0.92 ms
  LatentFeature->update: samples=63385, new_points=1517 (closreSur>VoxDwn>Radius>Distance), all_points=1110388
  TrainingPool->update: Nvs=63385 ->  close_surface_sample_idx=37763, all_points=38410865, increasement: 38347480
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([37763])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.784172, mean_loss=0.784234, diff=-0.000062, thres=0.000100
FrameId=302:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 12635, --cropped--> 12634
  Registration->register: reg_points=torch.Size([444, 6]), translation=tensor([-1.2082, -0.6177,  0.2736], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([12634, 6]) -> sampled_points=torch.Size([63170, 6]) time= 0.87 ms
  LatentFeature->update: samples=63170, new_points=1515 (closreSur>VoxDwn>Radius>Distance), all_points=1111903
  TrainingPool->update: Nvs=63170 ->  close_surface_sample_idx=37710, all_points=38474035, increasement: 38410865
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([37710])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.784164, mean_loss=0.784161, diff=0.000003, thres=0.000100
FrameId=303:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 12373, --cropped--> 12372
  Registration->register: reg_points=torch.Size([437, 6]), translation=tensor([-1.1960, -0.5431,  0.2948], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([12372, 6]) -> sampled_points=torch.Size([61860, 6]) time= 0.89 ms
  LatentFeature->update: samples=61860, new_points=1515 (closreSur>VoxDwn>Radius>Distance), all_points=1113418
  TrainingPool->update: Nvs=61860 ->  close_surface_sample_idx=36933, all_points=38535895, increasement: 38474035
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([36933])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.784615, mean_loss=0.784715, diff=-0.000099, thres=0.000100
FrameId=304:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 12255, --cropped--> 12254
  Registration->register: reg_points=torch.Size([430, 6]), translation=tensor([-1.2121, -0.5556,  0.2839], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([12254, 6]) -> sampled_points=torch.Size([61270, 6]) time= 0.88 ms
  LatentFeature->update: samples=61270, new_points=1487 (closreSur>VoxDwn>Radius>Distance), all_points=1114905
  TrainingPool->update: Nvs=61270 ->  close_surface_sample_idx=36595, all_points=38597165, increasement: 38535895
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([36595])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.784697, mean_loss=0.784755, diff=-0.000058, thres=0.000100
FrameId=305:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 12472, --cropped--> 12471
  Registration->register: reg_points=torch.Size([445, 6]), translation=tensor([-1.1198, -0.5016,  0.2370], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([12471, 6]) -> sampled_points=torch.Size([62355, 6]) time= 0.98 ms
  LatentFeature->update: samples=62355, new_points=1494 (closreSur>VoxDwn>Radius>Distance), all_points=1116399
  TrainingPool->update: Nvs=62355 ->  close_surface_sample_idx=37213, all_points=38659520, increasement: 38597165
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([37213])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.783868, mean_loss=0.783831, diff=0.000037, thres=0.000100
FrameId=306:  cached_time=2.0 ms
  TumDataset->next_frame: Original=307200 -downsample-> 12469, --cropped--> 12468
  Registration->register: reg_points=torch.Size([453, 6]), translation=tensor([-1.1371, -0.5108,  0.2289], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([12468, 6]) -> sampled_points=torch.Size([62340, 6]) time= 0.96 ms
  LatentFeature->update: samples=62340, new_points=1503 (closreSur>VoxDwn>Radius>Distance), all_points=1117902
  TrainingPool->update: Nvs=62340 ->  close_surface_sample_idx=37136, all_points=38721860, increasement: 38659520
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([37136])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.784715, mean_loss=0.784775, diff=-0.000059, thres=0.000100
FrameId=307:  cached_time=2.0 ms
  TumDataset->next_frame: Original=307200 -downsample-> 12500, --cropped--> 12499
  Registration->register: reg_points=torch.Size([451, 6]), translation=tensor([-1.1115, -0.5407,  0.2223], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([12499, 6]) -> sampled_points=torch.Size([62495, 6]) time= 0.83 ms
  LatentFeature->update: samples=62495, new_points=1510 (closreSur>VoxDwn>Radius>Distance), all_points=1119412
  TrainingPool->update: Nvs=62495 ->  close_surface_sample_idx=37251, all_points=38784355, increasement: 38721860
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([37251])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.784216, mean_loss=0.784184, diff=0.000032, thres=0.000100
FrameId=308:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 13026, --cropped--> 13025
  Registration->register: reg_points=torch.Size([486, 6]), translation=tensor([-1.1410, -0.5437,  0.2352], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([13025, 6]) -> sampled_points=torch.Size([65125, 6]) time= 0.84 ms
  LatentFeature->update: samples=65125, new_points=1535 (closreSur>VoxDwn>Radius>Distance), all_points=1120947
  TrainingPool->update: Nvs=65125 ->  close_surface_sample_idx=38687, all_points=38849480, increasement: 38784355
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([38687])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.784828, mean_loss=0.784798, diff=0.000030, thres=0.000100
FrameId=309:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 13378, --cropped--> 13377
  Registration->register: reg_points=torch.Size([497, 6]), translation=tensor([-1.0606, -0.5114,  0.2445], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([13377, 6]) -> sampled_points=torch.Size([66885, 6]) time= 0.85 ms
  LatentFeature->update: samples=66885, new_points=1641 (closreSur>VoxDwn>Radius>Distance), all_points=1122588
  TrainingPool->update: Nvs=66885 ->  close_surface_sample_idx=39857, all_points=38916365, increasement: 38849480
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([39857])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.784455, mean_loss=0.784498, diff=-0.000043, thres=0.000100
FrameId=310:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 13641, --cropped--> 13640
  Registration->register: reg_points=torch.Size([484, 6]), translation=tensor([-1.0585, -0.5004,  0.2557], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([13640, 6]) -> sampled_points=torch.Size([68200, 6]) time= 0.94 ms
  LatentFeature->update: samples=68200, new_points=1659 (closreSur>VoxDwn>Radius>Distance), all_points=1124247
  TrainingPool->update: Nvs=68200 ->  close_surface_sample_idx=40623, all_points=38984565, increasement: 38916365
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([40623])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.784828, mean_loss=0.784771, diff=0.000057, thres=0.000100
FrameId=311:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 14370, --cropped--> 14369
  Registration->register: reg_points=torch.Size([527, 6]), translation=tensor([-0.9685, -0.5215,  0.2744], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([14369, 6]) -> sampled_points=torch.Size([71845, 6]) time= 0.81 ms
  LatentFeature->update: samples=71845, new_points=1749 (closreSur>VoxDwn>Radius>Distance), all_points=1125996
  TrainingPool->update: Nvs=71845 ->  close_surface_sample_idx=42902, all_points=39056410, increasement: 38984565
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([42902])
  TrainingPool->train: break at iter=57, cur_mean_loss=0.785669, mean_loss=0.785595, diff=0.000075, thres=0.000100
FrameId=312:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 15330, --cropped--> 15329
  Registration->register: reg_points=torch.Size([572, 6]), translation=tensor([-0.9066, -0.5495,  0.2769], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([15329, 6]) -> sampled_points=torch.Size([76645, 6]) time= 0.89 ms
  LatentFeature->update: samples=76645, new_points=1924 (closreSur>VoxDwn>Radius>Distance), all_points=1127920
  TrainingPool->update: Nvs=76645 ->  close_surface_sample_idx=45799, all_points=39133055, increasement: 39056410
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([45799])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.787243, mean_loss=0.787335, diff=-0.000092, thres=0.000100
FrameId=313:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 16083, --cropped--> 16082
  Registration->register: reg_points=torch.Size([605, 6]), translation=tensor([-0.6964, -0.5084,  0.2226], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([16082, 6]) -> sampled_points=torch.Size([80410, 6]) time= 0.87 ms
  LatentFeature->update: samples=80410, new_points=2010 (closreSur>VoxDwn>Radius>Distance), all_points=1129930
  TrainingPool->update: Nvs=80410 ->  close_surface_sample_idx=48045, all_points=39213465, increasement: 39133055
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([48045])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.785652, mean_loss=0.785741, diff=-0.000089, thres=0.000100
FrameId=314:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 16917, --cropped--> 16916
  Registration->register: reg_points=torch.Size([650, 6]), translation=tensor([-0.6752, -0.5036,  0.2160], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([16916, 6]) -> sampled_points=torch.Size([84580, 6]) time= 0.90 ms
  LatentFeature->update: samples=84580, new_points=2125 (closreSur>VoxDwn>Radius>Distance), all_points=1132055
  TrainingPool->update: Nvs=84580 ->  close_surface_sample_idx=50408, all_points=39298045, increasement: 39213465
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([50408])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.787593, mean_loss=0.787678, diff=-0.000085, thres=0.000100
FrameId=315:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 18197, --cropped--> 18196
  Registration->register: reg_points=torch.Size([728, 6]), translation=tensor([-0.7790, -0.5383,  0.2894], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([18196, 6]) -> sampled_points=torch.Size([90980, 6]) time= 0.91 ms
  LatentFeature->update: samples=90980, new_points=2333 (closreSur>VoxDwn>Radius>Distance), all_points=1134388
  TrainingPool->update: Nvs=90980 ->  close_surface_sample_idx=54294, all_points=39389025, increasement: 39298045
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([54294])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.785125, mean_loss=0.785199, diff=-0.000074, thres=0.000100
FrameId=316:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 19142, --cropped--> 19141
  Registration->register: reg_points=torch.Size([786, 6]), translation=tensor([-0.8079, -0.5988,  0.2995], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([19141, 6]) -> sampled_points=torch.Size([95705, 6]) time= 0.80 ms
  LatentFeature->update: samples=95705, new_points=2490 (closreSur>VoxDwn>Radius>Distance), all_points=1136878
  TrainingPool->update: Nvs=95705 ->  close_surface_sample_idx=57075, all_points=39484730, increasement: 39389025
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([57075])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.785268, mean_loss=0.785343, diff=-0.000075, thres=0.000100
FrameId=317:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 20323, --cropped--> 20322
  Registration->register: reg_points=torch.Size([834, 6]), translation=tensor([-0.7641, -0.6154,  0.3039], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([20322, 6]) -> sampled_points=torch.Size([101610, 6]) time= 0.97 ms
  LatentFeature->update: samples=101610, new_points=2617 (closreSur>VoxDwn>Radius>Distance), all_points=1139495
  TrainingPool->update: Nvs=101610 ->  close_surface_sample_idx=60528, all_points=39586340, increasement: 39484730
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([60528])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.787341, mean_loss=0.787439, diff=-0.000098, thres=0.000100
FrameId=318:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 21153, --cropped--> 21152
  Registration->register: reg_points=torch.Size([889, 6]), translation=tensor([-0.7574, -0.6362,  0.3209], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([21152, 6]) -> sampled_points=torch.Size([105760, 6]) time= 0.93 ms
  LatentFeature->update: samples=105760, new_points=2774 (closreSur>VoxDwn>Radius>Distance), all_points=1142269
  TrainingPool->update: Nvs=105760 ->  close_surface_sample_idx=63054, all_points=39692100, increasement: 39586340
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([63054])
  TrainingPool->train: break at iter=54, cur_mean_loss=0.786793, mean_loss=0.786811, diff=-0.000018, thres=0.000100
FrameId=319:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 22352, --cropped--> 22351
  Registration->register: reg_points=torch.Size([933, 6]), translation=tensor([-0.7277, -0.6407,  0.3455], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([22351, 6]) -> sampled_points=torch.Size([111755, 6]) time= 0.93 ms
  LatentFeature->update: samples=111755, new_points=2979 (closreSur>VoxDwn>Radius>Distance), all_points=1145248
  TrainingPool->update: Nvs=111755 ->  close_surface_sample_idx=66616, all_points=39803855, increasement: 39692100
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([66616])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.786547, mean_loss=0.786517, diff=0.000030, thres=0.000100
FrameId=320:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 23657, --cropped--> 23656
  Registration->register: reg_points=torch.Size([998, 6]), translation=tensor([-0.7022, -0.6337,  0.3708], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([23656, 6]) -> sampled_points=torch.Size([118280, 6]) time= 0.98 ms
  LatentFeature->update: samples=118280, new_points=3141 (closreSur>VoxDwn>Radius>Distance), all_points=1148389
  TrainingPool->update: Nvs=118280 ->  close_surface_sample_idx=70533, all_points=39922135, increasement: 39803855
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([70533])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.786828, mean_loss=0.786792, diff=0.000035, thres=0.000100
FrameId=321:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 25337, --cropped--> 25336
  Registration->register: reg_points=torch.Size([1084, 6]), translation=tensor([-0.7031, -0.6234,  0.3810], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([25336, 6]) -> sampled_points=torch.Size([126680, 6]) time= 0.85 ms
  LatentFeature->update: samples=126680, new_points=3427 (closreSur>VoxDwn>Radius>Distance), all_points=1151816
  TrainingPool->update: Nvs=126680 ->  close_surface_sample_idx=75700, all_points=40048815, increasement: 39922135
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([75700])
  TrainingPool->train: break at iter=55, cur_mean_loss=0.785719, mean_loss=0.785786, diff=-0.000067, thres=0.000100
FrameId=322:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 26768, --cropped--> 26767
  Registration->register: reg_points=torch.Size([1176, 6]), translation=tensor([-0.9492, -0.7978,  0.5443], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([26767, 6]) -> sampled_points=torch.Size([133835, 6]) time= 0.86 ms
  LatentFeature->update: samples=133835, new_points=3669 (closreSur>VoxDwn>Radius>Distance), all_points=1155485
  TrainingPool->update: Nvs=133835 ->  close_surface_sample_idx=79859, all_points=40182650, increasement: 40048815
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([79859])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.785719, mean_loss=0.785688, diff=0.000031, thres=0.000100
FrameId=323:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 27290, --cropped--> 27289
  Registration->register: reg_points=torch.Size([1175, 6]), translation=tensor([-0.9481, -0.7970,  0.5496], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([27289, 6]) -> sampled_points=torch.Size([136445, 6]) time= 0.97 ms
  LatentFeature->update: samples=136445, new_points=3731 (closreSur>VoxDwn>Radius>Distance), all_points=1159216
  TrainingPool->update: Nvs=136445 ->  close_surface_sample_idx=81361, all_points=40319095, increasement: 40182650
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([81361])
  TrainingPool->train: break at iter=54, cur_mean_loss=0.782258, mean_loss=0.782302, diff=-0.000044, thres=0.000100
FrameId=324:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 29141, --cropped--> 29140
  Registration->register: reg_points=torch.Size([1291, 6]), translation=tensor([-0.9770, -0.7728,  0.5710], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([29140, 6]) -> sampled_points=torch.Size([145700, 6]) time= 1.01 ms
  LatentFeature->update: samples=145700, new_points=4050 (closreSur>VoxDwn>Radius>Distance), all_points=1163266
  TrainingPool->update: Nvs=145700 ->  close_surface_sample_idx=86839, all_points=40464795, increasement: 40319095
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([86839])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.782836, mean_loss=0.782927, diff=-0.000091, thres=0.000100
FrameId=325:  cached_time=3.3 ms
  TumDataset->next_frame: Original=307200 -downsample-> 31326, --cropped--> 31325
  Registration->register: reg_points=torch.Size([1370, 6]), translation=tensor([-0.9986, -0.7520,  0.5931], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([31325, 6]) -> sampled_points=torch.Size([156625, 6]) time= 1.00 ms
  LatentFeature->update: samples=156625, new_points=4419 (closreSur>VoxDwn>Radius>Distance), all_points=1167685
  TrainingPool->update: Nvs=156625 ->  close_surface_sample_idx=93388, all_points=40621420, increasement: 40464795
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([93388])
  TrainingPool->train: break at iter=57, cur_mean_loss=0.782205, mean_loss=0.782253, diff=-0.000048, thres=0.000100
FrameId=326:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 33427, --cropped--> 33426
  Registration->register: reg_points=torch.Size([1486, 6]), translation=tensor([-1.0055, -0.7889,  0.5954], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([33426, 6]) -> sampled_points=torch.Size([167130, 6]) time= 1.04 ms
  LatentFeature->update: samples=167130, new_points=4794 (closreSur>VoxDwn>Radius>Distance), all_points=1172479
  TrainingPool->update: Nvs=167130 ->  close_surface_sample_idx=99563, all_points=40788550, increasement: 40621420
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([99563])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.782735, mean_loss=0.782702, diff=0.000033, thres=0.000100
FrameId=327:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 35488, --cropped--> 35487
  Registration->register: reg_points=torch.Size([1612, 6]), translation=tensor([-0.9728, -0.7859,  0.5997], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([35487, 6]) -> sampled_points=torch.Size([177435, 6]) time= 0.99 ms
  LatentFeature->update: samples=177435, new_points=5319 (closreSur>VoxDwn>Radius>Distance), all_points=1177798
  TrainingPool->update: Nvs=177435 ->  close_surface_sample_idx=105917, all_points=40965985, increasement: 40788550
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([105917])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.781313, mean_loss=0.781318, diff=-0.000005, thres=0.000100
FrameId=328:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 36149, --cropped--> 36148
  Registration->register: reg_points=torch.Size([1672, 6]), translation=tensor([-0.9626, -0.7940,  0.6117], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([36148, 6]) -> sampled_points=torch.Size([180740, 6]) time= 1.02 ms
  LatentFeature->update: samples=180740, new_points=5413 (closreSur>VoxDwn>Radius>Distance), all_points=1183211
  TrainingPool->update: Nvs=180740 ->  close_surface_sample_idx=107668, all_points=41146725, increasement: 40965985
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([107668])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.780463, mean_loss=0.780393, diff=0.000070, thres=0.000100
FrameId=329:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 37719, --cropped--> 37718
  Registration->register: reg_points=torch.Size([1777, 6]), translation=tensor([-0.9240, -0.7730,  0.6206], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([37718, 6]) -> sampled_points=torch.Size([188590, 6]) time= 1.02 ms
  LatentFeature->update: samples=188590, new_points=5757 (closreSur>VoxDwn>Radius>Distance), all_points=1188968
  TrainingPool->update: Nvs=188590 ->  close_surface_sample_idx=112485, all_points=41335315, increasement: 41146725
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([112485])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.779650, mean_loss=0.779670, diff=-0.000020, thres=0.000100
FrameId=330:  cached_time=2.0 ms
  TumDataset->next_frame: Original=307200 -downsample-> 38192, --cropped--> 38191
  Registration->register: reg_points=torch.Size([1822, 6]), translation=tensor([-0.9178, -0.7951,  0.6254], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([38191, 6]) -> sampled_points=torch.Size([190955, 6]) time= 1.02 ms
  LatentFeature->update: samples=190955, new_points=5998 (closreSur>VoxDwn>Radius>Distance), all_points=1194966
  TrainingPool->update: Nvs=190955 ->  close_surface_sample_idx=113826, all_points=41526270, increasement: 41335315
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([113826])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.779727, mean_loss=0.779741, diff=-0.000014, thres=0.000100
FrameId=331:  cached_time=1.6 ms
  TumDataset->next_frame: Original=307200 -downsample-> 38515, --cropped--> 38514
  Registration->register: reg_points=torch.Size([1901, 6]), translation=tensor([-0.9047, -0.7895,  0.6404], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([38514, 6]) -> sampled_points=torch.Size([192570, 6]) time= 0.96 ms
  LatentFeature->update: samples=192570, new_points=6100 (closreSur>VoxDwn>Radius>Distance), all_points=1201066
  TrainingPool->update: Nvs=192570 ->  close_surface_sample_idx=114742, all_points=41718840, increasement: 41526270
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([114742])
  TrainingPool->train: break at iter=56, cur_mean_loss=0.777830, mean_loss=0.777759, diff=0.000071, thres=0.000100
FrameId=332:  cached_time=1.6 ms
  TumDataset->next_frame: Original=307200 -downsample-> 40512, --cropped--> 40511
  Registration->register: reg_points=torch.Size([1980, 6]), translation=tensor([-0.8888, -0.7804,  0.6574], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([40511, 6]) -> sampled_points=torch.Size([202555, 6]) time= 0.91 ms
  LatentFeature->update: samples=202555, new_points=6382 (closreSur>VoxDwn>Radius>Distance), all_points=1207448
  TrainingPool->update: Nvs=202555 ->  close_surface_sample_idx=119751, all_points=41921395, increasement: 41718840
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([119751])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.780395, mean_loss=0.780362, diff=0.000033, thres=0.000100
FrameId=333:  cached_time=1.6 ms
  TumDataset->next_frame: Original=307200 -downsample-> 42033, --cropped--> 42032
  Registration->register: reg_points=torch.Size([2087, 6]), translation=tensor([-0.8895, -0.7748,  0.6839], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([42032, 6]) -> sampled_points=torch.Size([210160, 6]) time= 1.13 ms
  LatentFeature->update: samples=210160, new_points=6741 (closreSur>VoxDwn>Radius>Distance), all_points=1214189
  TrainingPool->update: Nvs=210160 ->  close_surface_sample_idx=123645, all_points=42131555, increasement: 41921395
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([123645])
  TrainingPool->train: break at iter=56, cur_mean_loss=0.778325, mean_loss=0.778340, diff=-0.000016, thres=0.000100
FrameId=334:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 43240, --cropped--> 43239
  Registration->register: reg_points=torch.Size([2167, 6]), translation=tensor([-0.8584, -0.7553,  0.7038], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([43239, 6]) -> sampled_points=torch.Size([216195, 6]) time= 0.97 ms
  LatentFeature->update: samples=216195, new_points=7061 (closreSur>VoxDwn>Radius>Distance), all_points=1221250
  TrainingPool->update: Nvs=216195 ->  close_surface_sample_idx=128596, all_points=42347750, increasement: 42131555
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([128596])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.779156, mean_loss=0.779222, diff=-0.000066, thres=0.000100
FrameId=335:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 44171, --cropped--> 44170
  Registration->register: reg_points=torch.Size([2210, 6]), translation=tensor([-0.8439, -0.7359,  0.7188], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([44170, 6]) -> sampled_points=torch.Size([220850, 6]) time= 1.06 ms
  LatentFeature->update: samples=220850, new_points=7215 (closreSur>VoxDwn>Radius>Distance), all_points=1228465
  TrainingPool->update: Nvs=220850 ->  close_surface_sample_idx=131077, all_points=42568600, increasement: 42347750
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([131077])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.777515, mean_loss=0.777572, diff=-0.000057, thres=0.000100
FrameId=336:  cached_time=1.6 ms
  TumDataset->next_frame: Original=307200 -downsample-> 49214, --cropped--> 49213
  Registration->register: reg_points=torch.Size([2465, 6]), translation=tensor([-0.8341, -0.7294,  0.7339], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([49213, 6]) -> sampled_points=torch.Size([246065, 6]) time= 0.90 ms
  LatentFeature->update: samples=246065, new_points=8221 (closreSur>VoxDwn>Radius>Distance), all_points=1236686
  TrainingPool->update: Nvs=246065 ->  close_surface_sample_idx=146535, all_points=42814665, increasement: 42568600
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([146535])
  TrainingPool->train: break at iter=57, cur_mean_loss=0.777381, mean_loss=0.777422, diff=-0.000041, thres=0.000100
FrameId=337:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 53116, --cropped--> 53115
  Registration->register: reg_points=torch.Size([2654, 6]), translation=tensor([-0.8314, -0.6756,  0.7655], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([53115, 6]) -> sampled_points=torch.Size([265575, 6]) time= 1.11 ms
  LatentFeature->update: samples=265575, new_points=8958 (closreSur>VoxDwn>Radius>Distance), all_points=1245644
  TrainingPool->update: Nvs=265575 ->  close_surface_sample_idx=157991, all_points=43080240, increasement: 42814665
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([157991])
  TrainingPool->train: break at iter=56, cur_mean_loss=0.778432, mean_loss=0.778497, diff=-0.000065, thres=0.000100
FrameId=338:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 56424, --cropped--> 56423
  Registration->register: reg_points=torch.Size([2770, 6]), translation=tensor([-0.8360, -0.6365,  0.7898], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([56423, 6]) -> sampled_points=torch.Size([282115, 6]) time= 1.02 ms
  LatentFeature->update: samples=282115, new_points=9558 (closreSur>VoxDwn>Radius>Distance), all_points=1255202
  TrainingPool->update: Nvs=282115 ->  close_surface_sample_idx=167770, all_points=43362355, increasement: 43080240
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([167770])
  TrainingPool->train: break at iter=55, cur_mean_loss=0.778271, mean_loss=0.778367, diff=-0.000096, thres=0.000100
FrameId=339:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 60386, --cropped--> 60385
  Registration->register: reg_points=torch.Size([2895, 6]), translation=tensor([-0.8305, -0.6533,  0.7999], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([60385, 6]) -> sampled_points=torch.Size([301925, 6]) time= 1.14 ms
  LatentFeature->update: samples=301925, new_points=10073 (closreSur>VoxDwn>Radius>Distance), all_points=1265275
  TrainingPool->update: Nvs=301925 ->  close_surface_sample_idx=177930, all_points=43664280, increasement: 43362355
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([177930])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.777624, mean_loss=0.777651, diff=-0.000028, thres=0.000100
FrameId=340:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 63500, --cropped--> 63499
  Registration->register: reg_points=torch.Size([3015, 6]), translation=tensor([-0.8071, -0.6569,  0.7955], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([63499, 6]) -> sampled_points=torch.Size([317495, 6]) time= 1.03 ms
  LatentFeature->update: samples=317495, new_points=10914 (closreSur>VoxDwn>Radius>Distance), all_points=1276189
  TrainingPool->update: Nvs=317495 ->  close_surface_sample_idx=188731, all_points=43981775, increasement: 43664280
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([188731])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.777408, mean_loss=0.777499, diff=-0.000091, thres=0.000100
FrameId=341:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 63443, --cropped--> 63442
  Registration->register: reg_points=torch.Size([3104, 6]), translation=tensor([-0.7880, -0.6053,  0.8277], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([63442, 6]) -> sampled_points=torch.Size([317210, 6]) time= 1.07 ms
  LatentFeature->update: samples=317210, new_points=11146 (closreSur>VoxDwn>Radius>Distance), all_points=1287335
  TrainingPool->update: Nvs=317210 ->  close_surface_sample_idx=188589, all_points=44298985, increasement: 43981775
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([188589])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.777270, mean_loss=0.777241, diff=0.000029, thres=0.000100
FrameId=342:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 64421, --cropped--> 64420
  Registration->register: reg_points=torch.Size([3124, 6]), translation=tensor([-0.7839, -0.6155,  0.8210], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([64420, 6]) -> sampled_points=torch.Size([322100, 6]) time= 1.16 ms
  LatentFeature->update: samples=322100, new_points=11213 (closreSur>VoxDwn>Radius>Distance), all_points=1298548
  TrainingPool->update: Nvs=322100 ->  close_surface_sample_idx=191502, all_points=44621085, increasement: 44298985
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([191502])
  TrainingPool->train: break at iter=54, cur_mean_loss=0.774653, mean_loss=0.774730, diff=-0.000077, thres=0.000100
FrameId=343:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 66551, --cropped--> 66550
  Registration->register: reg_points=torch.Size([3244, 6]), translation=tensor([-0.7751, -0.6055,  0.8348], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([66550, 6]) -> sampled_points=torch.Size([332750, 6]) time= 1.18 ms
  LatentFeature->update: samples=332750, new_points=11651 (closreSur>VoxDwn>Radius>Distance), all_points=1310199
  TrainingPool->update: Nvs=332750 ->  close_surface_sample_idx=197741, all_points=44953835, increasement: 44621085
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([197741])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.775026, mean_loss=0.775094, diff=-0.000068, thres=0.000100
FrameId=344:  cached_time=2.0 ms
  TumDataset->next_frame: Original=307200 -downsample-> 67363, --cropped--> 67362
  Registration->register: reg_points=torch.Size([3295, 6]), translation=tensor([-0.7697, -0.6030,  0.8347], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([67362, 6]) -> sampled_points=torch.Size([336810, 6]) time= 0.92 ms
  LatentFeature->update: samples=336810, new_points=11969 (closreSur>VoxDwn>Radius>Distance), all_points=1322168
  TrainingPool->update: Nvs=336810 ->  close_surface_sample_idx=200688, all_points=45290645, increasement: 44953835
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([200688])
  TrainingPool->train: break at iter=59, cur_mean_loss=0.773946, mean_loss=0.774002, diff=-0.000057, thres=0.000100
FrameId=345:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 67002, --cropped--> 67001
  Registration->register: reg_points=torch.Size([3218, 6]), translation=tensor([-0.7634, -0.5756,  0.8332], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([67001, 6]) -> sampled_points=torch.Size([335005, 6]) time= 0.91 ms
  LatentFeature->update: samples=335005, new_points=11833 (closreSur>VoxDwn>Radius>Distance), all_points=1334001
  TrainingPool->update: Nvs=335005 ->  close_surface_sample_idx=199480, all_points=45625650, increasement: 45290645
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([199480])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.775712, mean_loss=0.775770, diff=-0.000058, thres=0.000100
FrameId=346:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 66006, --cropped--> 66005
  Registration->register: reg_points=torch.Size([3207, 6]), translation=tensor([-0.7472, -0.5714,  0.8210], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([66005, 6]) -> sampled_points=torch.Size([330025, 6]) time= 1.11 ms
  LatentFeature->update: samples=330025, new_points=11714 (closreSur>VoxDwn>Radius>Distance), all_points=1345715
  TrainingPool->update: Nvs=330025 ->  close_surface_sample_idx=196424, all_points=45955675, increasement: 45625650
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([196424])
  TrainingPool->train: break at iter=56, cur_mean_loss=0.773257, mean_loss=0.773352, diff=-0.000095, thres=0.000100
FrameId=347:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 64610, --cropped--> 64609
  Registration->register: reg_points=torch.Size([3146, 6]), translation=tensor([-0.7448, -0.5449,  0.8102], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([64609, 6]) -> sampled_points=torch.Size([323045, 6]) time= 1.03 ms
  LatentFeature->update: samples=323045, new_points=11514 (closreSur>VoxDwn>Radius>Distance), all_points=1357229
  TrainingPool->update: Nvs=323045 ->  close_surface_sample_idx=192535, all_points=46278720, increasement: 45955675
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([192535])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.775086, mean_loss=0.775107, diff=-0.000022, thres=0.000100
FrameId=348:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 64325, --cropped--> 64324
  Registration->register: reg_points=torch.Size([3172, 6]), translation=tensor([-0.7264, -0.5141,  0.8074], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([64324, 6]) -> sampled_points=torch.Size([321620, 6]) time= 1.05 ms
  LatentFeature->update: samples=321620, new_points=11562 (closreSur>VoxDwn>Radius>Distance), all_points=1368791
  TrainingPool->update: Nvs=321620 ->  close_surface_sample_idx=191473, all_points=46600340, increasement: 46278720
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([191473])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.774147, mean_loss=0.774199, diff=-0.000052, thres=0.000100
FrameId=349:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 63859, --cropped--> 63858
  Registration->register: reg_points=torch.Size([3173, 6]), translation=tensor([-0.7069, -0.5043,  0.8041], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([63858, 6]) -> sampled_points=torch.Size([319290, 6]) time= 0.95 ms
  LatentFeature->update: samples=319290, new_points=11445 (closreSur>VoxDwn>Radius>Distance), all_points=1380236
  TrainingPool->update: Nvs=319290 ->  close_surface_sample_idx=190063, all_points=46919630, increasement: 46600340
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([190063])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.773838, mean_loss=0.773779, diff=0.000059, thres=0.000100
FrameId=350:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 63668, --cropped--> 63667
  Registration->register: reg_points=torch.Size([3161, 6]), translation=tensor([-0.7224, -0.5090,  0.7941], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([63667, 6]) -> sampled_points=torch.Size([318335, 6]) time= 1.08 ms
  LatentFeature->update: samples=318335, new_points=11355 (closreSur>VoxDwn>Radius>Distance), all_points=1391591
  TrainingPool->update: Nvs=318335 ->  close_surface_sample_idx=189613, all_points=47237965, increasement: 46919630
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([189613])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.774144, mean_loss=0.774083, diff=0.000061, thres=0.000100
FrameId=351:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 61452, --cropped--> 61451
  Registration->register: reg_points=torch.Size([2970, 6]), translation=tensor([-0.7331, -0.4994,  0.7819], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([61451, 6]) -> sampled_points=torch.Size([307255, 6]) time= 1.13 ms
  LatentFeature->update: samples=307255, new_points=10692 (closreSur>VoxDwn>Radius>Distance), all_points=1402283
  TrainingPool->update: Nvs=307255 ->  close_surface_sample_idx=183053, all_points=47545220, increasement: 47237965
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([183053])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.776482, mean_loss=0.776558, diff=-0.000076, thres=0.000100
FrameId=352:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 59272, --cropped--> 59271
  Registration->register: reg_points=torch.Size([2882, 6]), translation=tensor([-0.7323, -0.5187,  0.7371], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([59271, 6]) -> sampled_points=torch.Size([296355, 6]) time= 1.06 ms
  LatentFeature->update: samples=296355, new_points=10160 (closreSur>VoxDwn>Radius>Distance), all_points=1412443
  TrainingPool->update: Nvs=296355 ->  close_surface_sample_idx=176417, all_points=47841575, increasement: 47545220
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([176417])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.774896, mean_loss=0.774937, diff=-0.000041, thres=0.000100
FrameId=353:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 56092, --cropped--> 56091
  Registration->register: reg_points=torch.Size([2648, 6]), translation=tensor([-0.7188, -0.5155,  0.7105], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([56091, 6]) -> sampled_points=torch.Size([280455, 6]) time= 0.94 ms
  LatentFeature->update: samples=280455, new_points=9356 (closreSur>VoxDwn>Radius>Distance), all_points=1421799
  TrainingPool->update: Nvs=280455 ->  close_surface_sample_idx=167015, all_points=48122030, increasement: 47841575
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([167015])
  TrainingPool->train: break at iter=57, cur_mean_loss=0.773796, mean_loss=0.773771, diff=0.000026, thres=0.000100
FrameId=354:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 54036, --cropped--> 54035
  Registration->register: reg_points=torch.Size([2595, 6]), translation=tensor([-0.7056, -0.4989,  0.6858], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([54035, 6]) -> sampled_points=torch.Size([270175, 6]) time= 1.06 ms
  LatentFeature->update: samples=270175, new_points=8857 (closreSur>VoxDwn>Radius>Distance), all_points=1430656
  TrainingPool->update: Nvs=270175 ->  close_surface_sample_idx=160882, all_points=48392205, increasement: 48122030
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([160882])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.774378, mean_loss=0.774404, diff=-0.000026, thres=0.000100
FrameId=355:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 50852, --cropped--> 50851
  Registration->register: reg_points=torch.Size([2373, 6]), translation=tensor([-0.6949, -0.4887,  0.6664], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([50851, 6]) -> sampled_points=torch.Size([254255, 6]) time= 1.12 ms
  LatentFeature->update: samples=254255, new_points=8210 (closreSur>VoxDwn>Radius>Distance), all_points=1438866
  TrainingPool->update: Nvs=254255 ->  close_surface_sample_idx=151571, all_points=48646460, increasement: 48392205
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([151571])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.774548, mean_loss=0.774514, diff=0.000034, thres=0.000100
FrameId=356:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 47458, --cropped--> 47457
  Registration->register: reg_points=torch.Size([2254, 6]), translation=tensor([-0.6742, -0.4818,  0.6447], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([47457, 6]) -> sampled_points=torch.Size([237285, 6]) time= 0.95 ms
  LatentFeature->update: samples=237285, new_points=7598 (closreSur>VoxDwn>Radius>Distance), all_points=1446464
  TrainingPool->update: Nvs=237285 ->  close_surface_sample_idx=141374, all_points=48883745, increasement: 48646460
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([141374])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.775472, mean_loss=0.775560, diff=-0.000088, thres=0.000100
FrameId=357:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 45528, --cropped--> 45527
  Registration->register: reg_points=torch.Size([2198, 6]), translation=tensor([-0.6655, -0.4901,  0.6255], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([45527, 6]) -> sampled_points=torch.Size([227635, 6]) time= 1.04 ms
  LatentFeature->update: samples=227635, new_points=7371 (closreSur>VoxDwn>Radius>Distance), all_points=1453835
  TrainingPool->update: Nvs=227635 ->  close_surface_sample_idx=135667, all_points=49111380, increasement: 48883745
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([135667])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.773620, mean_loss=0.773691, diff=-0.000071, thres=0.000100
FrameId=358:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 43172, --cropped--> 43171
  Registration->register: reg_points=torch.Size([2045, 6]), translation=tensor([-0.6488, -0.5135,  0.5950], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([43171, 6]) -> sampled_points=torch.Size([215855, 6]) time= 1.06 ms
  LatentFeature->update: samples=215855, new_points=6903 (closreSur>VoxDwn>Radius>Distance), all_points=1460738
  TrainingPool->update: Nvs=215855 ->  close_surface_sample_idx=128644, all_points=49327235, increasement: 49111380
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([128644])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.775393, mean_loss=0.775462, diff=-0.000069, thres=0.000100
FrameId=359:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 41774, --cropped--> 41773
  Registration->register: reg_points=torch.Size([1996, 6]), translation=tensor([-0.6310, -0.5054,  0.5793], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([41773, 6]) -> sampled_points=torch.Size([208865, 6]) time= 0.99 ms
  LatentFeature->update: samples=208865, new_points=6743 (closreSur>VoxDwn>Radius>Distance), all_points=1467481
  TrainingPool->update: Nvs=208865 ->  close_surface_sample_idx=124451, all_points=49536100, increasement: 49327235
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([124451])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.774861, mean_loss=0.774886, diff=-0.000026, thres=0.000100
FrameId=360:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 41009, --cropped--> 41008
  Registration->register: reg_points=torch.Size([1994, 6]), translation=tensor([-0.6176, -0.5054,  0.5669], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([41008, 6]) -> sampled_points=torch.Size([205040, 6]) time= 1.03 ms
  LatentFeature->update: samples=205040, new_points=6688 (closreSur>VoxDwn>Radius>Distance), all_points=1474169
  TrainingPool->update: Nvs=205040 ->  close_surface_sample_idx=122196, all_points=49741140, increasement: 49536100
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([122196])
  TrainingPool->train: break at iter=55, cur_mean_loss=0.775647, mean_loss=0.775703, diff=-0.000055, thres=0.000100
FrameId=361:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 40991, --cropped--> 40990
  Registration->register: reg_points=torch.Size([1994, 6]), translation=tensor([-0.5966, -0.5168,  0.5421], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([40990, 6]) -> sampled_points=torch.Size([204950, 6]) time= 0.99 ms
  LatentFeature->update: samples=204950, new_points=6748 (closreSur>VoxDwn>Radius>Distance), all_points=1480917
  TrainingPool->update: Nvs=204950 ->  close_surface_sample_idx=122241, all_points=49946090, increasement: 49741140
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([122241])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.776101, mean_loss=0.776035, diff=0.000066, thres=0.000100
FrameId=362:  cached_time=2.0 ms
  TumDataset->next_frame: Original=307200 -downsample-> 41418, --cropped--> 41417
  Registration->register: reg_points=torch.Size([2012, 6]), translation=tensor([-0.5841, -0.5082,  0.5271], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([41417, 6]) -> sampled_points=torch.Size([207085, 6]) time= 0.95 ms
  LatentFeature->update: samples=207085, new_points=6881 (closreSur>VoxDwn>Radius>Distance), all_points=1487798
  TrainingPool->update:  All points now is 50153175 > 50000000 frame buffer: discard 153175 points
  TrainingPool->update: Nvs=206496 ->  close_surface_sample_idx=123202, all_points=50000000, increasement: 49793504
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([123202])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.777303, mean_loss=0.777381, diff=-0.000078, thres=0.000100
FrameId=363:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 40795, --cropped--> 40794
  Registration->register: reg_points=torch.Size([1988, 6]), translation=tensor([-0.5736, -0.5105,  0.5214], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([40794, 6]) -> sampled_points=torch.Size([203970, 6]) time= 0.87 ms
  LatentFeature->update: samples=203970, new_points=6750 (closreSur>VoxDwn>Radius>Distance), all_points=1494548
  TrainingPool->update:  All points now is 50203970 > 50000000 frame buffer: discard 203970 points
  TrainingPool->update: Nvs=203150 ->  close_surface_sample_idx=121038, all_points=50000000, increasement: 49796850
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([121038])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.778939, mean_loss=0.778918, diff=0.000021, thres=0.000100
FrameId=364:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 39754, --cropped--> 39753
  Registration->register: reg_points=torch.Size([1914, 6]), translation=tensor([-0.5383, -0.5013,  0.5041], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([39753, 6]) -> sampled_points=torch.Size([198765, 6]) time= 0.98 ms
  LatentFeature->update: samples=198765, new_points=6520 (closreSur>VoxDwn>Radius>Distance), all_points=1501068
  TrainingPool->update:  All points now is 50198765 > 50000000 frame buffer: discard 198765 points
  TrainingPool->update: Nvs=197968 ->  close_surface_sample_idx=117946, all_points=50000000, increasement: 49802032
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([117946])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.779444, mean_loss=0.779399, diff=0.000045, thres=0.000100
FrameId=365:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 41185, --cropped--> 41184
  Registration->register: reg_points=torch.Size([1969, 6]), translation=tensor([-0.5168, -0.4927,  0.4903], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([41184, 6]) -> sampled_points=torch.Size([205920, 6]) time= 1.12 ms
  LatentFeature->update: samples=205920, new_points=6837 (closreSur>VoxDwn>Radius>Distance), all_points=1507905
  TrainingPool->update:  All points now is 50205920 > 50000000 frame buffer: discard 205920 points
  TrainingPool->update: Nvs=205072 ->  close_surface_sample_idx=122249, all_points=50000000, increasement: 49794928
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([122249])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.777704, mean_loss=0.777781, diff=-0.000077, thres=0.000100
FrameId=366:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 42003, --cropped--> 42002
  Registration->register: reg_points=torch.Size([2048, 6]), translation=tensor([-0.4901, -0.5006,  0.4828], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([42002, 6]) -> sampled_points=torch.Size([210010, 6]) time= 0.97 ms
  LatentFeature->update: samples=210010, new_points=7067 (closreSur>VoxDwn>Radius>Distance), all_points=1514972
  TrainingPool->update:  All points now is 50210010 > 50000000 frame buffer: discard 210010 points
  TrainingPool->update: Nvs=209155 ->  close_surface_sample_idx=124689, all_points=50000000, increasement: 49790845
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([124689])
  TrainingPool->train: break at iter=58, cur_mean_loss=0.780568, mean_loss=0.780622, diff=-0.000054, thres=0.000100
FrameId=367:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 42289, --cropped--> 42288
  Registration->register: reg_points=torch.Size([2041, 6]), translation=tensor([-0.4737, -0.5026,  0.4793], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([42288, 6]) -> sampled_points=torch.Size([211440, 6]) time= 0.92 ms
  LatentFeature->update: samples=211440, new_points=7163 (closreSur>VoxDwn>Radius>Distance), all_points=1522135
  TrainingPool->update:  All points now is 50211440 > 50000000 frame buffer: discard 211440 points
  TrainingPool->update: Nvs=210515 ->  close_surface_sample_idx=125479, all_points=50000000, increasement: 49789485
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([125479])
  TrainingPool->train: break at iter=54, cur_mean_loss=0.778608, mean_loss=0.778615, diff=-0.000007, thres=0.000100
FrameId=368:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 43526, --cropped--> 43525
  Registration->register: reg_points=torch.Size([2142, 6]), translation=tensor([-0.4464, -0.5029,  0.4566], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([43525, 6]) -> sampled_points=torch.Size([217625, 6]) time= 1.01 ms
  LatentFeature->update: samples=217625, new_points=7430 (closreSur>VoxDwn>Radius>Distance), all_points=1529565
  TrainingPool->update:  All points now is 50217625 > 50000000 frame buffer: discard 217625 points
  TrainingPool->update: Nvs=216705 ->  close_surface_sample_idx=129086, all_points=50000000, increasement: 49783295
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([129086])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.781420, mean_loss=0.781516, diff=-0.000096, thres=0.000100
FrameId=369:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 45479, --cropped--> 45478
  Registration->register: reg_points=torch.Size([2249, 6]), translation=tensor([-0.4150, -0.5027,  0.4505], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([45478, 6]) -> sampled_points=torch.Size([227390, 6]) time= 1.00 ms
  LatentFeature->update: samples=227390, new_points=7876 (closreSur>VoxDwn>Radius>Distance), all_points=1537441
  TrainingPool->update:  All points now is 50227390 > 50000000 frame buffer: discard 227390 points
  TrainingPool->update: Nvs=226395 ->  close_surface_sample_idx=135011, all_points=50000000, increasement: 49773605
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([135011])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.781057, mean_loss=0.781117, diff=-0.000060, thres=0.000100
FrameId=370:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 46365, --cropped--> 46364
  Registration->register: reg_points=torch.Size([2291, 6]), translation=tensor([-0.3925, -0.5040,  0.4396], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([46364, 6]) -> sampled_points=torch.Size([231820, 6]) time= 0.99 ms
  LatentFeature->update: samples=231820, new_points=8108 (closreSur>VoxDwn>Radius>Distance), all_points=1545549
  TrainingPool->update:  All points now is 50231820 > 50000000 frame buffer: discard 231820 points
  TrainingPool->update: Nvs=230787 ->  close_surface_sample_idx=137530, all_points=50000000, increasement: 49769213
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([137530])
  TrainingPool->train: break at iter=54, cur_mean_loss=0.781470, mean_loss=0.781558, diff=-0.000088, thres=0.000100
FrameId=371:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 46532, --cropped--> 46531
  Registration->register: reg_points=torch.Size([2402, 6]), translation=tensor([-0.3651, -0.5192,  0.4238], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([46531, 6]) -> sampled_points=torch.Size([232655, 6]) time= 0.97 ms
  LatentFeature->update: samples=232655, new_points=8349 (closreSur>VoxDwn>Radius>Distance), all_points=1553898
  TrainingPool->update:  All points now is 50232655 > 50000000 frame buffer: discard 232655 points
  TrainingPool->update: Nvs=231561 ->  close_surface_sample_idx=137931, all_points=50000000, increasement: 49768439
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([137931])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.781577, mean_loss=0.781574, diff=0.000003, thres=0.000100
FrameId=372:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 47172, --cropped--> 47171
  Registration->register: reg_points=torch.Size([2397, 6]), translation=tensor([-0.3288, -0.5194,  0.4116], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([47171, 6]) -> sampled_points=torch.Size([235855, 6]) time= 0.89 ms
  LatentFeature->update: samples=235855, new_points=8446 (closreSur>VoxDwn>Radius>Distance), all_points=1562344
  TrainingPool->update:  All points now is 50235855 > 50000000 frame buffer: discard 235855 points
  TrainingPool->update: Nvs=234692 ->  close_surface_sample_idx=139659, all_points=50000000, increasement: 49765308
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([139659])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.780655, mean_loss=0.780750, diff=-0.000094, thres=0.000100
FrameId=373:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 48700, --cropped--> 48699
  Registration->register: reg_points=torch.Size([2469, 6]), translation=tensor([-0.3089, -0.5164,  0.4115], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([48699, 6]) -> sampled_points=torch.Size([243495, 6]) time= 1.00 ms
  LatentFeature->update: samples=243495, new_points=8770 (closreSur>VoxDwn>Radius>Distance), all_points=1571114
  TrainingPool->update:  All points now is 50243495 > 50000000 frame buffer: discard 243495 points
  TrainingPool->update: Nvs=242329 ->  close_surface_sample_idx=144343, all_points=50000000, increasement: 49757671
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([144343])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.780682, mean_loss=0.780658, diff=0.000024, thres=0.000100
FrameId=374:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 49276, --cropped--> 49275
  Registration->register: reg_points=torch.Size([2541, 6]), translation=tensor([-0.2833, -0.5125,  0.4029], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([49275, 6]) -> sampled_points=torch.Size([246375, 6]) time= 0.92 ms
  LatentFeature->update: samples=246375, new_points=8960 (closreSur>VoxDwn>Radius>Distance), all_points=1580074
  TrainingPool->update:  All points now is 50246375 > 50000000 frame buffer: discard 246375 points
  TrainingPool->update: Nvs=245163 ->  close_surface_sample_idx=146023, all_points=50000000, increasement: 49754837
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([146023])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.780349, mean_loss=0.780362, diff=-0.000013, thres=0.000100
FrameId=375:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 47372, --cropped--> 47371
  Registration->register: reg_points=torch.Size([2421, 6]), translation=tensor([-0.2485, -0.5218,  0.3798], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([47371, 6]) -> sampled_points=torch.Size([236855, 6]) time= 0.93 ms
  LatentFeature->update: samples=236855, new_points=8584 (closreSur>VoxDwn>Radius>Distance), all_points=1588658
  TrainingPool->update:  All points now is 50236855 > 50000000 frame buffer: discard 236855 points
  TrainingPool->update: Nvs=235755 ->  close_surface_sample_idx=140374, all_points=50000000, increasement: 49764245
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([140374])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.779823, mean_loss=0.779774, diff=0.000049, thres=0.000100
FrameId=376:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 46958, --cropped--> 46957
  Registration->register: reg_points=torch.Size([2405, 6]), translation=tensor([-0.2194, -0.5181,  0.3589], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([46957, 6]) -> sampled_points=torch.Size([234785, 6]) time= 1.08 ms
  LatentFeature->update: samples=234785, new_points=8530 (closreSur>VoxDwn>Radius>Distance), all_points=1597188
  TrainingPool->update:  All points now is 50234785 > 50000000 frame buffer: discard 234785 points
  TrainingPool->update: Nvs=233724 ->  close_surface_sample_idx=139148, all_points=50000000, increasement: 49766276
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([139148])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.780366, mean_loss=0.780359, diff=0.000007, thres=0.000100
FrameId=377:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 46949, --cropped--> 46948
  Registration->register: reg_points=torch.Size([2455, 6]), translation=tensor([-0.1934, -0.5213,  0.3536], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([46948, 6]) -> sampled_points=torch.Size([234740, 6]) time= 1.03 ms
  LatentFeature->update: samples=234740, new_points=8573 (closreSur>VoxDwn>Radius>Distance), all_points=1605761
  TrainingPool->update:  All points now is 50234740 > 50000000 frame buffer: discard 234740 points
  TrainingPool->update: Nvs=233651 ->  close_surface_sample_idx=139190, all_points=50000000, increasement: 49766349
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([139190])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.781094, mean_loss=0.781113, diff=-0.000019, thres=0.000100
FrameId=378:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 45765, --cropped--> 45764
  Registration->register: reg_points=torch.Size([2412, 6]), translation=tensor([-0.1584, -0.5211,  0.3379], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([45764, 6]) -> sampled_points=torch.Size([228820, 6]) time= 1.03 ms
  LatentFeature->update: samples=228820, new_points=8383 (closreSur>VoxDwn>Radius>Distance), all_points=1614144
  TrainingPool->update:  All points now is 50228820 > 50000000 frame buffer: discard 228820 points
  TrainingPool->update: Nvs=227818 ->  close_surface_sample_idx=135703, all_points=50000000, increasement: 49772182
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([135703])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.780185, mean_loss=0.780229, diff=-0.000044, thres=0.000100
FrameId=379:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 45754, --cropped--> 45753
  Registration->register: reg_points=torch.Size([2390, 6]), translation=tensor([-0.1260, -0.5549,  0.3270], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([45753, 6]) -> sampled_points=torch.Size([228765, 6]) time= 0.89 ms
  LatentFeature->update: samples=228765, new_points=8473 (closreSur>VoxDwn>Radius>Distance), all_points=1622617
  TrainingPool->update:  All points now is 50228765 > 50000000 frame buffer: discard 228765 points
  TrainingPool->update: Nvs=227730 ->  close_surface_sample_idx=135471, all_points=50000000, increasement: 49772270
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([135471])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.780593, mean_loss=0.780628, diff=-0.000035, thres=0.000100
FrameId=380:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 44226, --cropped--> 44225
  Registration->register: reg_points=torch.Size([2282, 6]), translation=tensor([-0.1037, -0.5896,  0.3175], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([44225, 6]) -> sampled_points=torch.Size([221125, 6]) time= 1.00 ms
  LatentFeature->update: samples=221125, new_points=8108 (closreSur>VoxDwn>Radius>Distance), all_points=1630725
  TrainingPool->update:  All points now is 50221125 > 50000000 frame buffer: discard 221125 points
  TrainingPool->update: Nvs=220147 ->  close_surface_sample_idx=131058, all_points=50000000, increasement: 49779853
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([131058])
  TrainingPool->train: break at iter=58, cur_mean_loss=0.777839, mean_loss=0.777861, diff=-0.000022, thres=0.000100
FrameId=381:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 42723, --cropped--> 42722
  Registration->register: reg_points=torch.Size([2168, 6]), translation=tensor([-0.0758, -0.5667,  0.3087], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([42722, 6]) -> sampled_points=torch.Size([213610, 6]) time= 1.09 ms
  LatentFeature->update: samples=213610, new_points=7699 (closreSur>VoxDwn>Radius>Distance), all_points=1638424
  TrainingPool->update:  All points now is 50213610 > 50000000 frame buffer: discard 213610 points
  TrainingPool->update: Nvs=212738 ->  close_surface_sample_idx=126406, all_points=50000000, increasement: 49787262
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([126406])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.779680, mean_loss=0.779739, diff=-0.000059, thres=0.000100
FrameId=382:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 41373, --cropped--> 41372
  Registration->register: reg_points=torch.Size([2101, 6]), translation=tensor([-0.0425, -0.5714,  0.2897], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([41372, 6]) -> sampled_points=torch.Size([206860, 6]) time= 0.96 ms
  LatentFeature->update: samples=206860, new_points=7381 (closreSur>VoxDwn>Radius>Distance), all_points=1645805
  TrainingPool->update:  All points now is 50206860 > 50000000 frame buffer: discard 206860 points
  TrainingPool->update: Nvs=206010 ->  close_surface_sample_idx=122503, all_points=50000000, increasement: 49793990
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([122503])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.780540, mean_loss=0.780594, diff=-0.000054, thres=0.000100
FrameId=383:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 40280, --cropped--> 40279
  Registration->register: reg_points=torch.Size([2029, 6]), translation=tensor([-0.0443, -0.6091,  0.2880], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([40279, 6]) -> sampled_points=torch.Size([201395, 6]) time= 0.98 ms
  LatentFeature->update: samples=201395, new_points=7184 (closreSur>VoxDwn>Radius>Distance), all_points=1652989
  TrainingPool->update:  All points now is 50201395 > 50000000 frame buffer: discard 201395 points
  TrainingPool->update: Nvs=200575 ->  close_surface_sample_idx=119438, all_points=50000000, increasement: 49799425
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([119438])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.778318, mean_loss=0.778343, diff=-0.000025, thres=0.000100
FrameId=384:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 40429, --cropped--> 40428
  Registration->register: reg_points=torch.Size([2011, 6]), translation=tensor([-0.0231, -0.5995,  0.2810], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([40428, 6]) -> sampled_points=torch.Size([202140, 6]) time= 1.02 ms
  LatentFeature->update: samples=202140, new_points=7055 (closreSur>VoxDwn>Radius>Distance), all_points=1660044
  TrainingPool->update:  All points now is 50202140 > 50000000 frame buffer: discard 202140 points
  TrainingPool->update: Nvs=201337 ->  close_surface_sample_idx=119808, all_points=50000000, increasement: 49798663
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([119808])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.780123, mean_loss=0.780155, diff=-0.000032, thres=0.000100
FrameId=385:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 39849, --cropped--> 39848
  Registration->register: reg_points=torch.Size([1961, 6]), translation=tensor([-0.0088, -0.6321,  0.2846], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([39848, 6]) -> sampled_points=torch.Size([199240, 6]) time= 1.01 ms
  LatentFeature->update: samples=199240, new_points=6911 (closreSur>VoxDwn>Radius>Distance), all_points=1666955
  TrainingPool->update:  All points now is 50199240 > 50000000 frame buffer: discard 199240 points
  TrainingPool->update: Nvs=198456 ->  close_surface_sample_idx=117951, all_points=50000000, increasement: 49801544
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([117951])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.777588, mean_loss=0.777587, diff=0.000001, thres=0.000100
FrameId=386:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 38920, --cropped--> 38919
  Registration->register: reg_points=torch.Size([1978, 6]), translation=tensor([ 0.0276, -0.6189,  0.2713], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([38919, 6]) -> sampled_points=torch.Size([194595, 6]) time= 0.98 ms
  LatentFeature->update: samples=194595, new_points=6782 (closreSur>VoxDwn>Radius>Distance), all_points=1673737
  TrainingPool->update:  All points now is 50194595 > 50000000 frame buffer: discard 194595 points
  TrainingPool->update: Nvs=193841 ->  close_surface_sample_idx=115351, all_points=50000000, increasement: 49806159
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([115351])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.778933, mean_loss=0.779019, diff=-0.000085, thres=0.000100
FrameId=387:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 38794, --cropped--> 38793
  Registration->register: reg_points=torch.Size([1965, 6]), translation=tensor([ 0.0424, -0.6176,  0.2674], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([38793, 6]) -> sampled_points=torch.Size([193965, 6]) time= 1.04 ms
  LatentFeature->update: samples=193965, new_points=6711 (closreSur>VoxDwn>Radius>Distance), all_points=1680448
  TrainingPool->update:  All points now is 50193965 > 50000000 frame buffer: discard 193965 points
  TrainingPool->update: Nvs=193268 ->  close_surface_sample_idx=115112, all_points=50000000, increasement: 49806732
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([115112])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.778982, mean_loss=0.779043, diff=-0.000061, thres=0.000100
FrameId=388:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 37999, --cropped--> 37998
  Registration->register: reg_points=torch.Size([1912, 6]), translation=tensor([ 0.0756, -0.6204,  0.2713], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([37998, 6]) -> sampled_points=torch.Size([189990, 6]) time= 0.88 ms
  LatentFeature->update: samples=189990, new_points=6488 (closreSur>VoxDwn>Radius>Distance), all_points=1686936
  TrainingPool->update:  All points now is 50189990 > 50000000 frame buffer: discard 189990 points
  TrainingPool->update: Nvs=189285 ->  close_surface_sample_idx=112694, all_points=50000000, increasement: 49810715
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([112694])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.777774, mean_loss=0.777864, diff=-0.000090, thres=0.000100
FrameId=389:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 36799, --cropped--> 36798
  Registration->register: reg_points=torch.Size([1808, 6]), translation=tensor([ 0.1099, -0.6483,  0.2586], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([36798, 6]) -> sampled_points=torch.Size([183990, 6]) time= 1.11 ms
  LatentFeature->update: samples=183990, new_points=6064 (closreSur>VoxDwn>Radius>Distance), all_points=1693000
  TrainingPool->update:  All points now is 50183990 > 50000000 frame buffer: discard 183990 points
  TrainingPool->update: Nvs=183367 ->  close_surface_sample_idx=109128, all_points=50000000, increasement: 49816633
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([109128])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.778175, mean_loss=0.778235, diff=-0.000060, thres=0.000100
FrameId=390:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 36605, --cropped--> 36604
  Registration->register: reg_points=torch.Size([1828, 6]), translation=tensor([ 0.1039, -0.6577,  0.2919], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([36604, 6]) -> sampled_points=torch.Size([183020, 6]) time= 0.95 ms
  LatentFeature->update: samples=183020, new_points=6044 (closreSur>VoxDwn>Radius>Distance), all_points=1699044
  TrainingPool->update:  All points now is 50183020 > 50000000 frame buffer: discard 183020 points
  TrainingPool->update: Nvs=182360 ->  close_surface_sample_idx=108497, all_points=50000000, increasement: 49817640
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([108497])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.777884, mean_loss=0.777809, diff=0.000075, thres=0.000100
FrameId=391:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 37594, --cropped--> 37593
  Registration->register: reg_points=torch.Size([1903, 6]), translation=tensor([ 0.1342, -0.6600,  0.2860], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([37593, 6]) -> sampled_points=torch.Size([187965, 6]) time= 0.93 ms
  LatentFeature->update: samples=187965, new_points=6286 (closreSur>VoxDwn>Radius>Distance), all_points=1705330
  TrainingPool->update:  All points now is 50187965 > 50000000 frame buffer: discard 187965 points
  TrainingPool->update: Nvs=187284 ->  close_surface_sample_idx=111480, all_points=50000000, increasement: 49812716
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([111480])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.777996, mean_loss=0.778051, diff=-0.000055, thres=0.000100
FrameId=392:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 38021, --cropped--> 38020
  Registration->register: reg_points=torch.Size([1894, 6]), translation=tensor([ 0.1480, -0.6682,  0.3002], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([38020, 6]) -> sampled_points=torch.Size([190100, 6]) time= 0.98 ms
  LatentFeature->update: samples=190100, new_points=6348 (closreSur>VoxDwn>Radius>Distance), all_points=1711678
  TrainingPool->update:  All points now is 50190100 > 50000000 frame buffer: discard 190100 points
  TrainingPool->update: Nvs=189372 ->  close_surface_sample_idx=112727, all_points=50000000, increasement: 49810628
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([112727])
  TrainingPool->train: break at iter=54, cur_mean_loss=0.776389, mean_loss=0.776385, diff=0.000004, thres=0.000100
FrameId=393:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 38632, --cropped--> 38631
  Registration->register: reg_points=torch.Size([1906, 6]), translation=tensor([ 0.1757, -0.6582,  0.2841], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([38631, 6]) -> sampled_points=torch.Size([193155, 6]) time= 0.94 ms
  LatentFeature->update: samples=193155, new_points=6405 (closreSur>VoxDwn>Radius>Distance), all_points=1718083
  TrainingPool->update:  All points now is 50193155 > 50000000 frame buffer: discard 193155 points
  TrainingPool->update: Nvs=192381 ->  close_surface_sample_idx=114545, all_points=50000000, increasement: 49807619
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([114545])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.776761, mean_loss=0.776841, diff=-0.000080, thres=0.000100
FrameId=394:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 38929, --cropped--> 38928
  Registration->register: reg_points=torch.Size([1858, 6]), translation=tensor([ 0.2157, -0.6294,  0.2658], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([38928, 6]) -> sampled_points=torch.Size([194640, 6]) time= 1.02 ms
  LatentFeature->update: samples=194640, new_points=6360 (closreSur>VoxDwn>Radius>Distance), all_points=1724443
  TrainingPool->update:  All points now is 50194640 > 50000000 frame buffer: discard 194640 points
  TrainingPool->update: Nvs=193862 ->  close_surface_sample_idx=115485, all_points=50000000, increasement: 49806138
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([115485])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.777089, mean_loss=0.777148, diff=-0.000059, thres=0.000100
FrameId=395:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 39212, --cropped--> 39211
  Registration->register: reg_points=torch.Size([1859, 6]), translation=tensor([ 0.2334, -0.6225,  0.2637], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([39211, 6]) -> sampled_points=torch.Size([196055, 6]) time= 0.94 ms
  LatentFeature->update: samples=196055, new_points=6313 (closreSur>VoxDwn>Radius>Distance), all_points=1730756
  TrainingPool->update:  All points now is 50196055 > 50000000 frame buffer: discard 196055 points
  TrainingPool->update: Nvs=195315 ->  close_surface_sample_idx=116203, all_points=50000000, increasement: 49804685
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([116203])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.774216, mean_loss=0.774239, diff=-0.000023, thres=0.000100
FrameId=396:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 38555, --cropped--> 38554
  Registration->register: reg_points=torch.Size([1791, 6]), translation=tensor([ 0.2474, -0.6349,  0.2706], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([38554, 6]) -> sampled_points=torch.Size([192770, 6]) time= 0.99 ms
  LatentFeature->update: samples=192770, new_points=5929 (closreSur>VoxDwn>Radius>Distance), all_points=1736685
  TrainingPool->update:  All points now is 50192770 > 50000000 frame buffer: discard 192770 points
  TrainingPool->update: Nvs=192053 ->  close_surface_sample_idx=114392, all_points=50000000, increasement: 49807947
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([114392])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.775118, mean_loss=0.775151, diff=-0.000033, thres=0.000100
FrameId=397:  cached_time=2.0 ms
  TumDataset->next_frame: Original=307200 -downsample-> 38323, --cropped--> 38322
  Registration->register: reg_points=torch.Size([1800, 6]), translation=tensor([ 0.2808, -0.6369,  0.2566], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([38322, 6]) -> sampled_points=torch.Size([191610, 6]) time= 0.99 ms
  LatentFeature->update: samples=191610, new_points=5919 (closreSur>VoxDwn>Radius>Distance), all_points=1742604
  TrainingPool->update:  All points now is 50191610 > 50000000 frame buffer: discard 191610 points
  TrainingPool->update: Nvs=190878 ->  close_surface_sample_idx=113570, all_points=50000000, increasement: 49809122
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([113570])
  TrainingPool->train: break at iter=55, cur_mean_loss=0.775349, mean_loss=0.775416, diff=-0.000067, thres=0.000100
FrameId=398:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 39552, --cropped--> 39551
  Registration->register: reg_points=torch.Size([1842, 6]), translation=tensor([ 0.2986, -0.6267,  0.2571], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([39551, 6]) -> sampled_points=torch.Size([197755, 6]) time= 0.84 ms
  LatentFeature->update: samples=197755, new_points=6093 (closreSur>VoxDwn>Radius>Distance), all_points=1748697
  TrainingPool->update:  All points now is 50197755 > 50000000 frame buffer: discard 197755 points
  TrainingPool->update: Nvs=196985 ->  close_surface_sample_idx=117336, all_points=50000000, increasement: 49803015
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([117336])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.775907, mean_loss=0.775841, diff=0.000066, thres=0.000100
FrameId=399:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 40646, --cropped--> 40645
  Registration->register: reg_points=torch.Size([1906, 6]), translation=tensor([ 0.3161, -0.6212,  0.2538], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([40645, 6]) -> sampled_points=torch.Size([203225, 6]) time= 1.05 ms
  LatentFeature->update: samples=203225, new_points=6236 (closreSur>VoxDwn>Radius>Distance), all_points=1754933
  TrainingPool->update:  All points now is 50203225 > 50000000 frame buffer: discard 203225 points
  TrainingPool->update: Nvs=202413 ->  close_surface_sample_idx=120419, all_points=50000000, increasement: 49797587
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([120419])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.775337, mean_loss=0.775399, diff=-0.000062, thres=0.000100
FrameId=400:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 40239, --cropped--> 40238
  Registration->register: reg_points=torch.Size([1814, 6]), translation=tensor([ 0.3372, -0.6304,  0.2408], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([40238, 6]) -> sampled_points=torch.Size([201190, 6]) time= 0.88 ms
  LatentFeature->update: samples=201190, new_points=6014 (closreSur>VoxDwn>Radius>Distance), all_points=1760947
  TrainingPool->update:  All points now is 50201190 > 50000000 frame buffer: discard 201190 points
  TrainingPool->update: Nvs=200396 ->  close_surface_sample_idx=119426, all_points=50000000, increasement: 49799604
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([119426])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.775515, mean_loss=0.775544, diff=-0.000029, thres=0.000100
FrameId=401:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 40546, --cropped--> 40545
  Registration->register: reg_points=torch.Size([1879, 6]), translation=tensor([ 0.3626, -0.6262,  0.2396], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([40545, 6]) -> sampled_points=torch.Size([202725, 6]) time= 1.02 ms
  LatentFeature->update: samples=202725, new_points=6130 (closreSur>VoxDwn>Radius>Distance), all_points=1767077
  TrainingPool->update:  All points now is 50202725 > 50000000 frame buffer: discard 202725 points
  TrainingPool->update: Nvs=201914 ->  close_surface_sample_idx=120245, all_points=50000000, increasement: 49798086
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([120245])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.774240, mean_loss=0.774258, diff=-0.000018, thres=0.000100
FrameId=402:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 41242, --cropped--> 41241
  Registration->register: reg_points=torch.Size([1881, 6]), translation=tensor([ 0.3777, -0.6064,  0.2370], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([41241, 6]) -> sampled_points=torch.Size([206205, 6]) time= 1.03 ms
  LatentFeature->update: samples=206205, new_points=6258 (closreSur>VoxDwn>Radius>Distance), all_points=1773335
  TrainingPool->update:  All points now is 50206205 > 50000000 frame buffer: discard 206205 points
  TrainingPool->update: Nvs=205373 ->  close_surface_sample_idx=122244, all_points=50000000, increasement: 49794627
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([122244])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.774571, mean_loss=0.774591, diff=-0.000020, thres=0.000100
FrameId=403:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 41931, --cropped--> 41930
  Registration->register: reg_points=torch.Size([1923, 6]), translation=tensor([ 0.3886, -0.6088,  0.2381], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([41930, 6]) -> sampled_points=torch.Size([209650, 6]) time= 1.02 ms
  LatentFeature->update: samples=209650, new_points=6341 (closreSur>VoxDwn>Radius>Distance), all_points=1779676
  TrainingPool->update:  All points now is 50209650 > 50000000 frame buffer: discard 209650 points
  TrainingPool->update: Nvs=208782 ->  close_surface_sample_idx=124050, all_points=50000000, increasement: 49791218
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([124050])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.774244, mean_loss=0.774172, diff=0.000072, thres=0.000100
FrameId=404:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 41300, --cropped--> 41299
  Registration->register: reg_points=torch.Size([1867, 6]), translation=tensor([ 0.4189, -0.6136,  0.2197], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([41299, 6]) -> sampled_points=torch.Size([206495, 6]) time= 0.95 ms
  LatentFeature->update: samples=206495, new_points=6250 (closreSur>VoxDwn>Radius>Distance), all_points=1785926
  TrainingPool->update:  All points now is 50206495 > 50000000 frame buffer: discard 206495 points
  TrainingPool->update: Nvs=205648 ->  close_surface_sample_idx=122040, all_points=50000000, increasement: 49794352
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([122040])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.773750, mean_loss=0.773735, diff=0.000015, thres=0.000100
FrameId=405:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 42872, --cropped--> 42871
  Registration->register: reg_points=torch.Size([1954, 6]), translation=tensor([ 0.4227, -0.6063,  0.2287], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([42871, 6]) -> sampled_points=torch.Size([214355, 6]) time= 1.49 ms
  LatentFeature->update: samples=214355, new_points=6549 (closreSur>VoxDwn>Radius>Distance), all_points=1792475
  TrainingPool->update:  All points now is 50214355 > 50000000 frame buffer: discard 214355 points
  TrainingPool->update: Nvs=213457 ->  close_surface_sample_idx=126965, all_points=50000000, increasement: 49786543
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([126965])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.773786, mean_loss=0.773784, diff=0.000002, thres=0.000100
FrameId=406:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 43830, --cropped--> 43829
  Registration->register: reg_points=torch.Size([2032, 6]), translation=tensor([ 0.4357, -0.6132,  0.2298], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([43829, 6]) -> sampled_points=torch.Size([219145, 6]) time= 1.10 ms
  LatentFeature->update: samples=219145, new_points=6800 (closreSur>VoxDwn>Radius>Distance), all_points=1799275
  TrainingPool->update:  All points now is 50219145 > 50000000 frame buffer: discard 219145 points
  TrainingPool->update: Nvs=218213 ->  close_surface_sample_idx=129651, all_points=50000000, increasement: 49781787
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([129651])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.775459, mean_loss=0.775418, diff=0.000041, thres=0.000100
FrameId=407:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 44629, --cropped--> 44628
  Registration->register: reg_points=torch.Size([2095, 6]), translation=tensor([ 0.4542, -0.5920,  0.2241], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([44628, 6]) -> sampled_points=torch.Size([223140, 6]) time= 1.10 ms
  LatentFeature->update: samples=223140, new_points=7052 (closreSur>VoxDwn>Radius>Distance), all_points=1806327
  TrainingPool->update:  All points now is 50223140 > 50000000 frame buffer: discard 223140 points
  TrainingPool->update: Nvs=222131 ->  close_surface_sample_idx=132048, all_points=50000000, increasement: 49777869
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([132048])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.773423, mean_loss=0.773400, diff=0.000023, thres=0.000100
FrameId=408:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 45081, --cropped--> 45080
  Registration->register: reg_points=torch.Size([2081, 6]), translation=tensor([ 0.4687, -0.5906,  0.2172], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([45080, 6]) -> sampled_points=torch.Size([225400, 6]) time= 0.90 ms
  LatentFeature->update: samples=225400, new_points=7127 (closreSur>VoxDwn>Radius>Distance), all_points=1813454
  TrainingPool->update:  All points now is 50225400 > 50000000 frame buffer: discard 225400 points
  TrainingPool->update: Nvs=224385 ->  close_surface_sample_idx=132976, all_points=50000000, increasement: 49775615
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([132976])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.773408, mean_loss=0.773410, diff=-0.000002, thres=0.000100
FrameId=409:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 45048, --cropped--> 45047
  Registration->register: reg_points=torch.Size([2110, 6]), translation=tensor([ 0.4787, -0.5766,  0.2094], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([45047, 6]) -> sampled_points=torch.Size([225235, 6]) time= 1.06 ms
  LatentFeature->update: samples=225235, new_points=7201 (closreSur>VoxDwn>Radius>Distance), all_points=1820655
  TrainingPool->update:  All points now is 50225235 > 50000000 frame buffer: discard 225235 points
  TrainingPool->update: Nvs=224219 ->  close_surface_sample_idx=132575, all_points=50000000, increasement: 49775781
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([132575])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.773932, mean_loss=0.773898, diff=0.000034, thres=0.000100
FrameId=410:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 45972, --cropped--> 45971
  Registration->register: reg_points=torch.Size([2157, 6]), translation=tensor([ 0.4920, -0.5717,  0.2015], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([45971, 6]) -> sampled_points=torch.Size([229855, 6]) time= 1.04 ms
  LatentFeature->update: samples=229855, new_points=7408 (closreSur>VoxDwn>Radius>Distance), all_points=1828063
  TrainingPool->update:  All points now is 50229855 > 50000000 frame buffer: discard 229855 points
  TrainingPool->update: Nvs=228815 ->  close_surface_sample_idx=136002, all_points=50000000, increasement: 49771185
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([136002])
  TrainingPool->train: break at iter=54, cur_mean_loss=0.773172, mean_loss=0.773251, diff=-0.000079, thres=0.000100
FrameId=411:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 45961, --cropped--> 45960
  Registration->register: reg_points=torch.Size([2163, 6]), translation=tensor([ 0.5124, -0.5770,  0.1878], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([45960, 6]) -> sampled_points=torch.Size([229800, 6]) time= 1.06 ms
  LatentFeature->update: samples=229800, new_points=7247 (closreSur>VoxDwn>Radius>Distance), all_points=1835310
  TrainingPool->update:  All points now is 50229800 > 50000000 frame buffer: discard 229800 points
  TrainingPool->update: Nvs=228701 ->  close_surface_sample_idx=135326, all_points=50000000, increasement: 49771299
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([135326])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.773738, mean_loss=0.773709, diff=0.000029, thres=0.000100
FrameId=412:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 45344, --cropped--> 45343
  Registration->register: reg_points=torch.Size([2108, 6]), translation=tensor([ 0.5279, -0.5557,  0.1843], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([45343, 6]) -> sampled_points=torch.Size([226715, 6]) time= 0.94 ms
  LatentFeature->update: samples=226715, new_points=7116 (closreSur>VoxDwn>Radius>Distance), all_points=1842426
  TrainingPool->update:  All points now is 50226715 > 50000000 frame buffer: discard 226715 points
  TrainingPool->update: Nvs=225700 ->  close_surface_sample_idx=133649, all_points=50000000, increasement: 49774300
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([133649])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.772440, mean_loss=0.772436, diff=0.000004, thres=0.000100
FrameId=413:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 45855, --cropped--> 45854
  Registration->register: reg_points=torch.Size([2207, 6]), translation=tensor([ 0.5302, -0.5414,  0.1835], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([45854, 6]) -> sampled_points=torch.Size([229270, 6]) time= 0.81 ms
  LatentFeature->update: samples=229270, new_points=7238 (closreSur>VoxDwn>Radius>Distance), all_points=1849664
  TrainingPool->update:  All points now is 50229270 > 50000000 frame buffer: discard 229270 points
  TrainingPool->update: Nvs=228238 ->  close_surface_sample_idx=135096, all_points=50000000, increasement: 49771762
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([135096])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.772706, mean_loss=0.772759, diff=-0.000052, thres=0.000100
FrameId=414:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 47101, --cropped--> 47100
  Registration->register: reg_points=torch.Size([2309, 6]), translation=tensor([ 0.5291, -0.5410,  0.1975], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([47100, 6]) -> sampled_points=torch.Size([235500, 6]) time= 1.15 ms
  LatentFeature->update: samples=235500, new_points=7635 (closreSur>VoxDwn>Radius>Distance), all_points=1857299
  TrainingPool->update:  All points now is 50235500 > 50000000 frame buffer: discard 235500 points
  TrainingPool->update: Nvs=234291 ->  close_surface_sample_idx=139338, all_points=50000000, increasement: 49765709
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([139338])
  TrainingPool->train: break at iter=55, cur_mean_loss=0.773853, mean_loss=0.773870, diff=-0.000017, thres=0.000100
FrameId=415:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 47790, --cropped--> 47789
  Registration->register: reg_points=torch.Size([2288, 6]), translation=tensor([ 0.5424, -0.5335,  0.2058], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([47789, 6]) -> sampled_points=torch.Size([238945, 6]) time= 1.10 ms
  LatentFeature->update: samples=238945, new_points=7626 (closreSur>VoxDwn>Radius>Distance), all_points=1864925
  TrainingPool->update:  All points now is 50238945 > 50000000 frame buffer: discard 238945 points
  TrainingPool->update: Nvs=237828 ->  close_surface_sample_idx=139632, all_points=50000000, increasement: 49762172
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([139632])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.773596, mean_loss=0.773662, diff=-0.000066, thres=0.000100
FrameId=416:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 48718, --cropped--> 48717
  Registration->register: reg_points=torch.Size([2349, 6]), translation=tensor([ 0.5501, -0.5307,  0.1989], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([48717, 6]) -> sampled_points=torch.Size([243585, 6]) time= 0.98 ms
  LatentFeature->update: samples=243585, new_points=7720 (closreSur>VoxDwn>Radius>Distance), all_points=1872645
  TrainingPool->update:  All points now is 50243585 > 50000000 frame buffer: discard 243585 points
  TrainingPool->update: Nvs=242429 ->  close_surface_sample_idx=142087, all_points=50000000, increasement: 49757571
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([142087])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.772674, mean_loss=0.772754, diff=-0.000080, thres=0.000100
FrameId=417:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 49764, --cropped--> 49763
  Registration->register: reg_points=torch.Size([2423, 6]), translation=tensor([ 0.5635, -0.5176,  0.1908], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([49763, 6]) -> sampled_points=torch.Size([248815, 6]) time= 1.03 ms
  LatentFeature->update: samples=248815, new_points=7988 (closreSur>VoxDwn>Radius>Distance), all_points=1880633
  TrainingPool->update:  All points now is 50248815 > 50000000 frame buffer: discard 248815 points
  TrainingPool->update: Nvs=247611 ->  close_surface_sample_idx=145921, all_points=50000000, increasement: 49752389
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([145921])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.772812, mean_loss=0.772901, diff=-0.000089, thres=0.000100
FrameId=418:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 49713, --cropped--> 49712
  Registration->register: reg_points=torch.Size([2401, 6]), translation=tensor([ 0.5599, -0.5136,  0.1926], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([49712, 6]) -> sampled_points=torch.Size([248560, 6]) time= 1.07 ms
  LatentFeature->update: samples=248560, new_points=8054 (closreSur>VoxDwn>Radius>Distance), all_points=1888687
  TrainingPool->update:  All points now is 50248560 > 50000000 frame buffer: discard 248560 points
  TrainingPool->update: Nvs=247345 ->  close_surface_sample_idx=146195, all_points=50000000, increasement: 49752655
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([146195])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.773067, mean_loss=0.773154, diff=-0.000088, thres=0.000100
FrameId=419:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 52158, --cropped--> 52157
  Registration->register: reg_points=torch.Size([2447, 6]), translation=tensor([ 0.5671, -0.5103,  0.1933], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([52157, 6]) -> sampled_points=torch.Size([260785, 6]) time= 1.10 ms
  LatentFeature->update: samples=260785, new_points=8335 (closreSur>VoxDwn>Radius>Distance), all_points=1897022
  TrainingPool->update:  All points now is 50260785 > 50000000 frame buffer: discard 260785 points
  TrainingPool->update: Nvs=259436 ->  close_surface_sample_idx=153721, all_points=50000000, increasement: 49740564
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([153721])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.772650, mean_loss=0.772644, diff=0.000006, thres=0.000100
FrameId=420:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 51933, --cropped--> 51932
  Registration->register: reg_points=torch.Size([2509, 6]), translation=tensor([ 0.5944, -0.5108,  0.1751], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([51932, 6]) -> sampled_points=torch.Size([259660, 6]) time= 1.00 ms
  LatentFeature->update: samples=259660, new_points=8360 (closreSur>VoxDwn>Radius>Distance), all_points=1905382
  TrainingPool->update:  All points now is 50259660 > 50000000 frame buffer: discard 259660 points
  TrainingPool->update: Nvs=258361 ->  close_surface_sample_idx=153221, all_points=50000000, increasement: 49741639
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([153221])
  TrainingPool->train: break at iter=54, cur_mean_loss=0.772635, mean_loss=0.772645, diff=-0.000010, thres=0.000100
FrameId=421:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 52340, --cropped--> 52339
  Registration->register: reg_points=torch.Size([2508, 6]), translation=tensor([ 0.6066, -0.4929,  0.1730], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([52339, 6]) -> sampled_points=torch.Size([261695, 6]) time= 1.10 ms
  LatentFeature->update: samples=261695, new_points=8445 (closreSur>VoxDwn>Radius>Distance), all_points=1913827
  TrainingPool->update:  All points now is 50261695 > 50000000 frame buffer: discard 261695 points
  TrainingPool->update: Nvs=260335 ->  close_surface_sample_idx=153898, all_points=50000000, increasement: 49739665
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([153898])
  TrainingPool->train: break at iter=54, cur_mean_loss=0.771467, mean_loss=0.771396, diff=0.000071, thres=0.000100
FrameId=422:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 54098, --cropped--> 54097
  Registration->register: reg_points=torch.Size([2603, 6]), translation=tensor([ 0.6071, -0.4843,  0.1783], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([54097, 6]) -> sampled_points=torch.Size([270485, 6]) time= 1.01 ms
  LatentFeature->update: samples=270485, new_points=8921 (closreSur>VoxDwn>Radius>Distance), all_points=1922748
  TrainingPool->update:  All points now is 50270485 > 50000000 frame buffer: discard 270485 points
  TrainingPool->update: Nvs=269054 ->  close_surface_sample_idx=159872, all_points=50000000, increasement: 49730946
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([159872])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.771651, mean_loss=0.771643, diff=0.000008, thres=0.000100
FrameId=423:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 54631, --cropped--> 54630
  Registration->register: reg_points=torch.Size([2620, 6]), translation=tensor([ 0.6161, -0.4784,  0.1765], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([54630, 6]) -> sampled_points=torch.Size([273150, 6]) time= 1.04 ms
  LatentFeature->update: samples=273150, new_points=8839 (closreSur>VoxDwn>Radius>Distance), all_points=1931587
  TrainingPool->update:  All points now is 50273150 > 50000000 frame buffer: discard 273150 points
  TrainingPool->update: Nvs=271749 ->  close_surface_sample_idx=160996, all_points=50000000, increasement: 49728251
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([160996])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.772283, mean_loss=0.772319, diff=-0.000036, thres=0.000100
FrameId=424:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 53792, --cropped--> 53791
  Registration->register: reg_points=torch.Size([2537, 6]), translation=tensor([ 0.6312, -0.4680,  0.1656], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([53791, 6]) -> sampled_points=torch.Size([268955, 6]) time= 1.04 ms
  LatentFeature->update: samples=268955, new_points=8693 (closreSur>VoxDwn>Radius>Distance), all_points=1940280
  TrainingPool->update:  All points now is 50268955 > 50000000 frame buffer: discard 268955 points
  TrainingPool->update: Nvs=267521 ->  close_surface_sample_idx=158167, all_points=50000000, increasement: 49732479
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([158167])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.771924, mean_loss=0.771957, diff=-0.000033, thres=0.000100
FrameId=425:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 53781, --cropped--> 53780
  Registration->register: reg_points=torch.Size([2524, 6]), translation=tensor([ 0.6431, -0.4628,  0.1691], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([53780, 6]) -> sampled_points=torch.Size([268900, 6]) time= 0.97 ms
  LatentFeature->update: samples=268900, new_points=8733 (closreSur>VoxDwn>Radius>Distance), all_points=1949013
  TrainingPool->update:  All points now is 50268900 > 50000000 frame buffer: discard 268900 points
  TrainingPool->update: Nvs=267445 ->  close_surface_sample_idx=158157, all_points=50000000, increasement: 49732555
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([158157])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.772480, mean_loss=0.772450, diff=0.000030, thres=0.000100
FrameId=426:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 53672, --cropped--> 53671
  Registration->register: reg_points=torch.Size([2529, 6]), translation=tensor([ 0.6609, -0.4480,  0.1497], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([53671, 6]) -> sampled_points=torch.Size([268355, 6]) time= 1.09 ms
  LatentFeature->update: samples=268355, new_points=8732 (closreSur>VoxDwn>Radius>Distance), all_points=1957745
  TrainingPool->update:  All points now is 50268355 > 50000000 frame buffer: discard 268355 points
  TrainingPool->update: Nvs=266952 ->  close_surface_sample_idx=158371, all_points=50000000, increasement: 49733048
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([158371])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.771517, mean_loss=0.771601, diff=-0.000084, thres=0.000100
FrameId=427:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 55833, --cropped--> 55832
  Registration->register: reg_points=torch.Size([2660, 6]), translation=tensor([ 0.6706, -0.4305,  0.1543], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([55832, 6]) -> sampled_points=torch.Size([279160, 6]) time= 0.97 ms
  LatentFeature->update: samples=279160, new_points=9185 (closreSur>VoxDwn>Radius>Distance), all_points=1966930
  TrainingPool->update:  All points now is 50279160 > 50000000 frame buffer: discard 279160 points
  TrainingPool->update: Nvs=277605 ->  close_surface_sample_idx=164815, all_points=50000000, increasement: 49722395
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([164815])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.771196, mean_loss=0.771249, diff=-0.000053, thres=0.000100
FrameId=428:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 57829, --cropped--> 57828
  Registration->register: reg_points=torch.Size([2773, 6]), translation=tensor([ 0.6693, -0.3927,  0.1692], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([57828, 6]) -> sampled_points=torch.Size([289140, 6]) time= 1.01 ms
  LatentFeature->update: samples=289140, new_points=9669 (closreSur>VoxDwn>Radius>Distance), all_points=1976599
  TrainingPool->update:  All points now is 50289140 > 50000000 frame buffer: discard 289140 points
  TrainingPool->update: Nvs=287565 ->  close_surface_sample_idx=170414, all_points=50000000, increasement: 49712435
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([170414])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.771671, mean_loss=0.771766, diff=-0.000095, thres=0.000100
FrameId=429:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 58159, --cropped--> 58158
  Registration->register: reg_points=torch.Size([2809, 6]), translation=tensor([ 0.6700, -0.3968,  0.1710], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([58158, 6]) -> sampled_points=torch.Size([290790, 6]) time= 1.10 ms
  LatentFeature->update: samples=290790, new_points=9749 (closreSur>VoxDwn>Radius>Distance), all_points=1986348
  TrainingPool->update:  All points now is 50290790 > 50000000 frame buffer: discard 290790 points
  TrainingPool->update: Nvs=289134 ->  close_surface_sample_idx=171889, all_points=50000000, increasement: 49710866
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([171889])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.773359, mean_loss=0.773444, diff=-0.000085, thres=0.000100
FrameId=430:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 58732, --cropped--> 58731
  Registration->register: reg_points=torch.Size([2789, 6]), translation=tensor([ 0.6735, -0.3862,  0.1683], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([58731, 6]) -> sampled_points=torch.Size([293655, 6]) time= 1.06 ms
  LatentFeature->update: samples=293655, new_points=9925 (closreSur>VoxDwn>Radius>Distance), all_points=1996273
  TrainingPool->update:  All points now is 50293655 > 50000000 frame buffer: discard 293655 points
  TrainingPool->update: Nvs=291924 ->  close_surface_sample_idx=173667, all_points=50000000, increasement: 49708076
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([173667])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.773230, mean_loss=0.773229, diff=0.000001, thres=0.000100
FrameId=431:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 59166, --cropped--> 59165
  Registration->register: reg_points=torch.Size([2853, 6]), translation=tensor([ 0.6686, -0.3720,  0.1730], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([59165, 6]) -> sampled_points=torch.Size([295825, 6]) time= 1.10 ms
  LatentFeature->update: samples=295825, new_points=10040 (closreSur>VoxDwn>Radius>Distance), all_points=2006313
  TrainingPool->update:  All points now is 50295825 > 50000000 frame buffer: discard 295825 points
  TrainingPool->update: Nvs=294121 ->  close_surface_sample_idx=174355, all_points=50000000, increasement: 49705879
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([174355])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.773323, mean_loss=0.773268, diff=0.000055, thres=0.000100
FrameId=432:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 58625, --cropped--> 58624
  Registration->register: reg_points=torch.Size([2801, 6]), translation=tensor([ 0.6668, -0.3657,  0.1619], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([58624, 6]) -> sampled_points=torch.Size([293120, 6]) time= 1.11 ms
  LatentFeature->update: samples=293120, new_points=9975 (closreSur>VoxDwn>Radius>Distance), all_points=2016288
  TrainingPool->update:  All points now is 50293120 > 50000000 frame buffer: discard 293120 points
  TrainingPool->update: Nvs=291417 ->  close_surface_sample_idx=172487, all_points=50000000, increasement: 49708583
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([172487])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.773038, mean_loss=0.773076, diff=-0.000038, thres=0.000100
FrameId=433:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 59598, --cropped--> 59597
  Registration->register: reg_points=torch.Size([2865, 6]), translation=tensor([ 0.6619, -0.3426,  0.1583], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([59597, 6]) -> sampled_points=torch.Size([297985, 6]) time= 1.10 ms
  LatentFeature->update: samples=297985, new_points=10093 (closreSur>VoxDwn>Radius>Distance), all_points=2026381
  TrainingPool->update:  All points now is 50297985 > 50000000 frame buffer: discard 297985 points
  TrainingPool->update: Nvs=296273 ->  close_surface_sample_idx=175246, all_points=50000000, increasement: 49703727
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([175246])
  TrainingPool->train: break at iter=54, cur_mean_loss=0.772784, mean_loss=0.772877, diff=-0.000093, thres=0.000100
FrameId=434:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 59490, --cropped--> 59489
  Registration->register: reg_points=torch.Size([2855, 6]), translation=tensor([ 0.6545, -0.3118,  0.1667], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([59489, 6]) -> sampled_points=torch.Size([297445, 6]) time= 1.06 ms
  LatentFeature->update: samples=297445, new_points=10243 (closreSur>VoxDwn>Radius>Distance), all_points=2036624
  TrainingPool->update:  All points now is 50297445 > 50000000 frame buffer: discard 297445 points
  TrainingPool->update: Nvs=295694 ->  close_surface_sample_idx=175024, all_points=50000000, increasement: 49704306
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([175024])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.772555, mean_loss=0.772553, diff=0.000002, thres=0.000100
FrameId=435:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 61286, --cropped--> 61285
  Registration->register: reg_points=torch.Size([2986, 6]), translation=tensor([ 0.6332, -0.2933,  0.1713], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([61285, 6]) -> sampled_points=torch.Size([306425, 6]) time= 1.00 ms
  LatentFeature->update: samples=306425, new_points=10697 (closreSur>VoxDwn>Radius>Distance), all_points=2047321
  TrainingPool->update:  All points now is 50306425 > 50000000 frame buffer: discard 306425 points
  TrainingPool->update: Nvs=304572 ->  close_surface_sample_idx=181210, all_points=50000000, increasement: 49695428
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([181210])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.773702, mean_loss=0.773791, diff=-0.000090, thres=0.000100
FrameId=436:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 61963, --cropped--> 61962
  Registration->register: reg_points=torch.Size([3028, 6]), translation=tensor([ 0.6354, -0.2779,  0.1639], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([61962, 6]) -> sampled_points=torch.Size([309810, 6]) time= 1.07 ms
  LatentFeature->update: samples=309810, new_points=10946 (closreSur>VoxDwn>Radius>Distance), all_points=2058267
  TrainingPool->update:  All points now is 50309810 > 50000000 frame buffer: discard 309810 points
  TrainingPool->update: Nvs=307896 ->  close_surface_sample_idx=181585, all_points=50000000, increasement: 49692104
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([181585])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.774338, mean_loss=0.774306, diff=0.000032, thres=0.000100
FrameId=437:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 63058, --cropped--> 63057
  Registration->register: reg_points=torch.Size([3065, 6]), translation=tensor([ 0.6241, -0.2670,  0.1629], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([63057, 6]) -> sampled_points=torch.Size([315285, 6]) time= 1.12 ms
  LatentFeature->update: samples=315285, new_points=11201 (closreSur>VoxDwn>Radius>Distance), all_points=2069468
  TrainingPool->update:  All points now is 50315285 > 50000000 frame buffer: discard 315285 points
  TrainingPool->update: Nvs=313372 ->  close_surface_sample_idx=185594, all_points=50000000, increasement: 49686628
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([185594])
  TrainingPool->train: break at iter=55, cur_mean_loss=0.774030, mean_loss=0.773957, diff=0.000073, thres=0.000100
FrameId=438:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 61837, --cropped--> 61836
  Registration->register: reg_points=torch.Size([3004, 6]), translation=tensor([ 0.6019, -0.2803,  0.1668], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([61836, 6]) -> sampled_points=torch.Size([309180, 6]) time= 0.95 ms
  LatentFeature->update: samples=309180, new_points=10981 (closreSur>VoxDwn>Radius>Distance), all_points=2080449
  TrainingPool->update:  All points now is 50309180 > 50000000 frame buffer: discard 309180 points
  TrainingPool->update: Nvs=307321 ->  close_surface_sample_idx=181723, all_points=50000000, increasement: 49692679
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([181723])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.774121, mean_loss=0.774165, diff=-0.000043, thres=0.000100
FrameId=439:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 60110, --cropped--> 60109
  Registration->register: reg_points=torch.Size([2954, 6]), translation=tensor([ 0.5954, -0.2802,  0.1507], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([60109, 6]) -> sampled_points=torch.Size([300545, 6]) time= 1.11 ms
  LatentFeature->update: samples=300545, new_points=10564 (closreSur>VoxDwn>Radius>Distance), all_points=2091013
  TrainingPool->update:  All points now is 50300545 > 50000000 frame buffer: discard 300545 points
  TrainingPool->update: Nvs=298756 ->  close_surface_sample_idx=176475, all_points=50000000, increasement: 49701244
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([176475])
  TrainingPool->train: break at iter=55, cur_mean_loss=0.774063, mean_loss=0.774010, diff=0.000053, thres=0.000100
FrameId=440:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 61069, --cropped--> 61068
  Registration->register: reg_points=torch.Size([2983, 6]), translation=tensor([ 0.5946, -0.2514,  0.1356], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([61068, 6]) -> sampled_points=torch.Size([305340, 6]) time= 1.03 ms
  LatentFeature->update: samples=305340, new_points=10802 (closreSur>VoxDwn>Radius>Distance), all_points=2101815
  TrainingPool->update:  All points now is 50305340 > 50000000 frame buffer: discard 305340 points
  TrainingPool->update: Nvs=303500 ->  close_surface_sample_idx=178048, all_points=50000000, increasement: 49696500
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([178048])
  TrainingPool->train: break at iter=54, cur_mean_loss=0.773739, mean_loss=0.773681, diff=0.000058, thres=0.000100
FrameId=441:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 59996, --cropped--> 59995
  Registration->register: reg_points=torch.Size([2905, 6]), translation=tensor([ 0.5809, -0.2457,  0.1297], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([59995, 6]) -> sampled_points=torch.Size([299975, 6]) time= 0.95 ms
  LatentFeature->update: samples=299975, new_points=10507 (closreSur>VoxDwn>Radius>Distance), all_points=2112322
  TrainingPool->update:  All points now is 50299975 > 50000000 frame buffer: discard 299975 points
  TrainingPool->update: Nvs=298236 ->  close_surface_sample_idx=174449, all_points=50000000, increasement: 49701764
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([174449])
  TrainingPool->train: break at iter=54, cur_mean_loss=0.775424, mean_loss=0.775455, diff=-0.000031, thres=0.000100
FrameId=442:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 59024, --cropped--> 59023
  Registration->register: reg_points=torch.Size([2922, 6]), translation=tensor([ 0.5748, -0.2573,  0.1135], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([59023, 6]) -> sampled_points=torch.Size([295115, 6]) time= 1.11 ms
  LatentFeature->update: samples=295115, new_points=10455 (closreSur>VoxDwn>Radius>Distance), all_points=2122777
  TrainingPool->update:  All points now is 50295115 > 50000000 frame buffer: discard 295115 points
  TrainingPool->update: Nvs=293350 ->  close_surface_sample_idx=172709, all_points=50000000, increasement: 49706650
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([172709])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.774301, mean_loss=0.774262, diff=0.000039, thres=0.000100
FrameId=443:  cached_time=2.0 ms
  TumDataset->next_frame: Original=307200 -downsample-> 58162, --cropped--> 58161
  Registration->register: reg_points=torch.Size([2862, 6]), translation=tensor([ 0.5489, -0.2276,  0.1098], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([58161, 6]) -> sampled_points=torch.Size([290805, 6]) time= 1.11 ms
  LatentFeature->update: samples=290805, new_points=10196 (closreSur>VoxDwn>Radius>Distance), all_points=2132973
  TrainingPool->update:  All points now is 50290805 > 50000000 frame buffer: discard 290805 points
  TrainingPool->update: Nvs=289116 ->  close_surface_sample_idx=169667, all_points=50000000, increasement: 49710884
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([169667])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.773431, mean_loss=0.773398, diff=0.000033, thres=0.000100
FrameId=444:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 58166, --cropped--> 58165
  Registration->register: reg_points=torch.Size([2866, 6]), translation=tensor([ 0.5473, -0.2275,  0.0922], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([58165, 6]) -> sampled_points=torch.Size([290825, 6]) time= 1.11 ms
  LatentFeature->update: samples=290825, new_points=10265 (closreSur>VoxDwn>Radius>Distance), all_points=2143238
  TrainingPool->update:  All points now is 50290825 > 50000000 frame buffer: discard 290825 points
  TrainingPool->update: Nvs=289131 ->  close_surface_sample_idx=170882, all_points=50000000, increasement: 49710869
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([170882])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.773369, mean_loss=0.773278, diff=0.000092, thres=0.000100
FrameId=445:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 57084, --cropped--> 57083
  Registration->register: reg_points=torch.Size([2804, 6]), translation=tensor([ 0.5439, -0.2198,  0.0813], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([57083, 6]) -> sampled_points=torch.Size([285415, 6]) time= 1.10 ms
  LatentFeature->update: samples=285415, new_points=9967 (closreSur>VoxDwn>Radius>Distance), all_points=2153205
  TrainingPool->update:  All points now is 50285415 > 50000000 frame buffer: discard 285415 points
  TrainingPool->update: Nvs=283884 ->  close_surface_sample_idx=166943, all_points=50000000, increasement: 49716116
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([166943])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.773574, mean_loss=0.773518, diff=0.000056, thres=0.000100
FrameId=446:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 55626, --cropped--> 55625
  Registration->register: reg_points=torch.Size([2742, 6]), translation=tensor([ 0.5327, -0.2126,  0.0804], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([55625, 6]) -> sampled_points=torch.Size([278125, 6]) time= 1.11 ms
  LatentFeature->update: samples=278125, new_points=9709 (closreSur>VoxDwn>Radius>Distance), all_points=2162914
  TrainingPool->update:  All points now is 50278125 > 50000000 frame buffer: discard 278125 points
  TrainingPool->update: Nvs=276624 ->  close_surface_sample_idx=163694, all_points=50000000, increasement: 49723376
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([163694])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.774432, mean_loss=0.774498, diff=-0.000065, thres=0.000100
FrameId=447:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 54488, --cropped--> 54487
  Registration->register: reg_points=torch.Size([2683, 6]), translation=tensor([ 0.5314, -0.1820,  0.0481], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([54487, 6]) -> sampled_points=torch.Size([272435, 6]) time= 0.94 ms
  LatentFeature->update: samples=272435, new_points=9484 (closreSur>VoxDwn>Radius>Distance), all_points=2172398
  TrainingPool->update:  All points now is 50272435 > 50000000 frame buffer: discard 272435 points
  TrainingPool->update: Nvs=271057 ->  close_surface_sample_idx=160822, all_points=50000000, increasement: 49728943
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([160822])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.773288, mean_loss=0.773249, diff=0.000039, thres=0.000100
FrameId=448:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 54444, --cropped--> 54443
  Registration->register: reg_points=torch.Size([2657, 6]), translation=tensor([ 0.5233, -0.1648,  0.0347], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([54443, 6]) -> sampled_points=torch.Size([272215, 6]) time= 1.01 ms
  LatentFeature->update: samples=272215, new_points=9515 (closreSur>VoxDwn>Radius>Distance), all_points=2181913
  TrainingPool->update:  All points now is 50272215 > 50000000 frame buffer: discard 272215 points
  TrainingPool->update: Nvs=270756 ->  close_surface_sample_idx=160656, all_points=50000000, increasement: 49729244
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([160656])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.773572, mean_loss=0.773512, diff=0.000060, thres=0.000100
FrameId=449:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 54304, --cropped--> 54303
  Registration->register: reg_points=torch.Size([2647, 6]), translation=tensor([ 0.5127, -0.1240,  0.0346], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([54303, 6]) -> sampled_points=torch.Size([271515, 6]) time= 1.01 ms
  LatentFeature->update: samples=271515, new_points=9510 (closreSur>VoxDwn>Radius>Distance), all_points=2191423
  TrainingPool->update:  All points now is 50271515 > 50000000 frame buffer: discard 271515 points
  TrainingPool->update: Nvs=269986 ->  close_surface_sample_idx=160423, all_points=50000000, increasement: 49730014
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([160423])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.774538, mean_loss=0.774491, diff=0.000047, thres=0.000100
FrameId=450:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 53337, --cropped--> 53336
  Registration->register: reg_points=torch.Size([2522, 6]), translation=tensor([ 0.5169, -0.1068,  0.0289], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([53336, 6]) -> sampled_points=torch.Size([266680, 6]) time= 1.10 ms
  LatentFeature->update: samples=266680, new_points=9305 (closreSur>VoxDwn>Radius>Distance), all_points=2200728
  TrainingPool->update:  All points now is 50266680 > 50000000 frame buffer: discard 266680 points
  TrainingPool->update: Nvs=265311 ->  close_surface_sample_idx=157615, all_points=50000000, increasement: 49734689
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([157615])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.773952, mean_loss=0.773956, diff=-0.000004, thres=0.000100
FrameId=451:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 52335, --cropped--> 52334
  Registration->register: reg_points=torch.Size([2515, 6]), translation=tensor([ 0.5168, -0.1134,  0.0142], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([52334, 6]) -> sampled_points=torch.Size([261670, 6]) time= 1.06 ms
  LatentFeature->update: samples=261670, new_points=9117 (closreSur>VoxDwn>Radius>Distance), all_points=2209845
  TrainingPool->update:  All points now is 50261670 > 50000000 frame buffer: discard 261670 points
  TrainingPool->update: Nvs=260408 ->  close_surface_sample_idx=154704, all_points=50000000, increasement: 49739592
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([154704])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.774495, mean_loss=0.774581, diff=-0.000086, thres=0.000100
FrameId=452:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 52416, --cropped--> 52415
  Registration->register: reg_points=torch.Size([2512, 6]), translation=tensor([ 0.5076, -0.1096,  0.0031], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([52415, 6]) -> sampled_points=torch.Size([262075, 6]) time= 1.11 ms
  LatentFeature->update: samples=262075, new_points=9160 (closreSur>VoxDwn>Radius>Distance), all_points=2219005
  TrainingPool->update:  All points now is 50262075 > 50000000 frame buffer: discard 262075 points
  TrainingPool->update: Nvs=260715 ->  close_surface_sample_idx=154980, all_points=50000000, increasement: 49739285
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([154980])
  TrainingPool->train: break at iter=54, cur_mean_loss=0.774048, mean_loss=0.774123, diff=-0.000075, thres=0.000100
FrameId=453:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 51681, --cropped--> 51680
  Registration->register: reg_points=torch.Size([2516, 6]), translation=tensor([ 5.0844e-01, -9.9526e-02,  3.8938e-04], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([51680, 6]) -> sampled_points=torch.Size([258400, 6]) time= 1.03 ms
  LatentFeature->update: samples=258400, new_points=9083 (closreSur>VoxDwn>Radius>Distance), all_points=2228088
  TrainingPool->update:  All points now is 50258400 > 50000000 frame buffer: discard 258400 points
  TrainingPool->update: Nvs=257077 ->  close_surface_sample_idx=152873, all_points=50000000, increasement: 49742923
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([152873])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.774570, mean_loss=0.774627, diff=-0.000057, thres=0.000100
FrameId=454:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 51438, --cropped--> 51437
  Registration->register: reg_points=torch.Size([2453, 6]), translation=tensor([ 0.4930, -0.0701,  0.0147], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([51437, 6]) -> sampled_points=torch.Size([257185, 6]) time= 1.13 ms
  LatentFeature->update: samples=257185, new_points=8916 (closreSur>VoxDwn>Radius>Distance), all_points=2237004
  TrainingPool->update:  All points now is 50257185 > 50000000 frame buffer: discard 257185 points
  TrainingPool->update: Nvs=255839 ->  close_surface_sample_idx=152140, all_points=50000000, increasement: 49744161
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([152140])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.774664, mean_loss=0.774667, diff=-0.000003, thres=0.000100
FrameId=455:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 52836, --cropped--> 52835
  Registration->register: reg_points=torch.Size([2536, 6]), translation=tensor([ 0.4898, -0.0562,  0.0176], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([52835, 6]) -> sampled_points=torch.Size([264175, 6]) time= 1.13 ms
  LatentFeature->update: samples=264175, new_points=9337 (closreSur>VoxDwn>Radius>Distance), all_points=2246341
  TrainingPool->update:  All points now is 50264175 > 50000000 frame buffer: discard 264175 points
  TrainingPool->update: Nvs=262816 ->  close_surface_sample_idx=156232, all_points=50000000, increasement: 49737184
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([156232])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.774941, mean_loss=0.775037, diff=-0.000097, thres=0.000100
FrameId=456:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 53089, --cropped--> 53088
  Registration->register: reg_points=torch.Size([2510, 6]), translation=tensor([ 0.4766, -0.0302,  0.0093], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([53088, 6]) -> sampled_points=torch.Size([265440, 6]) time= 1.12 ms
  LatentFeature->update: samples=265440, new_points=9338 (closreSur>VoxDwn>Radius>Distance), all_points=2255679
  TrainingPool->update:  All points now is 50265440 > 50000000 frame buffer: discard 265440 points
  TrainingPool->update: Nvs=264049 ->  close_surface_sample_idx=156932, all_points=50000000, increasement: 49735951
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([156932])
  TrainingPool->train: break at iter=56, cur_mean_loss=0.774543, mean_loss=0.774503, diff=0.000040, thres=0.000100
FrameId=457:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 52226, --cropped--> 52225
  Registration->register: reg_points=torch.Size([2517, 6]), translation=tensor([ 0.4742, -0.0328,  0.0034], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([52225, 6]) -> sampled_points=torch.Size([261125, 6]) time= 1.02 ms
  LatentFeature->update: samples=261125, new_points=9262 (closreSur>VoxDwn>Radius>Distance), all_points=2264941
  TrainingPool->update:  All points now is 50261125 > 50000000 frame buffer: discard 261125 points
  TrainingPool->update: Nvs=259755 ->  close_surface_sample_idx=154496, all_points=50000000, increasement: 49740245
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([154496])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.776923, mean_loss=0.776857, diff=0.000066, thres=0.000100
FrameId=458:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 53279, --cropped--> 53278
  Registration->register: reg_points=torch.Size([2590, 6]), translation=tensor([ 0.4647, -0.0249, -0.0028], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([53278, 6]) -> sampled_points=torch.Size([266390, 6]) time= 1.01 ms
  LatentFeature->update: samples=266390, new_points=9515 (closreSur>VoxDwn>Radius>Distance), all_points=2274456
  TrainingPool->update:  All points now is 50266390 > 50000000 frame buffer: discard 266390 points
  TrainingPool->update: Nvs=264961 ->  close_surface_sample_idx=157377, all_points=50000000, increasement: 49735039
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([157377])
  TrainingPool->train: break at iter=55, cur_mean_loss=0.775476, mean_loss=0.775440, diff=0.000036, thres=0.000100
FrameId=459:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 55535, --cropped--> 55534
  Registration->register: reg_points=torch.Size([2725, 6]), translation=tensor([ 0.4501, -0.0200,  0.0184], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([55534, 6]) -> sampled_points=torch.Size([277670, 6]) time= 1.00 ms
  LatentFeature->update: samples=277670, new_points=10094 (closreSur>VoxDwn>Radius>Distance), all_points=2284550
  TrainingPool->update:  All points now is 50277670 > 50000000 frame buffer: discard 277670 points
  TrainingPool->update: Nvs=276117 ->  close_surface_sample_idx=163916, all_points=50000000, increasement: 49723883
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([163916])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.776338, mean_loss=0.776390, diff=-0.000053, thres=0.000100
FrameId=460:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 57407, --cropped--> 57406
  Registration->register: reg_points=torch.Size([2799, 6]), translation=tensor([ 0.4336, -0.0075,  0.0289], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([57406, 6]) -> sampled_points=torch.Size([287030, 6]) time= 1.07 ms
  LatentFeature->update: samples=287030, new_points=10485 (closreSur>VoxDwn>Radius>Distance), all_points=2295035
  TrainingPool->update:  All points now is 50287030 > 50000000 frame buffer: discard 287030 points
  TrainingPool->update: Nvs=285406 ->  close_surface_sample_idx=169501, all_points=50000000, increasement: 49714594
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([169501])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.776624, mean_loss=0.776605, diff=0.000019, thres=0.000100
FrameId=461:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 58568, --cropped--> 58567
  Registration->register: reg_points=torch.Size([2878, 6]), translation=tensor([0.4166, 0.0113, 0.0271], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([58567, 6]) -> sampled_points=torch.Size([292835, 6]) time= 1.17 ms
  LatentFeature->update: samples=292835, new_points=10820 (closreSur>VoxDwn>Radius>Distance), all_points=2305855
  TrainingPool->update:  All points now is 50292835 > 50000000 frame buffer: discard 292835 points
  TrainingPool->update: Nvs=291179 ->  close_surface_sample_idx=173081, all_points=50000000, increasement: 49708821
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([173081])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.776937, mean_loss=0.777036, diff=-0.000099, thres=0.000100
FrameId=462:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 60980, --cropped--> 60979
  Registration->register: reg_points=torch.Size([3078, 6]), translation=tensor([0.4022, 0.0270, 0.0226], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([60979, 6]) -> sampled_points=torch.Size([304895, 6]) time= 1.06 ms
  LatentFeature->update: samples=304895, new_points=11452 (closreSur>VoxDwn>Radius>Distance), all_points=2317307
  TrainingPool->update:  All points now is 50304895 > 50000000 frame buffer: discard 304895 points
  TrainingPool->update: Nvs=303048 ->  close_surface_sample_idx=180076, all_points=50000000, increasement: 49696952
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([180076])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.775613, mean_loss=0.775648, diff=-0.000035, thres=0.000100
FrameId=463:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 63484, --cropped--> 63483
  Registration->register: reg_points=torch.Size([3154, 6]), translation=tensor([0.3861, 0.0485, 0.0460], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([63483, 6]) -> sampled_points=torch.Size([317415, 6]) time= 1.00 ms
  LatentFeature->update: samples=317415, new_points=11946 (closreSur>VoxDwn>Radius>Distance), all_points=2329253
  TrainingPool->update:  All points now is 50317415 > 50000000 frame buffer: discard 317415 points
  TrainingPool->update: Nvs=315404 ->  close_surface_sample_idx=187523, all_points=50000000, increasement: 49684596
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([187523])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.776071, mean_loss=0.776008, diff=0.000064, thres=0.000100
FrameId=464:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 63142, --cropped--> 63141
  Registration->register: reg_points=torch.Size([3161, 6]), translation=tensor([0.3698, 0.0577, 0.0564], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([63141, 6]) -> sampled_points=torch.Size([315705, 6]) time= 1.00 ms
  LatentFeature->update: samples=315705, new_points=11881 (closreSur>VoxDwn>Radius>Distance), all_points=2341134
  TrainingPool->update:  All points now is 50315705 > 50000000 frame buffer: discard 315705 points
  TrainingPool->update: Nvs=313776 ->  close_surface_sample_idx=186225, all_points=50000000, increasement: 49686224
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([186225])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.775655, mean_loss=0.775695, diff=-0.000040, thres=0.000100
FrameId=465:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 62270, --cropped--> 62269
  Registration->register: reg_points=torch.Size([3068, 6]), translation=tensor([0.3584, 0.0639, 0.0590], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([62269, 6]) -> sampled_points=torch.Size([311345, 6]) time= 1.15 ms
  LatentFeature->update: samples=311345, new_points=11690 (closreSur>VoxDwn>Radius>Distance), all_points=2352824
  TrainingPool->update:  All points now is 50311345 > 50000000 frame buffer: discard 311345 points
  TrainingPool->update: Nvs=309462 ->  close_surface_sample_idx=183947, all_points=50000000, increasement: 49690538
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([183947])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.774837, mean_loss=0.774887, diff=-0.000050, thres=0.000100
FrameId=466:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 61462, --cropped--> 61461
  Registration->register: reg_points=torch.Size([3046, 6]), translation=tensor([0.3519, 0.0628, 0.0600], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([61461, 6]) -> sampled_points=torch.Size([307305, 6]) time= 1.18 ms
  LatentFeature->update: samples=307305, new_points=11406 (closreSur>VoxDwn>Radius>Distance), all_points=2364230
  TrainingPool->update:  All points now is 50307305 > 50000000 frame buffer: discard 307305 points
  TrainingPool->update: Nvs=305469 ->  close_surface_sample_idx=181415, all_points=50000000, increasement: 49694531
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([181415])
  TrainingPool->train: break at iter=54, cur_mean_loss=0.775111, mean_loss=0.775204, diff=-0.000093, thres=0.000100
FrameId=467:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 59422, --cropped--> 59421
  Registration->register: reg_points=torch.Size([2957, 6]), translation=tensor([0.3573, 0.0616, 0.0481], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([59421, 6]) -> sampled_points=torch.Size([297105, 6]) time= 1.13 ms
  LatentFeature->update: samples=297105, new_points=11003 (closreSur>VoxDwn>Radius>Distance), all_points=2375233
  TrainingPool->update:  All points now is 50297105 > 50000000 frame buffer: discard 297105 points
  TrainingPool->update: Nvs=295353 ->  close_surface_sample_idx=175427, all_points=50000000, increasement: 49704647
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([175427])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.775867, mean_loss=0.775859, diff=0.000008, thres=0.000100
FrameId=468:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 54619, --cropped--> 54618
  Registration->register: reg_points=torch.Size([2711, 6]), translation=tensor([0.3653, 0.0331, 0.0584], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([54618, 6]) -> sampled_points=torch.Size([273090, 6]) time= 1.02 ms
  LatentFeature->update: samples=273090, new_points=9989 (closreSur>VoxDwn>Radius>Distance), all_points=2385222
  TrainingPool->update:  All points now is 50273090 > 50000000 frame buffer: discard 273090 points
  TrainingPool->update: Nvs=271600 ->  close_surface_sample_idx=161425, all_points=50000000, increasement: 49728400
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([161425])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.775697, mean_loss=0.775742, diff=-0.000045, thres=0.000100
FrameId=469:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 49596, --cropped--> 49595
  Registration->register: reg_points=torch.Size([2426, 6]), translation=tensor([0.3650, 0.0158, 0.0413], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([49595, 6]) -> sampled_points=torch.Size([247975, 6]) time= 1.19 ms
  LatentFeature->update: samples=247975, new_points=8667 (closreSur>VoxDwn>Radius>Distance), all_points=2393889
  TrainingPool->update:  All points now is 50247975 > 50000000 frame buffer: discard 247975 points
  TrainingPool->update: Nvs=246727 ->  close_surface_sample_idx=146666, all_points=50000000, increasement: 49753273
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([146666])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.775094, mean_loss=0.775033, diff=0.000061, thres=0.000100
FrameId=470:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 46394, --cropped--> 46393
  Registration->register: reg_points=torch.Size([2237, 6]), translation=tensor([0.3607, 0.0599, 0.0178], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([46393, 6]) -> sampled_points=torch.Size([231965, 6]) time= 1.06 ms
  LatentFeature->update: samples=231965, new_points=8021 (closreSur>VoxDwn>Radius>Distance), all_points=2401910
  TrainingPool->update:  All points now is 50231965 > 50000000 frame buffer: discard 231965 points
  TrainingPool->update: Nvs=230884 ->  close_surface_sample_idx=137283, all_points=50000000, increasement: 49769116
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([137283])
  TrainingPool->train: break at iter=58, cur_mean_loss=0.773652, mean_loss=0.773746, diff=-0.000094, thres=0.000100
FrameId=471:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 42548, --cropped--> 42547
  Registration->register: reg_points=torch.Size([2009, 6]), translation=tensor([0.3218, 0.0665, 0.0329], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([42547, 6]) -> sampled_points=torch.Size([212735, 6]) time= 0.96 ms
  LatentFeature->update: samples=212735, new_points=7107 (closreSur>VoxDwn>Radius>Distance), all_points=2409017
  TrainingPool->update:  All points now is 50212735 > 50000000 frame buffer: discard 212735 points
  TrainingPool->update: Nvs=211851 ->  close_surface_sample_idx=125892, all_points=50000000, increasement: 49788149
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([125892])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.774702, mean_loss=0.774779, diff=-0.000077, thres=0.000100
FrameId=472:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 38368, --cropped--> 38367
  Registration->register: reg_points=torch.Size([1812, 6]), translation=tensor([0.3202, 0.0700, 0.0243], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([38367, 6]) -> sampled_points=torch.Size([191835, 6]) time= 0.97 ms
  LatentFeature->update: samples=191835, new_points=6027 (closreSur>VoxDwn>Radius>Distance), all_points=2415044
  TrainingPool->update:  All points now is 50191835 > 50000000 frame buffer: discard 191835 points
  TrainingPool->update: Nvs=191127 ->  close_surface_sample_idx=113198, all_points=50000000, increasement: 49808873
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([113198])
  TrainingPool->train: break at iter=54, cur_mean_loss=0.774046, mean_loss=0.773959, diff=0.000087, thres=0.000100
FrameId=473:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 34847, --cropped--> 34846
  Registration->register: reg_points=torch.Size([1527, 6]), translation=tensor([0.3126, 0.0835, 0.0109], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([34846, 6]) -> sampled_points=torch.Size([174230, 6]) time= 1.03 ms
  LatentFeature->update: samples=174230, new_points=5175 (closreSur>VoxDwn>Radius>Distance), all_points=2420219
  TrainingPool->update:  All points now is 50174230 > 50000000 frame buffer: discard 174230 points
  TrainingPool->update: Nvs=173610 ->  close_surface_sample_idx=103243, all_points=50000000, increasement: 49826390
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([103243])
  TrainingPool->train: break at iter=55, cur_mean_loss=0.774013, mean_loss=0.774099, diff=-0.000086, thres=0.000100
FrameId=474:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 33071, --cropped--> 33070
  Registration->register: reg_points=torch.Size([1478, 6]), translation=tensor([0.3088, 0.1066, 0.0028], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([33070, 6]) -> sampled_points=torch.Size([165350, 6]) time= 0.91 ms
  LatentFeature->update: samples=165350, new_points=4780 (closreSur>VoxDwn>Radius>Distance), all_points=2424999
  TrainingPool->update:  All points now is 50165350 > 50000000 frame buffer: discard 165350 points
  TrainingPool->update: Nvs=164811 ->  close_surface_sample_idx=98023, all_points=50000000, increasement: 49835189
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([98023])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.772368, mean_loss=0.772459, diff=-0.000091, thres=0.000100
FrameId=475:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 31149, --cropped--> 31148
  Registration->register: reg_points=torch.Size([1353, 6]), translation=tensor([0.2960, 0.1011, 0.0015], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([31148, 6]) -> sampled_points=torch.Size([155740, 6]) time= 0.88 ms
  LatentFeature->update: samples=155740, new_points=4431 (closreSur>VoxDwn>Radius>Distance), all_points=2429430
  TrainingPool->update:  All points now is 50155740 > 50000000 frame buffer: discard 155740 points
  TrainingPool->update: Nvs=155270 ->  close_surface_sample_idx=92390, all_points=50000000, increasement: 49844730
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([92390])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.772517, mean_loss=0.772514, diff=0.000004, thres=0.000100
FrameId=476:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 29785, --cropped--> 29784
  Registration->register: reg_points=torch.Size([1254, 6]), translation=tensor([ 0.2908,  0.1044, -0.0106], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([29784, 6]) -> sampled_points=torch.Size([148920, 6]) time= 0.91 ms
  LatentFeature->update: samples=148920, new_points=4125 (closreSur>VoxDwn>Radius>Distance), all_points=2433555
  TrainingPool->update:  All points now is 50148920 > 50000000 frame buffer: discard 148920 points
  TrainingPool->update: Nvs=148482 ->  close_surface_sample_idx=88342, all_points=50000000, increasement: 49851518
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([88342])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.774118, mean_loss=0.774029, diff=0.000090, thres=0.000100
FrameId=477:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 28488, --cropped--> 28487
  Registration->register: reg_points=torch.Size([1213, 6]), translation=tensor([ 0.2714,  0.1093, -0.0156], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([28487, 6]) -> sampled_points=torch.Size([142435, 6]) time= 0.98 ms
  LatentFeature->update: samples=142435, new_points=3873 (closreSur>VoxDwn>Radius>Distance), all_points=2437428
  TrainingPool->update:  All points now is 50142435 > 50000000 frame buffer: discard 142435 points
  TrainingPool->update: Nvs=142025 ->  close_surface_sample_idx=84565, all_points=50000000, increasement: 49857975
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([84565])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.771223, mean_loss=0.771289, diff=-0.000066, thres=0.000100
FrameId=478:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 26916, --cropped--> 26915
  Registration->register: reg_points=torch.Size([1106, 6]), translation=tensor([ 0.2773,  0.0942, -0.0279], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([26915, 6]) -> sampled_points=torch.Size([134575, 6]) time= 0.98 ms
  LatentFeature->update: samples=134575, new_points=3545 (closreSur>VoxDwn>Radius>Distance), all_points=2440973
  TrainingPool->update:  All points now is 50134575 > 50000000 frame buffer: discard 134575 points
  TrainingPool->update: Nvs=134260 ->  close_surface_sample_idx=79908, all_points=50000000, increasement: 49865740
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([79908])
  TrainingPool->train: break at iter=54, cur_mean_loss=0.770992, mean_loss=0.770989, diff=0.000003, thres=0.000100
FrameId=479:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 25726, --cropped--> 25725
  Registration->register: reg_points=torch.Size([985, 6]), translation=tensor([ 0.2850,  0.0870, -0.0546], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([25725, 6]) -> sampled_points=torch.Size([128625, 6]) time= 0.98 ms
  LatentFeature->update: samples=128625, new_points=3297 (closreSur>VoxDwn>Radius>Distance), all_points=2444270
  TrainingPool->update:  All points now is 50128625 > 50000000 frame buffer: discard 128625 points
  TrainingPool->update: Nvs=128282 ->  close_surface_sample_idx=76414, all_points=50000000, increasement: 49871718
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([76414])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.772969, mean_loss=0.772957, diff=0.000012, thres=0.000100
FrameId=480:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 25254, --cropped--> 25253
  Registration->register: reg_points=torch.Size([971, 6]), translation=tensor([ 0.2536,  0.0755, -0.0325], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([25253, 6]) -> sampled_points=torch.Size([126265, 6]) time= 1.03 ms
  LatentFeature->update: samples=126265, new_points=3179 (closreSur>VoxDwn>Radius>Distance), all_points=2447449
  TrainingPool->update:  All points now is 50126265 > 50000000 frame buffer: discard 126265 points
  TrainingPool->update: Nvs=125942 ->  close_surface_sample_idx=74930, all_points=50000000, increasement: 49874058
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([74930])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.771775, mean_loss=0.771854, diff=-0.000079, thres=0.000100
FrameId=481:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 24588, --cropped--> 24587
  Registration->register: reg_points=torch.Size([931, 6]), translation=tensor([ 0.2429,  0.0863, -0.0411], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([24587, 6]) -> sampled_points=torch.Size([122935, 6]) time= 0.98 ms
  LatentFeature->update: samples=122935, new_points=3097 (closreSur>VoxDwn>Radius>Distance), all_points=2450546
  TrainingPool->update:  All points now is 50122935 > 50000000 frame buffer: discard 122935 points
  TrainingPool->update: Nvs=122642 ->  close_surface_sample_idx=73080, all_points=50000000, increasement: 49877358
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([73080])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.772752, mean_loss=0.772753, diff=-0.000001, thres=0.000100
FrameId=482:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 23984, --cropped--> 23983
  Registration->register: reg_points=torch.Size([911, 6]), translation=tensor([ 0.2465,  0.0740, -0.0586], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([23983, 6]) -> sampled_points=torch.Size([119915, 6]) time= 1.01 ms
  LatentFeature->update: samples=119915, new_points=2976 (closreSur>VoxDwn>Radius>Distance), all_points=2453522
  TrainingPool->update:  All points now is 50119915 > 50000000 frame buffer: discard 119915 points
  TrainingPool->update: Nvs=119635 ->  close_surface_sample_idx=71234, all_points=50000000, increasement: 49880365
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([71234])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.771991, mean_loss=0.771969, diff=0.000022, thres=0.000100
FrameId=483:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 23002, --cropped--> 23001
  Registration->register: reg_points=torch.Size([873, 6]), translation=tensor([ 0.2387,  0.0640, -0.0662], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([23001, 6]) -> sampled_points=torch.Size([115005, 6]) time= 1.04 ms
  LatentFeature->update: samples=115005, new_points=2884 (closreSur>VoxDwn>Radius>Distance), all_points=2456406
  TrainingPool->update:  All points now is 50115005 > 50000000 frame buffer: discard 115005 points
  TrainingPool->update: Nvs=114745 ->  close_surface_sample_idx=68341, all_points=50000000, increasement: 49885255
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([68341])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.772325, mean_loss=0.772326, diff=-0.000001, thres=0.000100
FrameId=484:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 22861, --cropped--> 22860
  Registration->register: reg_points=torch.Size([863, 6]), translation=tensor([ 0.2409,  0.0504, -0.0809], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([22860, 6]) -> sampled_points=torch.Size([114300, 6]) time= 0.97 ms
  LatentFeature->update: samples=114300, new_points=2836 (closreSur>VoxDwn>Radius>Distance), all_points=2459242
  TrainingPool->update:  All points now is 50114300 > 50000000 frame buffer: discard 114300 points
  TrainingPool->update: Nvs=114006 ->  close_surface_sample_idx=67957, all_points=50000000, increasement: 49885994
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([67957])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.770340, mean_loss=0.770394, diff=-0.000054, thres=0.000100
FrameId=485:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 22223, --cropped--> 22222
  Registration->register: reg_points=torch.Size([841, 6]), translation=tensor([ 0.2342,  0.0404, -0.0915], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([22222, 6]) -> sampled_points=torch.Size([111110, 6]) time= 0.91 ms
  LatentFeature->update: samples=111110, new_points=2764 (closreSur>VoxDwn>Radius>Distance), all_points=2462006
  TrainingPool->update:  All points now is 50111110 > 50000000 frame buffer: discard 111110 points
  TrainingPool->update: Nvs=110852 ->  close_surface_sample_idx=66125, all_points=50000000, increasement: 49889148
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([66125])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.772894, mean_loss=0.772920, diff=-0.000026, thres=0.000100
FrameId=486:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 22071, --cropped--> 22070
  Registration->register: reg_points=torch.Size([817, 6]), translation=tensor([ 0.2391,  0.0498, -0.1152], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([22070, 6]) -> sampled_points=torch.Size([110350, 6]) time= 0.96 ms
  LatentFeature->update: samples=110350, new_points=2749 (closreSur>VoxDwn>Radius>Distance), all_points=2464755
  TrainingPool->update:  All points now is 50110350 > 50000000 frame buffer: discard 110350 points
  TrainingPool->update: Nvs=110138 ->  close_surface_sample_idx=65719, all_points=50000000, increasement: 49889862
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([65719])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.770866, mean_loss=0.770882, diff=-0.000016, thres=0.000100
FrameId=487:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 21627, --cropped--> 21626
  Registration->register: reg_points=torch.Size([797, 6]), translation=tensor([ 0.2219,  0.0408, -0.1155], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([21626, 6]) -> sampled_points=torch.Size([108130, 6]) time= 0.85 ms
  LatentFeature->update: samples=108130, new_points=2699 (closreSur>VoxDwn>Radius>Distance), all_points=2467454
  TrainingPool->update:  All points now is 50108130 > 50000000 frame buffer: discard 108130 points
  TrainingPool->update: Nvs=107916 ->  close_surface_sample_idx=64287, all_points=50000000, increasement: 49892084
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([64287])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.773269, mean_loss=0.773186, diff=0.000083, thres=0.000100
FrameId=488:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 21145, --cropped--> 21144
  Registration->register: reg_points=torch.Size([803, 6]), translation=tensor([ 0.2116,  0.0406, -0.1362], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([21144, 6]) -> sampled_points=torch.Size([105720, 6]) time= 0.90 ms
  LatentFeature->update: samples=105720, new_points=2603 (closreSur>VoxDwn>Radius>Distance), all_points=2470057
  TrainingPool->update:  All points now is 50105720 > 50000000 frame buffer: discard 105720 points
  TrainingPool->update: Nvs=105532 ->  close_surface_sample_idx=62798, all_points=50000000, increasement: 49894468
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([62798])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.771298, mean_loss=0.771350, diff=-0.000052, thres=0.000100
FrameId=489:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 20788, --cropped--> 20787
  Registration->register: reg_points=torch.Size([795, 6]), translation=tensor([ 0.2144,  0.0361, -0.1508], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([20787, 6]) -> sampled_points=torch.Size([103935, 6]) time= 1.04 ms
  LatentFeature->update: samples=103935, new_points=2543 (closreSur>VoxDwn>Radius>Distance), all_points=2472600
  TrainingPool->update:  All points now is 50103935 > 50000000 frame buffer: discard 103935 points
  TrainingPool->update: Nvs=103733 ->  close_surface_sample_idx=61664, all_points=50000000, increasement: 49896267
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([61664])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.771262, mean_loss=0.771236, diff=0.000026, thres=0.000100
FrameId=490:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 20471, --cropped--> 20470
  Registration->register: reg_points=torch.Size([740, 6]), translation=tensor([ 0.2003,  0.0418, -0.1683], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([20470, 6]) -> sampled_points=torch.Size([102350, 6]) time= 0.94 ms
  LatentFeature->update: samples=102350, new_points=2553 (closreSur>VoxDwn>Radius>Distance), all_points=2475153
  TrainingPool->update:  All points now is 50102350 > 50000000 frame buffer: discard 102350 points
  TrainingPool->update: Nvs=102152 ->  close_surface_sample_idx=60935, all_points=50000000, increasement: 49897848
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([60935])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.771397, mean_loss=0.771385, diff=0.000012, thres=0.000100
FrameId=491:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 20309, --cropped--> 20308
  Registration->register: reg_points=torch.Size([736, 6]), translation=tensor([ 0.2047, -0.0056, -0.1883], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([20308, 6]) -> sampled_points=torch.Size([101540, 6]) time= 0.92 ms
  LatentFeature->update: samples=101540, new_points=2512 (closreSur>VoxDwn>Radius>Distance), all_points=2477665
  TrainingPool->update:  All points now is 50101540 > 50000000 frame buffer: discard 101540 points
  TrainingPool->update: Nvs=101337 ->  close_surface_sample_idx=60415, all_points=50000000, increasement: 49898663
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([60415])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.771783, mean_loss=0.771783, diff=-0.000000, thres=0.000100
FrameId=492:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 19869, --cropped--> 19868
  Registration->register: reg_points=torch.Size([736, 6]), translation=tensor([ 0.2154, -0.0232, -0.2119], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([19868, 6]) -> sampled_points=torch.Size([99340, 6]) time= 0.90 ms
  LatentFeature->update: samples=99340, new_points=2446 (closreSur>VoxDwn>Radius>Distance), all_points=2480111
  TrainingPool->update:  All points now is 50099340 > 50000000 frame buffer: discard 99340 points
  TrainingPool->update: Nvs=99152 ->  close_surface_sample_idx=59114, all_points=50000000, increasement: 49900848
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([59114])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.770969, mean_loss=0.770895, diff=0.000074, thres=0.000100
FrameId=493:  cached_time=1.9 ms
  TumDataset->next_frame: Original=307200 -downsample-> 19228, --cropped--> 19227
  Registration->register: reg_points=torch.Size([696, 6]), translation=tensor([ 0.1803, -0.0063, -0.2064], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([19227, 6]) -> sampled_points=torch.Size([96135, 6]) time= 0.93 ms
  LatentFeature->update: samples=96135, new_points=2355 (closreSur>VoxDwn>Radius>Distance), all_points=2482466
  TrainingPool->update:  All points now is 50096135 > 50000000 frame buffer: discard 96135 points
  TrainingPool->update: Nvs=95955 ->  close_surface_sample_idx=57189, all_points=50000000, increasement: 49904045
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([57189])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.770376, mean_loss=0.770343, diff=0.000033, thres=0.000100
FrameId=494:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 18341, --cropped--> 18340
  Registration->register: reg_points=torch.Size([669, 6]), translation=tensor([ 0.1740, -0.0371, -0.2158], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([18340, 6]) -> sampled_points=torch.Size([91700, 6]) time= 0.97 ms
  LatentFeature->update: samples=91700, new_points=2267 (closreSur>VoxDwn>Radius>Distance), all_points=2484733
  TrainingPool->update:  All points now is 50091700 > 50000000 frame buffer: discard 91700 points
  TrainingPool->update: Nvs=91534 ->  close_surface_sample_idx=54539, all_points=50000000, increasement: 49908466
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([54539])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.771232, mean_loss=0.771198, diff=0.000035, thres=0.000100
FrameId=495:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 17698, --cropped--> 17697
  Registration->register: reg_points=torch.Size([636, 6]), translation=tensor([ 0.1554, -0.0553, -0.2147], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([17697, 6]) -> sampled_points=torch.Size([88485, 6]) time= 0.96 ms
  LatentFeature->update: samples=88485, new_points=2148 (closreSur>VoxDwn>Radius>Distance), all_points=2486881
  TrainingPool->update:  All points now is 50088485 > 50000000 frame buffer: discard 88485 points
  TrainingPool->update: Nvs=88341 ->  close_surface_sample_idx=52674, all_points=50000000, increasement: 49911659
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([52674])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.771185, mean_loss=0.771134, diff=0.000051, thres=0.000100
FrameId=496:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 17024, --cropped--> 17023
  Registration->register: reg_points=torch.Size([621, 6]), translation=tensor([ 0.1451, -0.0826, -0.2160], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([17023, 6]) -> sampled_points=torch.Size([85115, 6]) time= 0.80 ms
  LatentFeature->update: samples=85115, new_points=2067 (closreSur>VoxDwn>Radius>Distance), all_points=2488948
  TrainingPool->update:  All points now is 50085115 > 50000000 frame buffer: discard 85115 points
  TrainingPool->update: Nvs=84983 ->  close_surface_sample_idx=50617, all_points=50000000, increasement: 49915017
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([50617])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.771098, mean_loss=0.771111, diff=-0.000013, thres=0.000100
FrameId=497:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 16304, --cropped--> 16303
  Registration->register: reg_points=torch.Size([589, 6]), translation=tensor([ 0.1514, -0.0674, -0.2320], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([16303, 6]) -> sampled_points=torch.Size([81515, 6]) time= 0.96 ms
  LatentFeature->update: samples=81515, new_points=1983 (closreSur>VoxDwn>Radius>Distance), all_points=2490931
  TrainingPool->update:  All points now is 50081515 > 50000000 frame buffer: discard 81515 points
  TrainingPool->update: Nvs=81390 ->  close_surface_sample_idx=48502, all_points=50000000, increasement: 49918610
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([48502])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.770425, mean_loss=0.770374, diff=0.000051, thres=0.000100
FrameId=498:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 15674, --cropped--> 15673
  Registration->register: reg_points=torch.Size([535, 6]), translation=tensor([ 0.1546, -0.0828, -0.2427], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([15673, 6]) -> sampled_points=torch.Size([78365, 6]) time= 1.02 ms
  LatentFeature->update: samples=78365, new_points=1881 (closreSur>VoxDwn>Radius>Distance), all_points=2492812
  TrainingPool->update:  All points now is 50078365 > 50000000 frame buffer: discard 78365 points
  TrainingPool->update: Nvs=78229 ->  close_surface_sample_idx=46673, all_points=50000000, increasement: 49921771
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([46673])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.772441, mean_loss=0.772464, diff=-0.000023, thres=0.000100
FrameId=499:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 15051, --cropped--> 15050
  Registration->register: reg_points=torch.Size([527, 6]), translation=tensor([ 0.0920, -0.0631, -0.2326], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([15050, 6]) -> sampled_points=torch.Size([75250, 6]) time= 0.98 ms
  LatentFeature->update: samples=75250, new_points=1771 (closreSur>VoxDwn>Radius>Distance), all_points=2494583
  TrainingPool->update:  All points now is 50075250 > 50000000 frame buffer: discard 75250 points
  TrainingPool->update: Nvs=75141 ->  close_surface_sample_idx=44807, all_points=50000000, increasement: 49924859
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([44807])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.771267, mean_loss=0.771231, diff=0.000036, thres=0.000100
FrameId=500:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 14475, --cropped--> 14474
  Registration->register: reg_points=torch.Size([498, 6]), translation=tensor([ 0.1063, -0.0770, -0.2541], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([14474, 6]) -> sampled_points=torch.Size([72370, 6]) time= 0.74 ms
  LatentFeature->update: samples=72370, new_points=1730 (closreSur>VoxDwn>Radius>Distance), all_points=2496313
  TrainingPool->update:  All points now is 50072370 > 50000000 frame buffer: discard 72370 points
  TrainingPool->update: Nvs=72276 ->  close_surface_sample_idx=43031, all_points=50000000, increasement: 49927724
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([43031])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.770910, mean_loss=0.770974, diff=-0.000064, thres=0.000100
FrameId=501:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 14041, --cropped--> 14040
  Registration->register: reg_points=torch.Size([483, 6]), translation=tensor([ 0.1016, -0.0944, -0.2648], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([14040, 6]) -> sampled_points=torch.Size([70200, 6]) time= 0.92 ms
  LatentFeature->update: samples=70200, new_points=1681 (closreSur>VoxDwn>Radius>Distance), all_points=2497994
  TrainingPool->update:  All points now is 50070200 > 50000000 frame buffer: discard 70200 points
  TrainingPool->update: Nvs=70111 ->  close_surface_sample_idx=41773, all_points=50000000, increasement: 49929889
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([41773])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.770147, mean_loss=0.770177, diff=-0.000031, thres=0.000100
FrameId=502:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 13482, --cropped--> 13481
  Registration->register: reg_points=torch.Size([478, 6]), translation=tensor([ 0.1147, -0.1572, -0.2477], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([13481, 6]) -> sampled_points=torch.Size([67405, 6]) time= 1.04 ms
  LatentFeature->update: samples=67405, new_points=1601 (closreSur>VoxDwn>Radius>Distance), all_points=2499595
  TrainingPool->update:  All points now is 50067405 > 50000000 frame buffer: discard 67405 points
  TrainingPool->update: Nvs=67316 ->  close_surface_sample_idx=40100, all_points=50000000, increasement: 49932684
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([40100])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.770015, mean_loss=0.769975, diff=0.000040, thres=0.000100
FrameId=503:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 13015, --cropped--> 13014
  Registration->register: reg_points=torch.Size([467, 6]), translation=tensor([ 0.1492, -0.1754, -0.2638], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([13014, 6]) -> sampled_points=torch.Size([65070, 6]) time= 1.06 ms
  LatentFeature->update: samples=65070, new_points=1556 (closreSur>VoxDwn>Radius>Distance), all_points=2501151
  TrainingPool->update:  All points now is 50065070 > 50000000 frame buffer: discard 65070 points
  TrainingPool->update: Nvs=64984 ->  close_surface_sample_idx=38759, all_points=50000000, increasement: 49935016
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([38759])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.768740, mean_loss=0.768830, diff=-0.000090, thres=0.000100
FrameId=504:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 12610, --cropped--> 12604
  Registration->register: reg_points=torch.Size([448, 6]), translation=tensor([ 0.1441, -0.1773, -0.2719], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([12604, 6]) -> sampled_points=torch.Size([63020, 6]) time= 0.84 ms
  LatentFeature->update: samples=63020, new_points=1532 (closreSur>VoxDwn>Radius>Distance), all_points=2502683
  TrainingPool->update:  All points now is 50063020 > 50000000 frame buffer: discard 63020 points
  TrainingPool->update: Nvs=62947 ->  close_surface_sample_idx=37475, all_points=50000000, increasement: 49937053
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([37475])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.770029, mean_loss=0.770001, diff=0.000029, thres=0.000100
FrameId=505:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 12262, --cropped--> 12237
  Registration->register: reg_points=torch.Size([443, 6]), translation=tensor([ 0.1469, -0.1778, -0.2796], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([12237, 6]) -> sampled_points=torch.Size([61185, 6]) time= 0.90 ms
  LatentFeature->update: samples=61185, new_points=1466 (closreSur>VoxDwn>Radius>Distance), all_points=2504149
  TrainingPool->update:  All points now is 50061185 > 50000000 frame buffer: discard 61185 points
  TrainingPool->update: Nvs=61113 ->  close_surface_sample_idx=36402, all_points=50000000, increasement: 49938887
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([36402])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.769929, mean_loss=0.769926, diff=0.000003, thres=0.000100
FrameId=506:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 11978, --cropped--> 11927
  Registration->register: reg_points=torch.Size([446, 6]), translation=tensor([ 0.1320, -0.2022, -0.2604], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([11927, 6]) -> sampled_points=torch.Size([59635, 6]) time= 0.94 ms
  LatentFeature->update: samples=59635, new_points=1453 (closreSur>VoxDwn>Radius>Distance), all_points=2505602
  TrainingPool->update:  All points now is 50059635 > 50000000 frame buffer: discard 59635 points
  TrainingPool->update: Nvs=59571 ->  close_surface_sample_idx=35485, all_points=50000000, increasement: 49940429
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([35485])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.770781, mean_loss=0.770768, diff=0.000013, thres=0.000100
FrameId=507:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 11569, --cropped--> 11489
  Registration->register: reg_points=torch.Size([426, 6]), translation=tensor([ 0.1094, -0.2177, -0.2611], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([11489, 6]) -> sampled_points=torch.Size([57445, 6]) time= 0.86 ms
  LatentFeature->update: samples=57445, new_points=1400 (closreSur>VoxDwn>Radius>Distance), all_points=2507002
  TrainingPool->update:  All points now is 50057445 > 50000000 frame buffer: discard 57445 points
  TrainingPool->update: Nvs=57381 ->  close_surface_sample_idx=34203, all_points=50000000, increasement: 49942619
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([34203])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.771571, mean_loss=0.771501, diff=0.000070, thres=0.000100
FrameId=508:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 11089, --cropped--> 10971
  Registration->register: reg_points=torch.Size([408, 6]), translation=tensor([ 0.0826, -0.2938, -0.2313], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([10971, 6]) -> sampled_points=torch.Size([54855, 6]) time= 0.86 ms
  LatentFeature->update: samples=54855, new_points=1346 (closreSur>VoxDwn>Radius>Distance), all_points=2508348
  TrainingPool->update:  All points now is 50054855 > 50000000 frame buffer: discard 54855 points
  TrainingPool->update: Nvs=54788 ->  close_surface_sample_idx=32706, all_points=50000000, increasement: 49945212
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([32706])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.769134, mean_loss=0.769035, diff=0.000099, thres=0.000100
FrameId=509:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 10877, --cropped--> 10694
  Registration->register: reg_points=torch.Size([400, 6]), translation=tensor([ 0.0294, -0.2737, -0.2061], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([10694, 6]) -> sampled_points=torch.Size([53470, 6]) time= 0.40 ms
  LatentFeature->update: samples=53470, new_points=1328 (closreSur>VoxDwn>Radius>Distance), all_points=2509676
  TrainingPool->update:  All points now is 50053470 > 50000000 frame buffer: discard 53470 points
  TrainingPool->update: Nvs=53420 ->  close_surface_sample_idx=31831, all_points=50000000, increasement: 49946580
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([31831])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.769481, mean_loss=0.769553, diff=-0.000072, thres=0.000100
FrameId=510:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 10507, --cropped--> 10263
  Registration->register: reg_points=torch.Size([370, 6]), translation=tensor([ 0.0897, -0.3199, -0.2169], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([10263, 6]) -> sampled_points=torch.Size([51315, 6]) time= 0.40 ms
  LatentFeature->update: samples=51315, new_points=1233 (closreSur>VoxDwn>Radius>Distance), all_points=2510909
  TrainingPool->update:  All points now is 50051315 > 50000000 frame buffer: discard 51315 points
  TrainingPool->update: Nvs=51266 ->  close_surface_sample_idx=30440, all_points=50000000, increasement: 49948734
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([30440])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.768579, mean_loss=0.768579, diff=0.000000, thres=0.000100
FrameId=511:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 10064, --cropped--> 9749
  Registration->register: reg_points=torch.Size([355, 6]), translation=tensor([ 0.0475, -0.3012, -0.2211], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([9749, 6]) -> sampled_points=torch.Size([48745, 6]) time= 0.45 ms
  LatentFeature->update: samples=48745, new_points=1175 (closreSur>VoxDwn>Radius>Distance), all_points=2512084
  TrainingPool->update:  All points now is 50048745 > 50000000 frame buffer: discard 48745 points
  TrainingPool->update: Nvs=48683 ->  close_surface_sample_idx=28982, all_points=50000000, increasement: 49951317
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([28982])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.769817, mean_loss=0.769914, diff=-0.000096, thres=0.000100
FrameId=512:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 9623, --cropped--> 9342
  Registration->register: reg_points=torch.Size([337, 6]), translation=tensor([ 0.0654, -0.2767, -0.2479], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([9342, 6]) -> sampled_points=torch.Size([46710, 6]) time= 0.37 ms
  LatentFeature->update: samples=46710, new_points=1137 (closreSur>VoxDwn>Radius>Distance), all_points=2513221
  TrainingPool->update:  All points now is 50046710 > 50000000 frame buffer: discard 46710 points
  TrainingPool->update: Nvs=46668 ->  close_surface_sample_idx=27763, all_points=50000000, increasement: 49953332
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([27763])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.770044, mean_loss=0.770034, diff=0.000009, thres=0.000100
FrameId=513:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 9407, --cropped--> 8966
  Registration->register: reg_points=torch.Size([321, 6]), translation=tensor([ 0.0793, -0.2888, -0.2353], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([8966, 6]) -> sampled_points=torch.Size([44830, 6]) time= 0.38 ms
  LatentFeature->update: samples=44830, new_points=1082 (closreSur>VoxDwn>Radius>Distance), all_points=2514303
  TrainingPool->update:  All points now is 50044830 > 50000000 frame buffer: discard 44830 points
  TrainingPool->update: Nvs=44788 ->  close_surface_sample_idx=26625, all_points=50000000, increasement: 49955212
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([26625])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.769664, mean_loss=0.769652, diff=0.000012, thres=0.000100
FrameId=514:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 9066, --cropped--> 8577
  Registration->register: reg_points=torch.Size([317, 6]), translation=tensor([ 0.0603, -0.2596, -0.2547], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([8577, 6]) -> sampled_points=torch.Size([42885, 6]) time= 0.38 ms
  LatentFeature->update: samples=42885, new_points=1027 (closreSur>VoxDwn>Radius>Distance), all_points=2515330
  TrainingPool->update:  All points now is 50042885 > 50000000 frame buffer: discard 42885 points
  TrainingPool->update: Nvs=42851 ->  close_surface_sample_idx=25364, all_points=50000000, increasement: 49957149
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([25364])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.770134, mean_loss=0.770080, diff=0.000054, thres=0.000100
FrameId=515:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 8831, --cropped--> 8237
  Registration->register: reg_points=torch.Size([307, 6]), translation=tensor([ 0.0772, -0.2803, -0.2606], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([8237, 6]) -> sampled_points=torch.Size([41185, 6]) time= 0.40 ms
  LatentFeature->update: samples=41185, new_points=1019 (closreSur>VoxDwn>Radius>Distance), all_points=2516349
  TrainingPool->update:  All points now is 50041185 > 50000000 frame buffer: discard 41185 points
  TrainingPool->update: Nvs=41153 ->  close_surface_sample_idx=24509, all_points=50000000, increasement: 49958847
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([24509])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.769549, mean_loss=0.769516, diff=0.000032, thres=0.000100
FrameId=516:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 8559, --cropped--> 7918
  Registration->register: reg_points=torch.Size([292, 6]), translation=tensor([ 0.0545, -0.2707, -0.2540], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([7918, 6]) -> sampled_points=torch.Size([39590, 6]) time= 0.38 ms
  LatentFeature->update: samples=39590, new_points=936 (closreSur>VoxDwn>Radius>Distance), all_points=2517285
  TrainingPool->update:  All points now is 50039590 > 50000000 frame buffer: discard 39590 points
  TrainingPool->update: Nvs=39562 ->  close_surface_sample_idx=23443, all_points=50000000, increasement: 49960438
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([23443])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.768604, mean_loss=0.768669, diff=-0.000065, thres=0.000100
FrameId=517:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 8154, --cropped--> 7626
  Registration->register: reg_points=torch.Size([274, 6]), translation=tensor([ 0.0612, -0.2918, -0.2445], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([7626, 6]) -> sampled_points=torch.Size([38130, 6]) time= 0.46 ms
  LatentFeature->update: samples=38130, new_points=909 (closreSur>VoxDwn>Radius>Distance), all_points=2518194
  TrainingPool->update:  All points now is 50038130 > 50000000 frame buffer: discard 38130 points
  TrainingPool->update: Nvs=38106 ->  close_surface_sample_idx=22602, all_points=50000000, increasement: 49961894
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([22602])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.768210, mean_loss=0.768203, diff=0.000008, thres=0.000100
FrameId=518:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 7837, --cropped--> 7269
  Registration->register: reg_points=torch.Size([249, 6]), translation=tensor([ 0.0606, -0.2964, -0.2494], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([7269, 6]) -> sampled_points=torch.Size([36345, 6]) time= 0.38 ms
  LatentFeature->update: samples=36345, new_points=878 (closreSur>VoxDwn>Radius>Distance), all_points=2519072
  TrainingPool->update:  All points now is 50036345 > 50000000 frame buffer: discard 36345 points
  TrainingPool->update: Nvs=36322 ->  close_surface_sample_idx=21582, all_points=50000000, increasement: 49963678
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([21582])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.770251, mean_loss=0.770264, diff=-0.000013, thres=0.000100
FrameId=519:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 7404, --cropped--> 6804
  Registration->register: reg_points=torch.Size([238, 6]), translation=tensor([ 0.0542, -0.3125, -0.2364], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([6804, 6]) -> sampled_points=torch.Size([34020, 6]) time= 0.38 ms
  LatentFeature->update: samples=34020, new_points=832 (closreSur>VoxDwn>Radius>Distance), all_points=2519904
  TrainingPool->update:  All points now is 50034020 > 50000000 frame buffer: discard 34020 points
  TrainingPool->update: Nvs=34008 ->  close_surface_sample_idx=20206, all_points=50000000, increasement: 49965992
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([20206])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.768542, mean_loss=0.768622, diff=-0.000080, thres=0.000100
FrameId=520:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 7255, --cropped--> 6598
  Registration->register: reg_points=torch.Size([225, 6]), translation=tensor([ 0.0672, -0.3185, -0.2466], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([6598, 6]) -> sampled_points=torch.Size([32990, 6]) time= 0.38 ms
  LatentFeature->update: samples=32990, new_points=801 (closreSur>VoxDwn>Radius>Distance), all_points=2520705
  TrainingPool->update:  All points now is 50032990 > 50000000 frame buffer: discard 32990 points
  TrainingPool->update: Nvs=32964 ->  close_surface_sample_idx=19615, all_points=50000000, increasement: 49967036
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([19615])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.769453, mean_loss=0.769490, diff=-0.000037, thres=0.000100
FrameId=521:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 7033, --cropped--> 6386
  Registration->register: reg_points=torch.Size([227, 6]), translation=tensor([ 0.0259, -0.3794, -0.1859], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([6386, 6]) -> sampled_points=torch.Size([31930, 6]) time= 0.39 ms
  LatentFeature->update: samples=31930, new_points=777 (closreSur>VoxDwn>Radius>Distance), all_points=2521482
  TrainingPool->update:  All points now is 50031930 > 50000000 frame buffer: discard 31930 points
  TrainingPool->update: Nvs=31916 ->  close_surface_sample_idx=18993, all_points=50000000, increasement: 49968084
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([18993])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.769087, mean_loss=0.769036, diff=0.000051, thres=0.000100
FrameId=522:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 6873, --cropped--> 6181
  Registration->register: reg_points=torch.Size([218, 6]), translation=tensor([ 0.0368, -0.3882, -0.1929], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([6181, 6]) -> sampled_points=torch.Size([30905, 6]) time= 0.37 ms
  LatentFeature->update: samples=30905, new_points=752 (closreSur>VoxDwn>Radius>Distance), all_points=2522234
  TrainingPool->update:  All points now is 50030905 > 50000000 frame buffer: discard 30905 points
  TrainingPool->update: Nvs=30887 ->  close_surface_sample_idx=18367, all_points=50000000, increasement: 49969113
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([18367])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.769514, mean_loss=0.769579, diff=-0.000065, thres=0.000100
FrameId=523:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 6723, --cropped--> 6024
  Registration->register: reg_points=torch.Size([218, 6]), translation=tensor([ 0.0237, -0.4034, -0.1709], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([6024, 6]) -> sampled_points=torch.Size([30120, 6]) time= 0.38 ms
  LatentFeature->update: samples=30120, new_points=717 (closreSur>VoxDwn>Radius>Distance), all_points=2522951
  TrainingPool->update:  All points now is 50030120 > 50000000 frame buffer: discard 30120 points
  TrainingPool->update: Nvs=30098 ->  close_surface_sample_idx=17834, all_points=50000000, increasement: 49969902
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([17834])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.771164, mean_loss=0.771259, diff=-0.000094, thres=0.000100
FrameId=524:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 6644, --cropped--> 5936
  Registration->register: reg_points=torch.Size([206, 6]), translation=tensor([ 0.0149, -0.3742, -0.1949], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([5936, 6]) -> sampled_points=torch.Size([29680, 6]) time= 0.41 ms
  LatentFeature->update: samples=29680, new_points=718 (closreSur>VoxDwn>Radius>Distance), all_points=2523669
  TrainingPool->update:  All points now is 50029680 > 50000000 frame buffer: discard 29680 points
  TrainingPool->update: Nvs=29663 ->  close_surface_sample_idx=17600, all_points=50000000, increasement: 49970337
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([17600])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.768832, mean_loss=0.768762, diff=0.000069, thres=0.000100
FrameId=525:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 6518, --cropped--> 5830
  Registration->register: reg_points=torch.Size([207, 6]), translation=tensor([ 0.0065, -0.4380, -0.1520], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([5830, 6]) -> sampled_points=torch.Size([29150, 6]) time= 0.40 ms
  LatentFeature->update: samples=29150, new_points=702 (closreSur>VoxDwn>Radius>Distance), all_points=2524371
  TrainingPool->update:  All points now is 50029150 > 50000000 frame buffer: discard 29150 points
  TrainingPool->update: Nvs=29125 ->  close_surface_sample_idx=17255, all_points=50000000, increasement: 49970875
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([17255])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.770180, mean_loss=0.770150, diff=0.000030, thres=0.000100
FrameId=526:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 6330, --cropped--> 5647
  Registration->register: reg_points=torch.Size([210, 6]), translation=tensor([ 0.0500, -0.4168, -0.1693], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([5647, 6]) -> sampled_points=torch.Size([28235, 6]) time= 0.38 ms
  LatentFeature->update: samples=28235, new_points=707 (closreSur>VoxDwn>Radius>Distance), all_points=2525078
  TrainingPool->update:  All points now is 50028235 > 50000000 frame buffer: discard 28235 points
  TrainingPool->update: Nvs=28217 ->  close_surface_sample_idx=16765, all_points=50000000, increasement: 49971783
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([16765])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.769297, mean_loss=0.769379, diff=-0.000082, thres=0.000100
FrameId=527:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 6520, --cropped--> 5891
  Registration->register: reg_points=torch.Size([210, 6]), translation=tensor([ 0.0467, -0.4294, -0.1575], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([5891, 6]) -> sampled_points=torch.Size([29455, 6]) time= 0.37 ms
  LatentFeature->update: samples=29455, new_points=716 (closreSur>VoxDwn>Radius>Distance), all_points=2525794
  TrainingPool->update:  All points now is 50029455 > 50000000 frame buffer: discard 29455 points
  TrainingPool->update: Nvs=29441 ->  close_surface_sample_idx=17544, all_points=50000000, increasement: 49970559
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([17544])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.768120, mean_loss=0.768124, diff=-0.000004, thres=0.000100
FrameId=528:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 6528, --cropped--> 5926
  Registration->register: reg_points=torch.Size([224, 6]), translation=tensor([ 0.0342, -0.4255, -0.1446], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([5926, 6]) -> sampled_points=torch.Size([29630, 6]) time= 0.68 ms
  LatentFeature->update: samples=29630, new_points=734 (closreSur>VoxDwn>Radius>Distance), all_points=2526528
  TrainingPool->update:  All points now is 50029630 > 50000000 frame buffer: discard 29630 points
  TrainingPool->update: Nvs=29612 ->  close_surface_sample_idx=17686, all_points=50000000, increasement: 49970388
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([17686])
  TrainingPool->train: break at iter=54, cur_mean_loss=0.769567, mean_loss=0.769501, diff=0.000066, thres=0.000100
FrameId=529:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 6651, --cropped--> 6084
  Registration->register: reg_points=torch.Size([225, 6]), translation=tensor([ 0.0217, -0.4057, -0.1347], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([6084, 6]) -> sampled_points=torch.Size([30420, 6]) time= 0.40 ms
  LatentFeature->update: samples=30420, new_points=745 (closreSur>VoxDwn>Radius>Distance), all_points=2527273
  TrainingPool->update:  All points now is 50030420 > 50000000 frame buffer: discard 30420 points
  TrainingPool->update: Nvs=30399 ->  close_surface_sample_idx=18091, all_points=50000000, increasement: 49969601
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([18091])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.768910, mean_loss=0.768863, diff=0.000047, thres=0.000100
FrameId=530:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 6722, --cropped--> 6226
  Registration->register: reg_points=torch.Size([239, 6]), translation=tensor([ 0.0273, -0.4074, -0.1356], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([6226, 6]) -> sampled_points=torch.Size([31130, 6]) time= 0.38 ms
  LatentFeature->update: samples=31130, new_points=770 (closreSur>VoxDwn>Radius>Distance), all_points=2528043
  TrainingPool->update:  All points now is 50031130 > 50000000 frame buffer: discard 31130 points
  TrainingPool->update: Nvs=31106 ->  close_surface_sample_idx=18557, all_points=50000000, increasement: 49968894
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([18557])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.768940, mean_loss=0.768962, diff=-0.000022, thres=0.000100
FrameId=531:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 6889, --cropped--> 6428
  Registration->register: reg_points=torch.Size([240, 6]), translation=tensor([ 0.0110, -0.3265, -0.1621], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([6428, 6]) -> sampled_points=torch.Size([32140, 6]) time= 0.40 ms
  LatentFeature->update: samples=32140, new_points=788 (closreSur>VoxDwn>Radius>Distance), all_points=2528831
  TrainingPool->update:  All points now is 50032140 > 50000000 frame buffer: discard 32140 points
  TrainingPool->update: Nvs=32111 ->  close_surface_sample_idx=19097, all_points=50000000, increasement: 49967889
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([19097])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.770352, mean_loss=0.770335, diff=0.000017, thres=0.000100
FrameId=532:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 7070, --cropped--> 6675
  Registration->register: reg_points=torch.Size([238, 6]), translation=tensor([-0.0101, -0.3425, -0.1360], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([6675, 6]) -> sampled_points=torch.Size([33375, 6]) time= 0.37 ms
  LatentFeature->update: samples=33375, new_points=816 (closreSur>VoxDwn>Radius>Distance), all_points=2529647
  TrainingPool->update:  All points now is 50033375 > 50000000 frame buffer: discard 33375 points
  TrainingPool->update: Nvs=33352 ->  close_surface_sample_idx=19851, all_points=50000000, increasement: 49966648
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([19851])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.768711, mean_loss=0.768743, diff=-0.000032, thres=0.000100
FrameId=533:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 7224, --cropped--> 6853
  Registration->register: reg_points=torch.Size([261, 6]), translation=tensor([ 0.0204, -0.3309, -0.1485], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([6853, 6]) -> sampled_points=torch.Size([34265, 6]) time= 0.38 ms
  LatentFeature->update: samples=34265, new_points=839 (closreSur>VoxDwn>Radius>Distance), all_points=2530486
  TrainingPool->update:  All points now is 50034265 > 50000000 frame buffer: discard 34265 points
  TrainingPool->update: Nvs=34241 ->  close_surface_sample_idx=20362, all_points=50000000, increasement: 49965759
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([20362])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.769816, mean_loss=0.769786, diff=0.000030, thres=0.000100
FrameId=534:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 7304, --cropped--> 6935
  Registration->register: reg_points=torch.Size([257, 6]), translation=tensor([-0.0064, -0.3536, -0.1299], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([6935, 6]) -> sampled_points=torch.Size([34675, 6]) time= 0.41 ms
  LatentFeature->update: samples=34675, new_points=850 (closreSur>VoxDwn>Radius>Distance), all_points=2531336
  TrainingPool->update:  All points now is 50034675 > 50000000 frame buffer: discard 34675 points
  TrainingPool->update: Nvs=34655 ->  close_surface_sample_idx=20652, all_points=50000000, increasement: 49965345
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([20652])
  TrainingPool->train: break at iter=56, cur_mean_loss=0.769359, mean_loss=0.769357, diff=0.000002, thres=0.000100
FrameId=535:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 7332, --cropped--> 6970
  Registration->register: reg_points=torch.Size([261, 6]), translation=tensor([-0.0021, -0.3977, -0.0972], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([6970, 6]) -> sampled_points=torch.Size([34850, 6]) time= 0.38 ms
  LatentFeature->update: samples=34850, new_points=865 (closreSur>VoxDwn>Radius>Distance), all_points=2532201
  TrainingPool->update:  All points now is 50034850 > 50000000 frame buffer: discard 34850 points
  TrainingPool->update: Nvs=34832 ->  close_surface_sample_idx=20738, all_points=50000000, increasement: 49965168
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([20738])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.768880, mean_loss=0.768821, diff=0.000058, thres=0.000100
FrameId=536:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 7333, --cropped--> 6972
  Registration->register: reg_points=torch.Size([261, 6]), translation=tensor([-0.0061, -0.3927, -0.0917], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([6972, 6]) -> sampled_points=torch.Size([34860, 6]) time= 0.39 ms
  LatentFeature->update: samples=34860, new_points=861 (closreSur>VoxDwn>Radius>Distance), all_points=2533062
  TrainingPool->update:  All points now is 50034860 > 50000000 frame buffer: discard 34860 points
  TrainingPool->update: Nvs=34826 ->  close_surface_sample_idx=20736, all_points=50000000, increasement: 49965174
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([20736])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.768947, mean_loss=0.769002, diff=-0.000055, thres=0.000100
FrameId=537:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 7372, --cropped--> 7065
  Registration->register: reg_points=torch.Size([268, 6]), translation=tensor([-0.0013, -0.4260, -0.0923], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([7065, 6]) -> sampled_points=torch.Size([35325, 6]) time= 0.38 ms
  LatentFeature->update: samples=35325, new_points=864 (closreSur>VoxDwn>Radius>Distance), all_points=2533926
  TrainingPool->update:  All points now is 50035325 > 50000000 frame buffer: discard 35325 points
  TrainingPool->update: Nvs=35305 ->  close_surface_sample_idx=20952, all_points=50000000, increasement: 49964695
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([20952])
  TrainingPool->train: break at iter=54, cur_mean_loss=0.769057, mean_loss=0.769083, diff=-0.000025, thres=0.000100
FrameId=538:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 7442, --cropped--> 7167
  Registration->register: reg_points=torch.Size([274, 6]), translation=tensor([-0.0176, -0.3961, -0.1153], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([7167, 6]) -> sampled_points=torch.Size([35835, 6]) time= 0.41 ms
  LatentFeature->update: samples=35835, new_points=884 (closreSur>VoxDwn>Radius>Distance), all_points=2534810
  TrainingPool->update:  All points now is 50035835 > 50000000 frame buffer: discard 35835 points
  TrainingPool->update: Nvs=35810 ->  close_surface_sample_idx=21302, all_points=50000000, increasement: 49964190
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([21302])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.768667, mean_loss=0.768606, diff=0.000060, thres=0.000100
FrameId=539:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 7512, --cropped--> 7260
  Registration->register: reg_points=torch.Size([271, 6]), translation=tensor([ 0.0249, -0.3654, -0.1506], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([7260, 6]) -> sampled_points=torch.Size([36300, 6]) time= 0.66 ms
  LatentFeature->update: samples=36300, new_points=884 (closreSur>VoxDwn>Radius>Distance), all_points=2535694
  TrainingPool->update:  All points now is 50036300 > 50000000 frame buffer: discard 36300 points
  TrainingPool->update: Nvs=36281 ->  close_surface_sample_idx=21561, all_points=50000000, increasement: 49963719
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([21561])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.769338, mean_loss=0.769347, diff=-0.000009, thres=0.000100
FrameId=540:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 7488, --cropped--> 7268
  Registration->register: reg_points=torch.Size([278, 6]), translation=tensor([-0.0337, -0.5009, -0.0349], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([7268, 6]) -> sampled_points=torch.Size([36340, 6]) time= 0.38 ms
  LatentFeature->update: samples=36340, new_points=877 (closreSur>VoxDwn>Radius>Distance), all_points=2536571
  TrainingPool->update:  All points now is 50036340 > 50000000 frame buffer: discard 36340 points
  TrainingPool->update: Nvs=36317 ->  close_surface_sample_idx=21555, all_points=50000000, increasement: 49963683
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([21555])
  TrainingPool->train: break at iter=57, cur_mean_loss=0.768682, mean_loss=0.768715, diff=-0.000034, thres=0.000100
FrameId=541:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 7803, --cropped--> 7619
  Registration->register: reg_points=torch.Size([298, 6]), translation=tensor([-0.0237, -0.4819, -0.0342], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([7619, 6]) -> sampled_points=torch.Size([38095, 6]) time= 0.38 ms
  LatentFeature->update: samples=38095, new_points=932 (closreSur>VoxDwn>Radius>Distance), all_points=2537503
  TrainingPool->update:  All points now is 50038095 > 50000000 frame buffer: discard 38095 points
  TrainingPool->update: Nvs=38068 ->  close_surface_sample_idx=22689, all_points=50000000, increasement: 49961932
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([22689])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.768301, mean_loss=0.768321, diff=-0.000020, thres=0.000100
FrameId=542:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 7727, --cropped--> 7568
  Registration->register: reg_points=torch.Size([300, 6]), translation=tensor([-0.0298, -0.5142, -0.0367], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([7568, 6]) -> sampled_points=torch.Size([37840, 6]) time= 0.37 ms
  LatentFeature->update: samples=37840, new_points=908 (closreSur>VoxDwn>Radius>Distance), all_points=2538411
  TrainingPool->update:  All points now is 50037840 > 50000000 frame buffer: discard 37840 points
  TrainingPool->update: Nvs=37810 ->  close_surface_sample_idx=22478, all_points=50000000, increasement: 49962190
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([22478])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.770212, mean_loss=0.770187, diff=0.000026, thres=0.000100
FrameId=543:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 7885, --cropped--> 7722
  Registration->register: reg_points=torch.Size([307, 6]), translation=tensor([-0.0238, -0.5215, -0.0308], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([7722, 6]) -> sampled_points=torch.Size([38610, 6]) time= 0.40 ms
  LatentFeature->update: samples=38610, new_points=972 (closreSur>VoxDwn>Radius>Distance), all_points=2539383
  TrainingPool->update:  All points now is 50038610 > 50000000 frame buffer: discard 38610 points
  TrainingPool->update: Nvs=38596 ->  close_surface_sample_idx=22888, all_points=50000000, increasement: 49961404
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([22888])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.767675, mean_loss=0.767659, diff=0.000016, thres=0.000100
FrameId=544:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 8048, --cropped--> 7913
  Registration->register: reg_points=torch.Size([317, 6]), translation=tensor([-0.0526, -0.4962, -0.0135], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([7913, 6]) -> sampled_points=torch.Size([39565, 6]) time= 0.41 ms
  LatentFeature->update: samples=39565, new_points=997 (closreSur>VoxDwn>Radius>Distance), all_points=2540380
  TrainingPool->update:  All points now is 50039565 > 50000000 frame buffer: discard 39565 points
  TrainingPool->update: Nvs=39533 ->  close_surface_sample_idx=23516, all_points=50000000, increasement: 49960467
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([23516])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.768646, mean_loss=0.768553, diff=0.000092, thres=0.000100
FrameId=545:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 8121, --cropped--> 8018
  Registration->register: reg_points=torch.Size([326, 6]), translation=tensor([-0.0368, -0.4802, -0.0171], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([8018, 6]) -> sampled_points=torch.Size([40090, 6]) time= 0.43 ms
  LatentFeature->update: samples=40090, new_points=990 (closreSur>VoxDwn>Radius>Distance), all_points=2541370
  TrainingPool->update:  All points now is 50040090 > 50000000 frame buffer: discard 40090 points
  TrainingPool->update: Nvs=40057 ->  close_surface_sample_idx=23798, all_points=50000000, increasement: 49959943
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([23798])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.768405, mean_loss=0.768436, diff=-0.000031, thres=0.000100
FrameId=546:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 8161, --cropped--> 8068
  Registration->register: reg_points=torch.Size([327, 6]), translation=tensor([-0.0366, -0.4643, -0.0242], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([8068, 6]) -> sampled_points=torch.Size([40340, 6]) time= 0.42 ms
  LatentFeature->update: samples=40340, new_points=1010 (closreSur>VoxDwn>Radius>Distance), all_points=2542380
  TrainingPool->update:  All points now is 50040340 > 50000000 frame buffer: discard 40340 points
  TrainingPool->update: Nvs=40322 ->  close_surface_sample_idx=23927, all_points=50000000, increasement: 49959678
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([23927])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.768608, mean_loss=0.768692, diff=-0.000084, thres=0.000100
FrameId=547:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 8528, --cropped--> 8262
  Registration->register: reg_points=torch.Size([322, 6]), translation=tensor([-0.0319, -0.4729, -0.0228], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([8262, 6]) -> sampled_points=torch.Size([41310, 6]) time= 0.45 ms
  LatentFeature->update: samples=41310, new_points=1055 (closreSur>VoxDwn>Radius>Distance), all_points=2543435
  TrainingPool->update:  All points now is 50041310 > 50000000 frame buffer: discard 41310 points
  TrainingPool->update: Nvs=41284 ->  close_surface_sample_idx=24541, all_points=50000000, increasement: 49958716
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([24541])
  TrainingPool->train: break at iter=54, cur_mean_loss=0.768275, mean_loss=0.768334, diff=-0.000058, thres=0.000100
FrameId=548:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 8728, --cropped--> 8480
  Registration->register: reg_points=torch.Size([334, 6]), translation=tensor([-0.0352, -0.5022, -0.0182], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([8480, 6]) -> sampled_points=torch.Size([42400, 6]) time= 0.41 ms
  LatentFeature->update: samples=42400, new_points=1076 (closreSur>VoxDwn>Radius>Distance), all_points=2544511
  TrainingPool->update:  All points now is 50042400 > 50000000 frame buffer: discard 42400 points
  TrainingPool->update: Nvs=42358 ->  close_surface_sample_idx=25149, all_points=50000000, increasement: 49957642
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([25149])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.768726, mean_loss=0.768813, diff=-0.000086, thres=0.000100
FrameId=549:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 8808, --cropped--> 8594
  Registration->register: reg_points=torch.Size([337, 6]), translation=tensor([-0.0441, -0.5134, -0.0043], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([8594, 6]) -> sampled_points=torch.Size([42970, 6]) time= 0.43 ms
  LatentFeature->update: samples=42970, new_points=1093 (closreSur>VoxDwn>Radius>Distance), all_points=2545604
  TrainingPool->update:  All points now is 50042970 > 50000000 frame buffer: discard 42970 points
  TrainingPool->update: Nvs=42940 ->  close_surface_sample_idx=25509, all_points=50000000, increasement: 49957060
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([25509])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.768803, mean_loss=0.768759, diff=0.000044, thres=0.000100
FrameId=550:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 8836, --cropped--> 8626
  Registration->register: reg_points=torch.Size([336, 6]), translation=tensor([-0.0421, -0.5172, -0.0045], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([8626, 6]) -> sampled_points=torch.Size([43130, 6]) time= 0.39 ms
  LatentFeature->update: samples=43130, new_points=1096 (closreSur>VoxDwn>Radius>Distance), all_points=2546700
  TrainingPool->update:  All points now is 50043130 > 50000000 frame buffer: discard 43130 points
  TrainingPool->update: Nvs=43088 ->  close_surface_sample_idx=25571, all_points=50000000, increasement: 49956912
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([25571])
  TrainingPool->train: break at iter=54, cur_mean_loss=0.767677, mean_loss=0.767721, diff=-0.000044, thres=0.000100
FrameId=551:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 8936, --cropped--> 8725
  Registration->register: reg_points=torch.Size([342, 6]), translation=tensor([-0.0448, -0.5221,  0.0031], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([8725, 6]) -> sampled_points=torch.Size([43625, 6]) time= 0.39 ms
  LatentFeature->update: samples=43625, new_points=1098 (closreSur>VoxDwn>Radius>Distance), all_points=2547798
  TrainingPool->update:  All points now is 50043625 > 50000000 frame buffer: discard 43625 points
  TrainingPool->update: Nvs=43586 ->  close_surface_sample_idx=25902, all_points=50000000, increasement: 49956414
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([25902])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.768917, mean_loss=0.768877, diff=0.000040, thres=0.000100
FrameId=552:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 9038, --cropped--> 8824
  Registration->register: reg_points=torch.Size([353, 6]), translation=tensor([-0.0460, -0.5212,  0.0077], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([8824, 6]) -> sampled_points=torch.Size([44120, 6]) time= 0.38 ms
  LatentFeature->update: samples=44120, new_points=1115 (closreSur>VoxDwn>Radius>Distance), all_points=2548913
  TrainingPool->update:  All points now is 50044120 > 50000000 frame buffer: discard 44120 points
  TrainingPool->update: Nvs=44086 ->  close_surface_sample_idx=26172, all_points=50000000, increasement: 49955914
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([26172])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.768752, mean_loss=0.768797, diff=-0.000046, thres=0.000100
FrameId=553:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 8952, --cropped--> 8732
  Registration->register: reg_points=torch.Size([343, 6]), translation=tensor([-0.0548, -0.5101,  0.0099], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([8732, 6]) -> sampled_points=torch.Size([43660, 6]) time= 0.38 ms
  LatentFeature->update: samples=43660, new_points=1092 (closreSur>VoxDwn>Radius>Distance), all_points=2550005
  TrainingPool->update:  All points now is 50043660 > 50000000 frame buffer: discard 43660 points
  TrainingPool->update: Nvs=43619 ->  close_surface_sample_idx=25939, all_points=50000000, increasement: 49956381
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([25939])
  TrainingPool->train: break at iter=54, cur_mean_loss=0.768434, mean_loss=0.768396, diff=0.000038, thres=0.000100
FrameId=554:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 8826, --cropped--> 8584
  Registration->register: reg_points=torch.Size([344, 6]), translation=tensor([-0.0560, -0.5161,  0.0126], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([8584, 6]) -> sampled_points=torch.Size([42920, 6]) time= 0.38 ms
  LatentFeature->update: samples=42920, new_points=1079 (closreSur>VoxDwn>Radius>Distance), all_points=2551084
  TrainingPool->update:  All points now is 50042920 > 50000000 frame buffer: discard 42920 points
  TrainingPool->update: Nvs=42882 ->  close_surface_sample_idx=25459, all_points=50000000, increasement: 49957118
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([25459])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.767490, mean_loss=0.767576, diff=-0.000086, thres=0.000100
FrameId=555:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 8683, --cropped--> 8431
  Registration->register: reg_points=torch.Size([340, 6]), translation=tensor([-0.0530, -0.5183,  0.0116], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([8431, 6]) -> sampled_points=torch.Size([42155, 6]) time= 0.44 ms
  LatentFeature->update: samples=42155, new_points=1039 (closreSur>VoxDwn>Radius>Distance), all_points=2552123
  TrainingPool->update:  All points now is 50042155 > 50000000 frame buffer: discard 42155 points
  TrainingPool->update: Nvs=42120 ->  close_surface_sample_idx=25079, all_points=50000000, increasement: 49957880
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([25079])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.768627, mean_loss=0.768664, diff=-0.000037, thres=0.000100
FrameId=556:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 8720, --cropped--> 8454
  Registration->register: reg_points=torch.Size([324, 6]), translation=tensor([-0.0092, -0.4876, -0.0117], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([8454, 6]) -> sampled_points=torch.Size([42270, 6]) time= 0.73 ms
  LatentFeature->update: samples=42270, new_points=1041 (closreSur>VoxDwn>Radius>Distance), all_points=2553164
  TrainingPool->update:  All points now is 50042270 > 50000000 frame buffer: discard 42270 points
  TrainingPool->update: Nvs=42244 ->  close_surface_sample_idx=25176, all_points=50000000, increasement: 49957756
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([25176])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.768587, mean_loss=0.768585, diff=0.000003, thres=0.000100
FrameId=557:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 8717, --cropped--> 8426
  Registration->register: reg_points=torch.Size([319, 6]), translation=tensor([-0.0183, -0.4905, -0.0106], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([8426, 6]) -> sampled_points=torch.Size([42130, 6]) time= 0.37 ms
  LatentFeature->update: samples=42130, new_points=1036 (closreSur>VoxDwn>Radius>Distance), all_points=2554200
  TrainingPool->update:  All points now is 50042130 > 50000000 frame buffer: discard 42130 points
  TrainingPool->update: Nvs=42094 ->  close_surface_sample_idx=25095, all_points=50000000, increasement: 49957906
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([25095])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.768019, mean_loss=0.768118, diff=-0.000099, thres=0.000100
FrameId=558:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 8768, --cropped--> 8438
  Registration->register: reg_points=torch.Size([317, 6]), translation=tensor([-0.0250, -0.4752, -0.0320], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([8438, 6]) -> sampled_points=torch.Size([42190, 6]) time= 0.40 ms
  LatentFeature->update: samples=42190, new_points=1046 (closreSur>VoxDwn>Radius>Distance), all_points=2555246
  TrainingPool->update:  All points now is 50042190 > 50000000 frame buffer: discard 42190 points
  TrainingPool->update: Nvs=42160 ->  close_surface_sample_idx=25120, all_points=50000000, increasement: 49957840
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([25120])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.768474, mean_loss=0.768433, diff=0.000041, thres=0.000100
FrameId=559:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 8664, --cropped--> 8318
  Registration->register: reg_points=torch.Size([307, 6]), translation=tensor([ 0.0188, -0.4639, -0.0682], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([8318, 6]) -> sampled_points=torch.Size([41590, 6]) time= 0.37 ms
  LatentFeature->update: samples=41590, new_points=1033 (closreSur>VoxDwn>Radius>Distance), all_points=2556279
  TrainingPool->update:  All points now is 50041590 > 50000000 frame buffer: discard 41590 points
  TrainingPool->update: Nvs=41554 ->  close_surface_sample_idx=24736, all_points=50000000, increasement: 49958446
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([24736])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.767969, mean_loss=0.768039, diff=-0.000070, thres=0.000100
FrameId=560:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 8743, --cropped--> 8376
  Registration->register: reg_points=torch.Size([310, 6]), translation=tensor([ 0.0252, -0.4625, -0.0734], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([8376, 6]) -> sampled_points=torch.Size([41880, 6]) time= 0.37 ms
  LatentFeature->update: samples=41880, new_points=1027 (closreSur>VoxDwn>Radius>Distance), all_points=2557306
  TrainingPool->update:  All points now is 50041880 > 50000000 frame buffer: discard 41880 points
  TrainingPool->update: Nvs=41832 ->  close_surface_sample_idx=24949, all_points=50000000, increasement: 49958168
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([24949])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.767641, mean_loss=0.767730, diff=-0.000089, thres=0.000100
FrameId=561:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 8839, --cropped--> 8435
  Registration->register: reg_points=torch.Size([308, 6]), translation=tensor([-0.0057, -0.4839, -0.0548], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([8435, 6]) -> sampled_points=torch.Size([42175, 6]) time= 0.39 ms
  LatentFeature->update: samples=42175, new_points=1037 (closreSur>VoxDwn>Radius>Distance), all_points=2558343
  TrainingPool->update:  All points now is 50042175 > 50000000 frame buffer: discard 42175 points
  TrainingPool->update: Nvs=42148 ->  close_surface_sample_idx=25086, all_points=50000000, increasement: 49957852
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([25086])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.768600, mean_loss=0.768670, diff=-0.000070, thres=0.000100
FrameId=562:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 8649, --cropped--> 8221
  Registration->register: reg_points=torch.Size([304, 6]), translation=tensor([-0.0174, -0.4978, -0.0442], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([8221, 6]) -> sampled_points=torch.Size([41105, 6]) time= 0.40 ms
  LatentFeature->update: samples=41105, new_points=1001 (closreSur>VoxDwn>Radius>Distance), all_points=2559344
  TrainingPool->update:  All points now is 50041105 > 50000000 frame buffer: discard 41105 points
  TrainingPool->update: Nvs=41067 ->  close_surface_sample_idx=24462, all_points=50000000, increasement: 49958933
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([24462])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.768189, mean_loss=0.768282, diff=-0.000093, thres=0.000100
FrameId=563:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 8509, --cropped--> 8068
  Registration->register: reg_points=torch.Size([296, 6]), translation=tensor([-0.0151, -0.4998, -0.0463], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([8068, 6]) -> sampled_points=torch.Size([40340, 6]) time= 0.47 ms
  LatentFeature->update: samples=40340, new_points=999 (closreSur>VoxDwn>Radius>Distance), all_points=2560343
  TrainingPool->update:  All points now is 50040340 > 50000000 frame buffer: discard 40340 points
  TrainingPool->update: Nvs=40308 ->  close_surface_sample_idx=24031, all_points=50000000, increasement: 49959692
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([24031])
  TrainingPool->train: break at iter=54, cur_mean_loss=0.768435, mean_loss=0.768354, diff=0.000081, thres=0.000100
FrameId=564:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 8538, --cropped--> 8116
  Registration->register: reg_points=torch.Size([298, 6]), translation=tensor([-0.0130, -0.4753, -0.0612], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([8116, 6]) -> sampled_points=torch.Size([40580, 6]) time= 0.38 ms
  LatentFeature->update: samples=40580, new_points=1024 (closreSur>VoxDwn>Radius>Distance), all_points=2561367
  TrainingPool->update:  All points now is 50040580 > 50000000 frame buffer: discard 40580 points
  TrainingPool->update: Nvs=40547 ->  close_surface_sample_idx=24171, all_points=50000000, increasement: 49959453
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([24171])
  TrainingPool->train: break at iter=55, cur_mean_loss=0.769216, mean_loss=0.769240, diff=-0.000024, thres=0.000100
FrameId=565:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 8556, --cropped--> 8126
  Registration->register: reg_points=torch.Size([302, 6]), translation=tensor([-0.0451, -0.4831, -0.0559], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([8126, 6]) -> sampled_points=torch.Size([40630, 6]) time= 0.37 ms
  LatentFeature->update: samples=40630, new_points=1014 (closreSur>VoxDwn>Radius>Distance), all_points=2562381
  TrainingPool->update:  All points now is 50040630 > 50000000 frame buffer: discard 40630 points
  TrainingPool->update: Nvs=40595 ->  close_surface_sample_idx=24231, all_points=50000000, increasement: 49959405
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([24231])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.767493, mean_loss=0.767581, diff=-0.000088, thres=0.000100
FrameId=566:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 8571, --cropped--> 8167
  Registration->register: reg_points=torch.Size([300, 6]), translation=tensor([-0.0635, -0.4904, -0.0477], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([8167, 6]) -> sampled_points=torch.Size([40835, 6]) time= 0.39 ms
  LatentFeature->update: samples=40835, new_points=1023 (closreSur>VoxDwn>Radius>Distance), all_points=2563404
  TrainingPool->update:  All points now is 50040835 > 50000000 frame buffer: discard 40835 points
  TrainingPool->update: Nvs=40802 ->  close_surface_sample_idx=24376, all_points=50000000, increasement: 49959198
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([24376])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.768647, mean_loss=0.768628, diff=0.000019, thres=0.000100
FrameId=567:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 8667, --cropped--> 8275
  Registration->register: reg_points=torch.Size([321, 6]), translation=tensor([-0.1663, -0.4965, -0.0213], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([8275, 6]) -> sampled_points=torch.Size([41375, 6]) time= 0.39 ms
  LatentFeature->update: samples=41375, new_points=1037 (closreSur>VoxDwn>Radius>Distance), all_points=2564441
  TrainingPool->update:  All points now is 50041375 > 50000000 frame buffer: discard 41375 points
  TrainingPool->update: Nvs=41345 ->  close_surface_sample_idx=24677, all_points=50000000, increasement: 49958655
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([24677])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.767341, mean_loss=0.767399, diff=-0.000058, thres=0.000100
FrameId=568:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 8767, --cropped--> 8401
  Registration->register: reg_points=torch.Size([325, 6]), translation=tensor([-0.1478, -0.5033, -0.0304], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([8401, 6]) -> sampled_points=torch.Size([42005, 6]) time= 0.38 ms
  LatentFeature->update: samples=42005, new_points=1054 (closreSur>VoxDwn>Radius>Distance), all_points=2565495
  TrainingPool->update:  All points now is 50042005 > 50000000 frame buffer: discard 42005 points
  TrainingPool->update: Nvs=41968 ->  close_surface_sample_idx=24985, all_points=50000000, increasement: 49958032
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([24985])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.768101, mean_loss=0.768002, diff=0.000098, thres=0.000100
FrameId=569:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 8687, --cropped--> 8330
  Registration->register: reg_points=torch.Size([320, 6]), translation=tensor([-0.1387, -0.5024, -0.0277], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([8330, 6]) -> sampled_points=torch.Size([41650, 6]) time= 0.39 ms
  LatentFeature->update: samples=41650, new_points=1039 (closreSur>VoxDwn>Radius>Distance), all_points=2566534
  TrainingPool->update:  All points now is 50041650 > 50000000 frame buffer: discard 41650 points
  TrainingPool->update: Nvs=41620 ->  close_surface_sample_idx=24753, all_points=50000000, increasement: 49958380
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([24753])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.766906, mean_loss=0.766957, diff=-0.000050, thres=0.000100
FrameId=570:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 8685, --cropped--> 8347
  Registration->register: reg_points=torch.Size([323, 6]), translation=tensor([-0.1510, -0.5156, -0.0211], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([8347, 6]) -> sampled_points=torch.Size([41735, 6]) time= 0.38 ms
  LatentFeature->update: samples=41735, new_points=1036 (closreSur>VoxDwn>Radius>Distance), all_points=2567570
  TrainingPool->update:  All points now is 50041735 > 50000000 frame buffer: discard 41735 points
  TrainingPool->update: Nvs=41696 ->  close_surface_sample_idx=24816, all_points=50000000, increasement: 49958304
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([24816])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.767760, mean_loss=0.767705, diff=0.000054, thres=0.000100
FrameId=571:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 8741, --cropped--> 8412
  Registration->register: reg_points=torch.Size([323, 6]), translation=tensor([-0.1661, -0.5174, -0.0048], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([8412, 6]) -> sampled_points=torch.Size([42060, 6]) time= 0.37 ms
  LatentFeature->update: samples=42060, new_points=1038 (closreSur>VoxDwn>Radius>Distance), all_points=2568608
  TrainingPool->update:  All points now is 50042060 > 50000000 frame buffer: discard 42060 points
  TrainingPool->update: Nvs=42027 ->  close_surface_sample_idx=25067, all_points=50000000, increasement: 49957973
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([25067])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.768974, mean_loss=0.769071, diff=-0.000098, thres=0.000100
FrameId=572:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 8716, --cropped--> 8401
  Registration->register: reg_points=torch.Size([331, 6]), translation=tensor([-0.1508, -0.4688, -0.0257], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([8401, 6]) -> sampled_points=torch.Size([42005, 6]) time= 0.38 ms
  LatentFeature->update: samples=42005, new_points=1051 (closreSur>VoxDwn>Radius>Distance), all_points=2569659
  TrainingPool->update:  All points now is 50042005 > 50000000 frame buffer: discard 42005 points
  TrainingPool->update: Nvs=41970 ->  close_surface_sample_idx=25041, all_points=50000000, increasement: 49958030
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([25041])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.767956, mean_loss=0.768019, diff=-0.000063, thres=0.000100
FrameId=573:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 8786, --cropped--> 8489
  Registration->register: reg_points=torch.Size([331, 6]), translation=tensor([-0.1743, -0.4869,  0.0074], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([8489, 6]) -> sampled_points=torch.Size([42445, 6]) time= 0.39 ms
  LatentFeature->update: samples=42445, new_points=1080 (closreSur>VoxDwn>Radius>Distance), all_points=2570739
  TrainingPool->update:  All points now is 50042445 > 50000000 frame buffer: discard 42445 points
  TrainingPool->update: Nvs=42401 ->  close_surface_sample_idx=25214, all_points=50000000, increasement: 49957599
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([25214])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.767787, mean_loss=0.767830, diff=-0.000042, thres=0.000100
FrameId=574:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 8704, --cropped--> 8450
  Registration->register: reg_points=torch.Size([331, 6]), translation=tensor([-0.1865, -0.4785,  0.0082], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([8450, 6]) -> sampled_points=torch.Size([42250, 6]) time= 0.38 ms
  LatentFeature->update: samples=42250, new_points=1073 (closreSur>VoxDwn>Radius>Distance), all_points=2571812
  TrainingPool->update:  All points now is 50042250 > 50000000 frame buffer: discard 42250 points
  TrainingPool->update: Nvs=42222 ->  close_surface_sample_idx=25181, all_points=50000000, increasement: 49957778
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([25181])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.768033, mean_loss=0.767994, diff=0.000040, thres=0.000100
FrameId=575:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 8859, --cropped--> 8634
  Registration->register: reg_points=torch.Size([333, 6]), translation=tensor([-0.2048, -0.4880,  0.0094], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([8634, 6]) -> sampled_points=torch.Size([43170, 6]) time= 0.38 ms
  LatentFeature->update: samples=43170, new_points=1088 (closreSur>VoxDwn>Radius>Distance), all_points=2572900
  TrainingPool->update:  All points now is 50043170 > 50000000 frame buffer: discard 43170 points
  TrainingPool->update: Nvs=43136 ->  close_surface_sample_idx=25681, all_points=50000000, increasement: 49956864
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([25681])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.769571, mean_loss=0.769571, diff=-0.000000, thres=0.000100
FrameId=576:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 8975, --cropped--> 8767
  Registration->register: reg_points=torch.Size([329, 6]), translation=tensor([-0.2146, -0.5181, -0.0131], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([8767, 6]) -> sampled_points=torch.Size([43835, 6]) time= 0.39 ms
  LatentFeature->update: samples=43835, new_points=1094 (closreSur>VoxDwn>Radius>Distance), all_points=2573994
  TrainingPool->update:  All points now is 50043835 > 50000000 frame buffer: discard 43835 points
  TrainingPool->update: Nvs=43794 ->  close_surface_sample_idx=26039, all_points=50000000, increasement: 49956206
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([26039])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.768150, mean_loss=0.768217, diff=-0.000067, thres=0.000100
FrameId=577:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 8956, --cropped--> 8766
  Registration->register: reg_points=torch.Size([327, 6]), translation=tensor([-0.2041, -0.5066, -0.0178], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([8766, 6]) -> sampled_points=torch.Size([43830, 6]) time= 0.38 ms
  LatentFeature->update: samples=43830, new_points=1116 (closreSur>VoxDwn>Radius>Distance), all_points=2575110
  TrainingPool->update:  All points now is 50043830 > 50000000 frame buffer: discard 43830 points
  TrainingPool->update: Nvs=43803 ->  close_surface_sample_idx=26120, all_points=50000000, increasement: 49956197
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([26120])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.768419, mean_loss=0.768455, diff=-0.000036, thres=0.000100
FrameId=578:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 9031, --cropped--> 8851
  Registration->register: reg_points=torch.Size([341, 6]), translation=tensor([-0.2152, -0.5031, -0.0129], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([8851, 6]) -> sampled_points=torch.Size([44255, 6]) time= 0.38 ms
  LatentFeature->update: samples=44255, new_points=1129 (closreSur>VoxDwn>Radius>Distance), all_points=2576239
  TrainingPool->update:  All points now is 50044255 > 50000000 frame buffer: discard 44255 points
  TrainingPool->update: Nvs=44220 ->  close_surface_sample_idx=26331, all_points=50000000, increasement: 49955780
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([26331])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.767206, mean_loss=0.767256, diff=-0.000050, thres=0.000100
FrameId=579:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 9027, --cropped--> 8850
  Registration->register: reg_points=torch.Size([346, 6]), translation=tensor([-0.2122, -0.4870, -0.0154], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([8850, 6]) -> sampled_points=torch.Size([44250, 6]) time= 0.39 ms
  LatentFeature->update: samples=44250, new_points=1115 (closreSur>VoxDwn>Radius>Distance), all_points=2577354
  TrainingPool->update:  All points now is 50044250 > 50000000 frame buffer: discard 44250 points
  TrainingPool->update: Nvs=44216 ->  close_surface_sample_idx=26260, all_points=50000000, increasement: 49955784
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([26260])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.768194, mean_loss=0.768280, diff=-0.000086, thres=0.000100
FrameId=580:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 9113, --cropped--> 8960
  Registration->register: reg_points=torch.Size([345, 6]), translation=tensor([-0.2151, -0.4929, -0.0032], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([8960, 6]) -> sampled_points=torch.Size([44800, 6]) time= 0.37 ms
  LatentFeature->update: samples=44800, new_points=1138 (closreSur>VoxDwn>Radius>Distance), all_points=2578492
  TrainingPool->update:  All points now is 50044800 > 50000000 frame buffer: discard 44800 points
  TrainingPool->update: Nvs=44756 ->  close_surface_sample_idx=26664, all_points=50000000, increasement: 49955244
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([26664])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.767536, mean_loss=0.767584, diff=-0.000048, thres=0.000100
FrameId=581:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 9321, --cropped--> 9162
  Registration->register: reg_points=torch.Size([356, 6]), translation=tensor([-0.2392, -0.5238,  0.0259], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([9162, 6]) -> sampled_points=torch.Size([45810, 6]) time= 0.42 ms
  LatentFeature->update: samples=45810, new_points=1141 (closreSur>VoxDwn>Radius>Distance), all_points=2579633
  TrainingPool->update:  All points now is 50045810 > 50000000 frame buffer: discard 45810 points
  TrainingPool->update: Nvs=45770 ->  close_surface_sample_idx=27236, all_points=50000000, increasement: 49954230
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([27236])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.768755, mean_loss=0.768855, diff=-0.000099, thres=0.000100
FrameId=582:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 9360, --cropped--> 9191
  Registration->register: reg_points=torch.Size([364, 6]), translation=tensor([-0.1909, -0.5537,  0.0185], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([9191, 6]) -> sampled_points=torch.Size([45955, 6]) time= 0.43 ms
  LatentFeature->update: samples=45955, new_points=1189 (closreSur>VoxDwn>Radius>Distance), all_points=2580822
  TrainingPool->update:  All points now is 50045955 > 50000000 frame buffer: discard 45955 points
  TrainingPool->update: Nvs=45913 ->  close_surface_sample_idx=27350, all_points=50000000, increasement: 49954087
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([27350])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.767958, mean_loss=0.767980, diff=-0.000023, thres=0.000100
FrameId=583:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 9454, --cropped--> 9308
  Registration->register: reg_points=torch.Size([372, 6]), translation=tensor([-0.1855, -0.5040,  0.0105], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([9308, 6]) -> sampled_points=torch.Size([46540, 6]) time= 0.42 ms
  LatentFeature->update: samples=46540, new_points=1179 (closreSur>VoxDwn>Radius>Distance), all_points=2582001
  TrainingPool->update:  All points now is 50046540 > 50000000 frame buffer: discard 46540 points
  TrainingPool->update: Nvs=46492 ->  close_surface_sample_idx=27631, all_points=50000000, increasement: 49953508
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([27631])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.768152, mean_loss=0.768209, diff=-0.000057, thres=0.000100
FrameId=584:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 9547, --cropped--> 9398
  Registration->register: reg_points=torch.Size([376, 6]), translation=tensor([-0.1945, -0.5032,  0.0047], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([9398, 6]) -> sampled_points=torch.Size([46990, 6]) time= 0.43 ms
  LatentFeature->update: samples=46990, new_points=1178 (closreSur>VoxDwn>Radius>Distance), all_points=2583179
  TrainingPool->update:  All points now is 50046990 > 50000000 frame buffer: discard 46990 points
  TrainingPool->update: Nvs=46936 ->  close_surface_sample_idx=27900, all_points=50000000, increasement: 49953064
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([27900])
  TrainingPool->train: break at iter=53, cur_mean_loss=0.768100, mean_loss=0.768191, diff=-0.000091, thres=0.000100
FrameId=585:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 9370, --cropped--> 9215
  Registration->register: reg_points=torch.Size([367, 6]), translation=tensor([-0.1890, -0.4991,  0.0151], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([9215, 6]) -> sampled_points=torch.Size([46075, 6]) time= 0.42 ms
  LatentFeature->update: samples=46075, new_points=1166 (closreSur>VoxDwn>Radius>Distance), all_points=2584345
  TrainingPool->update:  All points now is 50046075 > 50000000 frame buffer: discard 46075 points
  TrainingPool->update: Nvs=46037 ->  close_surface_sample_idx=27448, all_points=50000000, increasement: 49953963
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([27448])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.767743, mean_loss=0.767749, diff=-0.000005, thres=0.000100
FrameId=586:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 9363, --cropped--> 9213
  Registration->register: reg_points=torch.Size([376, 6]), translation=tensor([-0.2052, -0.5175,  0.0277], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([9213, 6]) -> sampled_points=torch.Size([46065, 6]) time= 0.41 ms
  LatentFeature->update: samples=46065, new_points=1138 (closreSur>VoxDwn>Radius>Distance), all_points=2585483
  TrainingPool->update:  All points now is 50046065 > 50000000 frame buffer: discard 46065 points
  TrainingPool->update: Nvs=46030 ->  close_surface_sample_idx=27244, all_points=50000000, increasement: 49953970
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([27244])
  TrainingPool->train: break at iter=55, cur_mean_loss=0.767654, mean_loss=0.767716, diff=-0.000062, thres=0.000100
FrameId=587:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 9273, --cropped--> 9125
  Registration->register: reg_points=torch.Size([371, 6]), translation=tensor([-0.2234, -0.5301,  0.0378], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([9125, 6]) -> sampled_points=torch.Size([45625, 6]) time= 0.42 ms
  LatentFeature->update: samples=45625, new_points=1126 (closreSur>VoxDwn>Radius>Distance), all_points=2586609
  TrainingPool->update:  All points now is 50045625 > 50000000 frame buffer: discard 45625 points
  TrainingPool->update: Nvs=45577 ->  close_surface_sample_idx=26968, all_points=50000000, increasement: 49954423
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([26968])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.767443, mean_loss=0.767487, diff=-0.000044, thres=0.000100
FrameId=588:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 9158, --cropped--> 9007
  Registration->register: reg_points=torch.Size([359, 6]), translation=tensor([-0.2381, -0.5340,  0.0394], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([9007, 6]) -> sampled_points=torch.Size([45035, 6]) time= 0.42 ms
  LatentFeature->update: samples=45035, new_points=1129 (closreSur>VoxDwn>Radius>Distance), all_points=2587738
  TrainingPool->update:  All points now is 50045035 > 50000000 frame buffer: discard 45035 points
  TrainingPool->update: Nvs=44991 ->  close_surface_sample_idx=26748, all_points=50000000, increasement: 49955009
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([26748])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.768472, mean_loss=0.768430, diff=0.000043, thres=0.000100
FrameId=589:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 9119, --cropped--> 8963
  Registration->register: reg_points=torch.Size([364, 6]), translation=tensor([-0.2408, -0.5448,  0.0410], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([8963, 6]) -> sampled_points=torch.Size([44815, 6]) time= 0.42 ms
  LatentFeature->update: samples=44815, new_points=1119 (closreSur>VoxDwn>Radius>Distance), all_points=2588857
  TrainingPool->update:  All points now is 50044815 > 50000000 frame buffer: discard 44815 points
  TrainingPool->update: Nvs=44781 ->  close_surface_sample_idx=26531, all_points=50000000, increasement: 49955219
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([26531])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.767373, mean_loss=0.767413, diff=-0.000040, thres=0.000100
FrameId=590:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 9068, --cropped--> 8922
  Registration->register: reg_points=torch.Size([355, 6]), translation=tensor([-0.2352, -0.5518,  0.0340], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([8922, 6]) -> sampled_points=torch.Size([44610, 6]) time= 0.42 ms
  LatentFeature->update: samples=44610, new_points=1105 (closreSur>VoxDwn>Radius>Distance), all_points=2589962
  TrainingPool->update:  All points now is 50044610 > 50000000 frame buffer: discard 44610 points
  TrainingPool->update: Nvs=44576 ->  close_surface_sample_idx=26506, all_points=50000000, increasement: 49955424
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([26506])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.767824, mean_loss=0.767822, diff=0.000001, thres=0.000100
FrameId=591:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 9099, --cropped--> 8938
  Registration->register: reg_points=torch.Size([365, 6]), translation=tensor([-0.2556, -0.5393,  0.0334], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([8938, 6]) -> sampled_points=torch.Size([44690, 6]) time= 0.40 ms
  LatentFeature->update: samples=44690, new_points=1115 (closreSur>VoxDwn>Radius>Distance), all_points=2591077
  TrainingPool->update:  All points now is 50044690 > 50000000 frame buffer: discard 44690 points
  TrainingPool->update: Nvs=44648 ->  close_surface_sample_idx=26423, all_points=50000000, increasement: 49955352
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([26423])
  TrainingPool->train: break at iter=51, cur_mean_loss=0.767799, mean_loss=0.767743, diff=0.000056, thres=0.000100
FrameId=592:  cached_time=1.8 ms
  TumDataset->next_frame: Original=307200 -downsample-> 9029, --cropped--> 8886
  Registration->register: reg_points=torch.Size([362, 6]), translation=tensor([-0.2436, -0.5285,  0.0243], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([8886, 6]) -> sampled_points=torch.Size([44430, 6]) time= 0.40 ms
  LatentFeature->update: samples=44430, new_points=1120 (closreSur>VoxDwn>Radius>Distance), all_points=2592197
  TrainingPool->update:  All points now is 50044430 > 50000000 frame buffer: discard 44430 points
  TrainingPool->update: Nvs=44386 ->  close_surface_sample_idx=26388, all_points=50000000, increasement: 49955614
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([26388])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.766629, mean_loss=0.766652, diff=-0.000023, thres=0.000100
FrameId=593:  cached_time=1.7 ms
  TumDataset->next_frame: Original=307200 -downsample-> 9213, --cropped--> 9069
  Registration->register: reg_points=torch.Size([367, 6]), translation=tensor([-0.2330, -0.5047,  0.0125], device='cuda:0')
  Sampling->dist_sampling: pc=torch.Size([9069, 6]) -> sampled_points=torch.Size([45345, 6]) time= 0.39 ms
  LatentFeature->update: samples=45345, new_points=1133 (closreSur>VoxDwn>Radius>Distance), all_points=2593330
  TrainingPool->update:  All points now is 50045345 > 50000000 frame buffer: discard 45345 points
  TrainingPool->update: Nvs=45305 ->  close_surface_sample_idx=27007, all_points=50000000, increasement: 49954695
  TrainingPool->train: n_iter=300, surface_sample_idx=torch.Size([27007])
  TrainingPool->train: break at iter=52, cur_mean_loss=0.767149, mean_loss=0.767235, diff=-0.000085, thres=0.000100
